"""
Milvus è³‡æ–™å¯«å…¥å™¨
è² è²¬å°‡å‘é‡è³‡æ–™å¯«å…¥ Milvus å‘é‡è³‡æ–™åº«
"""

import logging
from typing import Dict, List, Any, Optional
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
import numpy as np

logger = logging.getLogger(__name__)


class MilvusWriter:
    """Milvus è³‡æ–™å¯«å…¥å™¨"""
    
    def __init__(self, milvus_config: Dict[str, Any]):
        """
        åˆå§‹åŒ– Milvus å¯«å…¥å™¨
        
        Args:
            milvus_config: Milvus é…ç½®å­—å…¸
        """
        self.milvus_config = milvus_config
        self.connected = False
        
    def connect(self) -> None:
        """é€£æ¥åˆ° Milvus"""
        try:
            connections.connect(
                alias="default",
                host=self.milvus_config["host"],
                port=self.milvus_config["port"]
            )
            self.connected = True
            logger.info(f"æˆåŠŸé€£æ¥åˆ° Milvus: {self.milvus_config['host']}:{self.milvus_config['port']}")
        except Exception as e:
            logger.error(f"Milvus é€£æ¥å¤±æ•—: {e}")
            raise
    
    def create_collection(self, collection_name: str, embedding_dim: int = 1024) -> str:
        """
        å‰µå»º Milvus é›†åˆ
        
        Args:
            collection_name: é›†åˆåç¨±
            embedding_dim: åµŒå…¥å‘é‡ç¶­åº¦
            
        Returns:
            é›†åˆåç¨±
        """
        if not self.connected:
            self.connect()
            
        try:
            # æª¢æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            if utility.has_collection(collection_name):
                logger.info(f"é›†åˆ {collection_name} å·²å­˜åœ¨")
                return collection_name
            
            # å®šç¾©å­—æ®µ - ç¬¦åˆæ–°çš„ Milvus schema
            fields = [
                FieldSchema(name="chunk_id", dtype=DataType.VARCHAR, max_length=1024, is_primary=True),
                FieldSchema(name="chunk_index", dtype=DataType.INT64),
                FieldSchema(name="episode_id", dtype=DataType.INT64),
                FieldSchema(name="podcast_id", dtype=DataType.INT64),
                FieldSchema(name="episode_title", dtype=DataType.VARCHAR, max_length=1024),
                FieldSchema(name="chunk_text", dtype=DataType.VARCHAR, max_length=1024),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
                FieldSchema(name="language", dtype=DataType.VARCHAR, max_length=1024),
                FieldSchema(name="created_at", dtype=DataType.VARCHAR, max_length=1024),
                FieldSchema(name="source_model", dtype=DataType.VARCHAR, max_length=1024),
                FieldSchema(name="podcast_name", dtype=DataType.VARCHAR, max_length=1024),
                FieldSchema(name="author", dtype=DataType.VARCHAR, max_length=1024),
                FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=1024),
                # ğŸ” åˆä½µå¾Œçš„ tag æ¬„ä½ï¼Œå­˜ç‚º JSON æ ¼å¼å­—ä¸²
                FieldSchema(name="tags", dtype=DataType.VARCHAR, max_length=1024),
            ]
            
            # å‰µå»ºé›†åˆ
            schema = CollectionSchema(
                fields=fields,
                description=f"Podcast Chunks Collection with Vector Tags (dim: {embedding_dim})"
            )
            collection = Collection(name=collection_name, schema=schema)
            
            # å‰µå»ºç´¢å¼•
            index_params = {
                "metric_type": self.milvus_config.get("metric_type", "COSINE"),
                "index_type": self.milvus_config.get("index_type", "IVF_FLAT"),
                "params": {"nlist": self.milvus_config.get("nlist", 1024)}
            }
            
            # ç‚ºåµŒå…¥å‘é‡æ¬„ä½å‰µå»ºç´¢å¼•
            collection.create_index(field_name="embedding", index_params=index_params)
            
            logger.info(f"æˆåŠŸå‰µå»ºé›†åˆ {collection_name}")
            return collection_name
            
        except Exception as e:
            logger.error(f"å‰µå»ºé›†åˆå¤±æ•—: {e}")
            raise
    
    def drop_collection(self, collection_name: str) -> None:
        """
        åˆªé™¤é›†åˆ
        
        Args:
            collection_name: é›†åˆåç¨±
        """
        if not self.connected:
            self.connect()
            
        try:
            if utility.has_collection(collection_name):
                utility.drop_collection(collection_name)
                logger.info(f"æˆåŠŸåˆªé™¤é›†åˆ {collection_name}")
            else:
                logger.warning(f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
        except Exception as e:
            logger.error(f"åˆªé™¤é›†åˆå¤±æ•—: {e}")
            raise
    
    def insert_data(self, collection_name: str, data: Dict[str, List]) -> int:
        """
        æ’å…¥è³‡æ–™åˆ°é›†åˆ
        
        Args:
            collection_name: é›†åˆåç¨±
            data: è¦æ’å…¥çš„è³‡æ–™å­—å…¸
            
        Returns:
            æ’å…¥çš„è³‡æ–™æ•¸é‡
        """
        if not self.connected:
            self.connect()
            
        try:
            collection = Collection(collection_name)
            
            # å®šç¾©æ¬„ä½é †åºï¼ˆå¿…é ˆèˆ‡ schema ä¸€è‡´ï¼‰
            field_order = [
                "chunk_id", "chunk_index", "episode_id", "podcast_id", 
                "episode_title", "chunk_text", "embedding", "language", 
                "created_at", "source_model", "podcast_name", "author", 
                "category", "tags"
            ]
            
            # å°‡ dict è½‰æ›ç‚º list of listï¼ˆæ¯å€‹æ¬„ä½ä¸€å€‹ listï¼‰
            insert_data = [data[field] for field in field_order]
            
            # æ’å…¥è³‡æ–™
            insert_result = collection.insert(insert_data)
            inserted_count = len(data.get("chunk_id", []))
            
            logger.info(f"æˆåŠŸæ’å…¥ {inserted_count} ç­†è³‡æ–™åˆ°é›†åˆ {collection_name}")
            return inserted_count
            
        except Exception as e:
            logger.error(f"æ’å…¥è³‡æ–™å¤±æ•—: {e}")
            raise
    
    def batch_insert(self, collection_name: str, data_list: List[Dict[str, Any]], 
                    batch_size: int = 100) -> int:
        """
        æ‰¹æ¬¡æ’å…¥è³‡æ–™
        
        Args:
            collection_name: é›†åˆåç¨±
            data_list: è³‡æ–™åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            ç¸½æ’å…¥è³‡æ–™æ•¸é‡
        """
        total_inserted = 0
        
        try:
            for i in range(0, len(data_list), batch_size):
                batch_data = data_list[i:i + batch_size]
                
                # æ¯æ¬¡æ‰¹æ¬¡å‰æª¢æŸ¥é€£ç·š
                if not self.connected:
                    self.connect()
                
                # æº–å‚™æ’å…¥è³‡æ–™æ ¼å¼
                insert_data = self._prepare_batch_data(batch_data)
                
                # æ’å…¥æ‰¹æ¬¡è³‡æ–™
                inserted_count = self.insert_data(collection_name, insert_data)
                total_inserted += inserted_count
                
                logger.info(f"æ‰¹æ¬¡ {i//batch_size + 1}: æ’å…¥ {inserted_count} ç­†è³‡æ–™")
            
            return total_inserted
            
        except Exception as e:
            logger.error(f"æ‰¹æ¬¡æ’å…¥å¤±æ•—: {e}")
            # å˜—è©¦é‡æ–°é€£ç·š
            try:
                self.connect()
            except:
                pass
            raise
    
    def _prepare_batch_data(self, data_list: List[Dict[str, Any]]) -> Dict[str, List]:
        """
        æº–å‚™æ‰¹æ¬¡æ’å…¥è³‡æ–™æ ¼å¼
        
        Args:
            data_list: è³‡æ–™åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–å¾Œçš„è³‡æ–™å­—å…¸
        """
        batch_data = {
            "chunk_id": [],
            "chunk_index": [],
            "episode_id": [],
            "podcast_id": [],
            "episode_title": [],
            "chunk_text": [],
            "embedding": [],
            "language": [],
            "created_at": [],
            "source_model": [],
            "podcast_name": [],
            "author": [],
            "category": [],
            "tags": []
        }
        
        for data in data_list:
            for key in batch_data:
                if key in data:
                    value = data[key]
                    # å¼·åˆ¶ chunk_id ç‚º strï¼Œä¸”å¦‚æœæ˜¯ list åªå–ç¬¬ä¸€å€‹å…ƒç´ 
                    if key == "chunk_id":
                        if isinstance(value, list):
                            value = value[0] if value else ""
                        value = str(value)
                    batch_data[key].append(value)
                else:
                    # æä¾›é è¨­å€¼
                    if key == "embedding":
                        batch_data[key].append([])
                    elif key == "tags":
                        batch_data[key].append("[]")  # ç©ºçš„ JSON é™£åˆ—å­—ä¸²
                    else:
                        batch_data[key].append("")
        
        return batch_data
    
    def load_collection(self, collection_name: str) -> None:
        """
        è¼‰å…¥é›†åˆåˆ°è¨˜æ†¶é«”
        
        Args:
            collection_name: é›†åˆåç¨±
        """
        if not self.connected:
            self.connect()
            
        try:
            collection = Collection(collection_name)
            collection.load()
            logger.info(f"æˆåŠŸè¼‰å…¥é›†åˆ {collection_name}")
        except Exception as e:
            logger.error(f"è¼‰å…¥é›†åˆå¤±æ•—: {e}")
            raise
    
    def get_collection_stats(self, collection_name: str) -> Dict[str, Any]:
        """
        ç²å–é›†åˆçµ±è¨ˆè³‡è¨Š
        
        Args:
            collection_name: é›†åˆåç¨±
            
        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸
        """
        if not self.connected:
            self.connect()
            
        try:
            collection = Collection(collection_name)
            stats = {
                "collection_name": collection_name,
                "num_entities": collection.num_entities,
                "schema": {field.name: str(field.dtype) for field in collection.schema.fields}
            }
            return stats
        except Exception as e:
            logger.error(f"ç²å–é›†åˆçµ±è¨ˆå¤±æ•—: {e}")
            raise
    
    def close(self) -> None:
        """é—œé–‰é€£æ¥"""
        if self.connected:
            connections.disconnect("default")
            self.connected = False
            logger.info("Milvus é€£æ¥å·²é—œé–‰") 

    def clear_collection(self, collection_name: str) -> None:
        """
        æ¸…ç©ºé›†åˆå…§å®¹ï¼ˆä¿ç•™é›†åˆçµæ§‹ï¼‰
        
        Args:
            collection_name: é›†åˆåç¨±
        """
        if not self.connected:
            self.connect()
            
        try:
            if utility.has_collection(collection_name):
                collection = Collection(collection_name)
                # åˆªé™¤æ‰€æœ‰è³‡æ–™ï¼ˆä½¿ç”¨æ­£ç¢ºçš„ filter è¡¨é”å¼ï¼‰
                collection.delete("chunk_id != ''")  # åˆªé™¤æ‰€æœ‰æœ‰ chunk_id çš„è³‡æ–™
                logger.info(f"æˆåŠŸæ¸…ç©ºé›†åˆ {collection_name} çš„å…§å®¹")
            else:
                logger.warning(f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
        except Exception as e:
            logger.error(f"æ¸…ç©ºé›†åˆå¤±æ•—: {e}")
            raise 