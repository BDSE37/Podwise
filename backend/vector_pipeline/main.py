#!/usr/bin/env python3
"""
Vector Pipeline ä¸»ç¨‹å¼ - é‡æ§‹ç‰ˆæœ¬
çµ±ä¸€å…¥å£é»ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½
ç¬¦åˆ Google Clean Code åŸå‰‡
"""

import logging
import sys
import argparse
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

from config.settings import config
from services.tagging_service import TaggingService
from services.embedding_service import EmbeddingService
from services.search_service import SearchService
from utils.data_quality_checker import DataQualityChecker

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=getattr(logging, config.log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(config.log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class VectorPipeline:
    """Vector Pipeline ä¸»é¡åˆ¥ - é‡æ§‹ç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ– Vector Pipeline"""
        self.tagging_service = TaggingService()
        self.embedding_service = EmbeddingService()
        self.search_service = SearchService()
        self.data_quality_checker = DataQualityChecker()
        
        logger.info("Vector Pipeline åˆå§‹åŒ–å®Œæˆ")
    
    def process_tagging(self, stage1_dir: Optional[str] = None, 
                       stage3_dir: Optional[str] = None) -> Dict[str, Any]:
        """
        åŸ·è¡Œæ¨™ç±¤è™•ç†
        
        Args:
            stage1_dir: stage1 ç›®éŒ„è·¯å¾‘
            stage3_dir: stage3 ç›®éŒ„è·¯å¾‘
            
        Returns:
            è™•ç†çµæœ
        """
        stage1_path = Path(stage1_dir or config.stage1_dir)
        stage3_path = Path(stage3_dir or config.stage3_dir)
        
        if not stage1_path.exists():
            return {"error": f"è¼¸å…¥è·¯å¾‘ä¸å­˜åœ¨: {stage1_path}"}
        
        # ç²å–æ‰€æœ‰ RSS è³‡æ–™å¤¾
        rss_folders = [f.name for f in stage1_path.iterdir() 
                      if f.is_dir() and f.name.startswith('RSS_')]
        
        if not rss_folders:
            return {"error": "æ²’æœ‰æ‰¾åˆ° RSS è³‡æ–™å¤¾"}
        
        logger.info(f"é–‹å§‹æ¨™ç±¤è™•ç†ï¼Œæ‰¾åˆ° {len(rss_folders)} å€‹ RSS è³‡æ–™å¤¾")
        
        # åŸ·è¡Œæ¨™ç±¤è™•ç†
        results = self.tagging_service.process_multiple_rss_folders(
            rss_folders, str(stage1_path), str(stage3_path)
        )
        
        return results
    
    def process_embedding(self, stage3_dir: Optional[str] = None) -> Dict[str, Any]:
        """
        åŸ·è¡ŒåµŒå…¥è™•ç†
        
        Args:
            stage3_dir: stage3 ç›®éŒ„è·¯å¾‘
            
        Returns:
            åµŒå…¥çµæœ
        """
        logger.info("é–‹å§‹åµŒå…¥è™•ç†")
        
        results = self.embedding_service.embed_stage3_data(stage3_dir)
        
        if "error" not in results:
            logger.info(f"åµŒå…¥å®Œæˆ: {results['successful_files']}/{results['total_files']} æª”æ¡ˆæˆåŠŸ")
        
        return results
    
    def search_content(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """
        æœå°‹å…§å®¹
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            top_k: è¿”å›çµæœæ•¸é‡
            
        Returns:
            æœå°‹çµæœ
        """
        logger.info(f"æœå°‹å…§å®¹: '{query}'")
        
        results = self.search_service.search_similar_content(query, top_k)
        
        return {
            "query": query,
            "results": results,
            "count": len(results)
        }
    
    def test_search(self) -> Dict[str, Any]:
        """
        æ¸¬è©¦æœå°‹åŠŸèƒ½
        
        Returns:
            æ¸¬è©¦çµæœ
        """
        logger.info("é–‹å§‹æœå°‹åŠŸèƒ½æ¸¬è©¦")
        
        return self.search_service.test_search_functionality()
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """
        ç²å–é›†åˆçµ±è¨ˆè³‡è¨Š
        
        Returns:
            é›†åˆçµ±è¨ˆè³‡è¨Š
        """
        return self.search_service.get_collection_stats()
    
    def get_tag_statistics(self, stage3_dir: Optional[str] = None) -> Dict[str, Any]:
        """
        ç²å–æ¨™ç±¤çµ±è¨ˆè³‡è¨Š
        
        Args:
            stage3_dir: stage3 ç›®éŒ„è·¯å¾‘
            
        Returns:
            æ¨™ç±¤çµ±è¨ˆè³‡è¨Š
        """
        return self.tagging_service.get_tag_statistics(stage3_dir)
    
    def check_data_quality(self, stage3_dir: Optional[str] = None) -> Dict[str, Any]:
        """
        æª¢æŸ¥è³‡æ–™å“è³ª
        
        Args:
            stage3_dir: stage3 ç›®éŒ„è·¯å¾‘
            
        Returns:
            è³‡æ–™å“è³ªå ±å‘Š
        """
        stage3_path = Path(stage3_dir or config.stage3_dir)
        
        if not stage3_path.exists():
            return {"error": f"ç›®éŒ„ä¸å­˜åœ¨: {stage3_path}"}
        
        logger.info("é–‹å§‹è³‡æ–™å“è³ªæª¢æŸ¥")
        
        return self.data_quality_checker.check_stage3_data(str(stage3_path))
    
    def run_full_pipeline(self) -> Dict[str, Any]:
        """
        åŸ·è¡Œå®Œæ•´ç®¡ç·š
        
        Returns:
            å®Œæ•´ç®¡ç·šçµæœ
        """
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´ Vector Pipeline")
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "stages": {}
        }
        
        try:
            # éšæ®µ 1: æ¨™ç±¤è™•ç†
            logger.info("=== éšæ®µ 1: æ¨™ç±¤è™•ç† ===")
            tagging_results = self.process_tagging()
            results["stages"]["tagging"] = tagging_results
            
            # éšæ®µ 2: åµŒå…¥è™•ç†
            logger.info("=== éšæ®µ 2: åµŒå…¥è™•ç† ===")
            embedding_results = self.process_embedding()
            results["stages"]["embedding"] = embedding_results
            
            # éšæ®µ 3: æœå°‹æ¸¬è©¦
            logger.info("=== éšæ®µ 3: æœå°‹æ¸¬è©¦ ===")
            search_results = self.test_search()
            results["stages"]["search_test"] = search_results
            
            logger.info("ğŸ‰ å®Œæ•´ç®¡ç·šåŸ·è¡Œå®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç®¡ç·šåŸ·è¡Œå¤±æ•—: {e}")
            results["error"] = str(e)
        
        return results


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="Vector Pipeline ä¸»ç¨‹å¼")
    parser.add_argument("--action", choices=[
        "tagging", "embedding", "search", "test_search", 
        "stats", "tag_stats", "quality", "full_pipeline"
    ], default="full_pipeline", help="åŸ·è¡Œå‹•ä½œ")
    
    parser.add_argument("--query", type=str, help="æœå°‹æŸ¥è©¢")
    parser.add_argument("--top_k", type=int, default=5, help="æœå°‹çµæœæ•¸é‡")
    parser.add_argument("--stage1_dir", type=str, help="stage1 ç›®éŒ„è·¯å¾‘")
    parser.add_argument("--stage3_dir", type=str, help="stage3 ç›®éŒ„è·¯å¾‘")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ– Vector Pipeline
    pipeline = VectorPipeline()
    
    try:
        if args.action == "tagging":
            results = pipeline.process_tagging(args.stage1_dir, args.stage3_dir)
            print("æ¨™ç±¤è™•ç†çµæœ:", results)
            
        elif args.action == "embedding":
            results = pipeline.process_embedding(args.stage3_dir)
            print("åµŒå…¥è™•ç†çµæœ:", results)
            
        elif args.action == "search":
            if not args.query:
                print("éŒ¯èª¤: æœå°‹éœ€è¦æä¾› --query åƒæ•¸")
                return
            results = pipeline.search_content(args.query, args.top_k)
            print("æœå°‹çµæœ:", results)
            
        elif args.action == "test_search":
            results = pipeline.test_search()
            print("æœå°‹æ¸¬è©¦çµæœ:", results)
            
        elif args.action == "stats":
            results = pipeline.get_collection_stats()
            print("é›†åˆçµ±è¨ˆ:", results)
            
        elif args.action == "tag_stats":
            results = pipeline.get_tag_statistics(args.stage3_dir)
            print("æ¨™ç±¤çµ±è¨ˆ:", results)
            
        elif args.action == "quality":
            results = pipeline.check_data_quality(args.stage3_dir)
            print("è³‡æ–™å“è³ªå ±å‘Š:", results)
            
        elif args.action == "full_pipeline":
            results = pipeline.run_full_pipeline()
            print("å®Œæ•´ç®¡ç·šçµæœ:", results)
            
    except Exception as e:
        logger.error(f"åŸ·è¡Œå¤±æ•—: {e}")
        print(f"éŒ¯èª¤: {e}")


if __name__ == "__main__":
    main() 