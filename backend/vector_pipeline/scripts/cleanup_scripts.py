"""
æ¸…ç†è…³æœ¬
ç”¨æ–¼æ¸…ç†é‡è¤‡å’Œéæ™‚çš„æª”æ¡ˆ
ç¬¦åˆ Google Clean Code åŸå‰‡
"""

import logging
import shutil
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class CleanupScripts:
    """æ¸…ç†è…³æœ¬é¡åˆ¥"""
    
    def __init__(self, backup_dir: str = "backup_before_cleanup"):
        """
        åˆå§‹åŒ–æ¸…ç†è…³æœ¬
        
        Args:
            backup_dir: å‚™ä»½ç›®éŒ„
        """
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
        
    def backup_file(self, file_path: Path) -> bool:
        """
        å‚™ä»½æª”æ¡ˆ
        
        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            
        Returns:
            å‚™ä»½æ˜¯å¦æˆåŠŸ
        """
        try:
            if file_path.exists():
                backup_path = self.backup_dir / file_path.name
                shutil.copy2(file_path, backup_path)
                logger.info(f"å·²å‚™ä»½: {file_path} -> {backup_path}")
                return True
            return False
        except Exception as e:
            logger.error(f"å‚™ä»½å¤±æ•— {file_path}: {e}")
            return False
    
    def cleanup_duplicate_tagging_files(self) -> Dict[str, Any]:
        """
        æ¸…ç†é‡è¤‡çš„æ¨™ç±¤è™•ç†æª”æ¡ˆ
        
        Returns:
            æ¸…ç†çµæœ
        """
        logger.info("é–‹å§‹æ¸…ç†é‡è¤‡çš„æ¨™ç±¤è™•ç†æª”æ¡ˆ")
        
        duplicate_files = [
            "batch_enhanced_tagging.py",
            "batch_enhanced_tagging_v2.py", 
            "batch_retagging.py",
            "reprocess_rss_chunks.py"
        ]
        
        results = {
            "backed_up": [],
            "removed": [],
            "failed": []
        }
        
        for filename in duplicate_files:
            file_path = Path(filename)
            if file_path.exists():
                # å‚™ä»½æª”æ¡ˆ
                if self.backup_file(file_path):
                    results["backed_up"].append(filename)
                    
                    # ç§»é™¤æª”æ¡ˆ
                    try:
                        file_path.unlink()
                        results["removed"].append(filename)
                        logger.info(f"å·²ç§»é™¤: {filename}")
                    except Exception as e:
                        logger.error(f"ç§»é™¤å¤±æ•— {filename}: {e}")
                        results["failed"].append(filename)
        
        logger.info(f"æ¨™ç±¤è™•ç†æª”æ¡ˆæ¸…ç†å®Œæˆ: å‚™ä»½ {len(results['backed_up'])} å€‹ï¼Œç§»é™¤ {len(results['removed'])} å€‹")
        return results
    
    def cleanup_duplicate_milvus_files(self) -> Dict[str, Any]:
        """
        æ¸…ç†é‡è¤‡çš„ Milvus æ¸¬è©¦æª”æ¡ˆ
        
        Returns:
            æ¸…ç†çµæœ
        """
        logger.info("é–‹å§‹æ¸…ç†é‡è¤‡çš„ Milvus æ¸¬è©¦æª”æ¡ˆ")
        
        duplicate_files = [
            "test_milvus_connection.py",
            "test_single_insert.py",
            "test_simple_insert.py",
            "check_milvus_schema.py",
            "check_milvus_version.py",
            "reset_milvus_collection.py",
            "debug_insert_types.py",
            "debug_insert_data.py",
            "debug_data_types.py",
            "debug_id_formats.py",
            "debug_full_flow.py",
            "debug_chunk_id.py",
            "debug_real_embedding.py",
            "debug_embedding_process.py",
            "debug_embedding_errors.py"
        ]
        
        results = {
            "backed_up": [],
            "removed": [],
            "failed": []
        }
        
        for filename in duplicate_files:
            file_path = Path(filename)
            if file_path.exists():
                # å‚™ä»½æª”æ¡ˆ
                if self.backup_file(file_path):
                    results["backed_up"].append(filename)
                    
                    # ç§»é™¤æª”æ¡ˆ
                    try:
                        file_path.unlink()
                        results["removed"].append(filename)
                        logger.info(f"å·²ç§»é™¤: {filename}")
                    except Exception as e:
                        logger.error(f"ç§»é™¤å¤±æ•— {filename}: {e}")
                        results["failed"].append(filename)
        
        logger.info(f"Milvus æ¸¬è©¦æª”æ¡ˆæ¸…ç†å®Œæˆ: å‚™ä»½ {len(results['backed_up'])} å€‹ï¼Œç§»é™¤ {len(results['removed'])} å€‹")
        return results
    
    def cleanup_duplicate_embedding_files(self) -> Dict[str, Any]:
        """
        æ¸…ç†é‡è¤‡çš„åµŒå…¥æª”æ¡ˆ
        
        Returns:
            æ¸…ç†çµæœ
        """
        logger.info("é–‹å§‹æ¸…ç†é‡è¤‡çš„åµŒå…¥æª”æ¡ˆ")
        
        duplicate_files = [
            "embed_stage3_to_milvus.py",
            "embed_stage3_to_milvus_with_real_embeddings.py",
            "test_embedding_flow.py"
        ]
        
        results = {
            "backed_up": [],
            "removed": [],
            "failed": []
        }
        
        for filename in duplicate_files:
            file_path = Path(filename)
            if file_path.exists():
                # å‚™ä»½æª”æ¡ˆ
                if self.backup_file(file_path):
                    results["backed_up"].append(filename)
                    
                    # ç§»é™¤æª”æ¡ˆ
                    try:
                        file_path.unlink()
                        results["removed"].append(filename)
                        logger.info(f"å·²ç§»é™¤: {filename}")
                    except Exception as e:
                        logger.error(f"ç§»é™¤å¤±æ•— {filename}: {e}")
                        results["failed"].append(filename)
        
        logger.info(f"åµŒå…¥æª”æ¡ˆæ¸…ç†å®Œæˆ: å‚™ä»½ {len(results['backed_up'])} å€‹ï¼Œç§»é™¤ {len(results['removed'])} å€‹")
        return results
    
    def cleanup_duplicate_search_files(self) -> Dict[str, Any]:
        """
        æ¸…ç†é‡è¤‡çš„æœå°‹æ¸¬è©¦æª”æ¡ˆ
        
        Returns:
            æ¸…ç†çµæœ
        """
        logger.info("é–‹å§‹æ¸…ç†é‡è¤‡çš„æœå°‹æ¸¬è©¦æª”æ¡ˆ")
        
        duplicate_files = [
            "test_semantic_search.py",
            "simple_semantic_search.py",
            "investigate_real_failures.py",
            "find_failed_files.py",
            "check_failed_files.py",
            "analyze_failed_files.py",
            "simulate_embedding_failures.py"
        ]
        
        results = {
            "backed_up": [],
            "removed": [],
            "failed": []
        }
        
        for filename in duplicate_files:
            file_path = Path(filename)
            if file_path.exists():
                # å‚™ä»½æª”æ¡ˆ
                if self.backup_file(file_path):
                    results["backed_up"].append(filename)
                    
                    # ç§»é™¤æª”æ¡ˆ
                    try:
                        file_path.unlink()
                        results["removed"].append(filename)
                        logger.info(f"å·²ç§»é™¤: {filename}")
                    except Exception as e:
                        logger.error(f"ç§»é™¤å¤±æ•— {filename}: {e}")
                        results["failed"].append(filename)
        
        logger.info(f"æœå°‹æ¸¬è©¦æª”æ¡ˆæ¸…ç†å®Œæˆ: å‚™ä»½ {len(results['backed_up'])} å€‹ï¼Œç§»é™¤ {len(results['removed'])} å€‹")
        return results
    
    def cleanup_other_duplicate_files(self) -> Dict[str, Any]:
        """
        æ¸…ç†å…¶ä»–é‡è¤‡æª”æ¡ˆ
        
        Returns:
            æ¸…ç†çµæœ
        """
        logger.info("é–‹å§‹æ¸…ç†å…¶ä»–é‡è¤‡æª”æ¡ˆ")
        
        duplicate_files = [
            "standardize_stage3_data.py",
            "supplement_postgresql_fields.py",
            "rename_json_files.py",
            "cleanup_filenames.py",
            "run_vectorization.py",
            "run_all.sh",
            "start_milvus.sh"
        ]
        
        results = {
            "backed_up": [],
            "removed": [],
            "failed": []
        }
        
        for filename in duplicate_files:
            file_path = Path(filename)
            if file_path.exists():
                # å‚™ä»½æª”æ¡ˆ
                if self.backup_file(file_path):
                    results["backed_up"].append(filename)
                    
                    # ç§»é™¤æª”æ¡ˆ
                    try:
                        file_path.unlink()
                        results["removed"].append(filename)
                        logger.info(f"å·²ç§»é™¤: {filename}")
                    except Exception as e:
                        logger.error(f"ç§»é™¤å¤±æ•— {filename}: {e}")
                        results["failed"].append(filename)
        
        logger.info(f"å…¶ä»–æª”æ¡ˆæ¸…ç†å®Œæˆ: å‚™ä»½ {len(results['backed_up'])} å€‹ï¼Œç§»é™¤ {len(results['removed'])} å€‹")
        return results
    
    def run_full_cleanup(self) -> Dict[str, Any]:
        """
        åŸ·è¡Œå®Œæ•´æ¸…ç†
        
        Returns:
            å®Œæ•´æ¸…ç†çµæœ
        """
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´æ¸…ç†")
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "backup_dir": str(self.backup_dir),
            "categories": {}
        }
        
        try:
            # æ¸…ç†å„é¡åˆ¥æª”æ¡ˆ
            results["categories"]["tagging"] = self.cleanup_duplicate_tagging_files()
            results["categories"]["milvus"] = self.cleanup_duplicate_milvus_files()
            results["categories"]["embedding"] = self.cleanup_duplicate_embedding_files()
            results["categories"]["search"] = self.cleanup_duplicate_search_files()
            results["categories"]["other"] = self.cleanup_other_duplicate_files()
            
            # çµ±è¨ˆç¸½çµæœ
            total_backed_up = sum(len(cat["backed_up"]) for cat in results["categories"].values())
            total_removed = sum(len(cat["removed"]) for cat in results["categories"].values())
            total_failed = sum(len(cat["failed"]) for cat in results["categories"].values())
            
            results["summary"] = {
                "total_backed_up": total_backed_up,
                "total_removed": total_removed,
                "total_failed": total_failed
            }
            
            logger.info("ğŸ‰ å®Œæ•´æ¸…ç†åŸ·è¡Œå®Œæˆ")
            logger.info(f"ç¸½è¨ˆ: å‚™ä»½ {total_backed_up} å€‹æª”æ¡ˆï¼Œç§»é™¤ {total_removed} å€‹æª”æ¡ˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†åŸ·è¡Œå¤±æ•—: {e}")
            results["error"] = str(e)
        
        return results 