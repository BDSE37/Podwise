#!/usr/bin/env python3
"""
Podwise RAG Pipeline å›ç­”ç”Ÿæˆå™¨

å¯¦ç¾åˆ†å±¤çš„å›ç­”ç”Ÿæˆé‚è¼¯ï¼š
1. CrewAI + LangChain + LLM æª¢ç´¢ Milvus æ ¹æ“šç³»çµ±æç¤ºè©ç”Ÿæˆå›ç­”
2. default_qa_processor.py æ ¹æ“šé è¨­ Q&A æ¨¡ç³Šæ¯”å°æ–‡æœ¬ç›¸ä¼¼åº¦é«˜å°±æŒ‰ç…§é€™ä¸€ä»½å›ç­”
3. web_search_tool.py OpenAI å»æœå°‹ç”Ÿæˆå›è¦†

ä¸»è¦ç”Ÿæˆé‚è¼¯ä¾ç…§ agent_roles_config.py

ä½œè€…: Podwise Team
ç‰ˆæœ¬: 1.0.0
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import re

# å°å…¥æ‘˜è¦ç›¸é—œå·¥å…·
try:
    from tools.summary_generator import get_summary_generator
    from tools.cross_db_text_fetcher import get_cross_db_text_fetcher
    SUMMARY_TOOLS_AVAILABLE = True
except ImportError as e:
    logging.warning(f"æ‘˜è¦å·¥å…·å°å…¥å¤±æ•—: {e}")
    SUMMARY_TOOLS_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class PodcastRecommendation:
    """Podcast æ¨è–¦è³‡æ–™çµæ§‹"""
    title: str
    episode: str
    podcast_name: str
    description: str
    confidence: float
    category: str
    source: str
    rss_id: Optional[str] = None
    audio_url: Optional[str] = None
    image_url: Optional[str] = None


@dataclass
class AnswerGenerationResult:
    """å›ç­”ç”Ÿæˆçµæœ"""
    content: str
    confidence: float
    sources: List[str]
    processing_time: float
    level_used: str
    recommendations: List[PodcastRecommendation]
    metadata: Dict[str, Any]


class AnswerGenerator:
    """å›ç­”ç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 llm_manager=None,
                 default_qa_processor=None,
                 web_search_tool=None,
                 prompt_templates=None,
                 agent_roles_manager=None):
        """
        åˆå§‹åŒ–å›ç­”ç”Ÿæˆå™¨
        
        Args:
            llm_manager: LLM ç®¡ç†å™¨
            default_qa_processor: é è¨­å•ç­”è™•ç†å™¨
            web_search_tool: Web æœå°‹å·¥å…·
            prompt_templates: æç¤ºè©æ¨¡æ¿
            agent_roles_manager: ä»£ç†è§’è‰²ç®¡ç†å™¨
        """
        self.llm_manager = llm_manager
        self.default_qa_processor = default_qa_processor
        self.web_search_tool = web_search_tool
        self.prompt_templates = prompt_templates
        self.agent_roles_manager = agent_roles_manager
        
        logger.info("âœ… å›ç­”ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def generate_answer(self, 
                            query: str,
                            user_id: str,
                            search_results: List[Any] = None,
                            category: str = "å…¶ä»–",
                            user_context: Dict[str, Any] = None) -> AnswerGenerationResult:
        """
        ç”Ÿæˆå›ç­” - æŒ‰ç…§åˆ†å±¤é‚è¼¯è™•ç†
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            user_id: ç”¨æˆ¶ ID
            search_results: æœå°‹çµæœ
            category: åˆ†é¡
            user_context: ç”¨æˆ¶ä¸Šä¸‹æ–‡
            
        Returns:
            AnswerGenerationResult: å›ç­”ç”Ÿæˆçµæœ
        """
        start_time = datetime.now()
        
        try:
            # æ­¥é©Ÿ 0: æª¢æŸ¥æ˜¯å¦ç‚ºæ‘˜è¦æŸ¥è©¢
            if SUMMARY_TOOLS_AVAILABLE and self._is_summary_query(query):
                logger.info("æª¢æ¸¬åˆ°æ‘˜è¦æŸ¥è©¢ï¼Œä½¿ç”¨æ‘˜è¦ç”Ÿæˆå™¨")
                summary_result = await self._generate_summary_response(query, user_context)
                if summary_result:
                    return summary_result
            
            # æ­¥é©Ÿ 1: CrewAI + LangChain + LLM æª¢ç´¢ Milvus æ ¹æ“šç³»çµ±æç¤ºè©ç”Ÿæˆå›ç­”
            logger.info("æ­¥é©Ÿ 1: ä½¿ç”¨ CrewAI + LangChain + LLM ç”Ÿæˆå›ç­”")
            llm_result = await self._generate_with_llm_and_prompts(query, search_results or [], category, user_context or {})
            
            if llm_result and llm_result.confidence >= 0.7:
                logger.info(f"LLM ç”ŸæˆæˆåŠŸï¼Œä¿¡å¿ƒåº¦: {llm_result.confidence}")
                return llm_result
            
            # æ­¥é©Ÿ 2: æª¢æŸ¥é è¨­å•ç­”è™•ç†å™¨
            logger.info("æ­¥é©Ÿ 2: æª¢æŸ¥é è¨­å•ç­”è™•ç†å™¨")
            if self.default_qa_processor:
                qa_result = await self._generate_with_default_qa(query, user_context)
                if qa_result and qa_result.confidence >= 0.6:
                    logger.info(f"é è¨­å•ç­”åŒ¹é…æˆåŠŸï¼Œä¿¡å¿ƒåº¦: {qa_result.confidence}")
                    return qa_result
            
            # æ­¥é©Ÿ 3: ä½¿ç”¨ Web æœå°‹
            logger.info("æ­¥é©Ÿ 3: ä½¿ç”¨ Web æœå°‹")
            web_result = await self._generate_with_web_search(query, category, user_context)
            if web_result and web_result.confidence >= 0.5:
                logger.info(f"Web æœå°‹æˆåŠŸï¼Œä¿¡å¿ƒåº¦: {web_result.confidence}")
                return web_result
            
            # æ­¥é©Ÿ 4: é è¨­å›æ‡‰
            logger.info("æ­¥é©Ÿ 4: ä½¿ç”¨é è¨­å›æ‡‰")
            return await self._generate_default_response(query, user_context)
            
        except Exception as e:
            logger.error(f"å›ç­”ç”Ÿæˆå¤±æ•—: {e}")
            return AnswerGenerationResult(
                content="æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚",
                confidence=0.0,
                sources=["error"],
                processing_time=(datetime.now() - start_time).total_seconds(),
                level_used="error",
                recommendations=[],
                metadata={"error": str(e)}
            )
    
    async def _generate_with_llm_and_prompts(self, 
                                           query: str,
                                           search_results: List[Any],
                                           category: str,
                                           user_context: Dict[str, Any]) -> Optional[AnswerGenerationResult]:
        """ä½¿ç”¨ LLM å’Œæç¤ºè©æ¨¡æ¿ç”Ÿæˆå›ç­”"""
        try:
            if not self.llm_manager or not self.prompt_templates:
                return None
            
            # ç²å–å›ç­”ç”Ÿæˆæç¤ºè©æ¨¡æ¿
            try:
                from config.prompt_templates import get_prompt_template, format_prompt
                answer_template = get_prompt_template("answer_generation")
            except ImportError:
                logger.warning("ç„¡æ³•å°å…¥æç¤ºè©æ¨¡æ¿")
                return None
            
            # æ ¼å¼åŒ–æœå°‹çµæœ
            formatted_results = self._format_search_results_for_prompt(search_results)
            
            # æ ¼å¼åŒ–æç¤ºè©
            formatted_prompt = format_prompt(
                answer_template,
                leader_decision=formatted_results,
                user_question=query,
                user_context=user_context or {}
            )
            
            # ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”
            if hasattr(self.llm_manager, 'generate_text'):
                from llm.core.base_llm import GenerationRequest
                request = GenerationRequest(prompt=formatted_prompt)
                response = await self.llm_manager.generate_text(request)
                content = response.text if response else ""
            else:
                content = ""
            
            if content:
                # è§£ææ¨è–¦ç¯€ç›®
                recommendations = self._extract_recommendations_from_content(content, search_results)
                
                return AnswerGenerationResult(
                    content=content,
                    confidence=0.8,
                    sources=["llm_prompt"],
                    processing_time=0.0,
                    level_used="llm_prompt",
                    recommendations=recommendations,
                    metadata={"prompt_used": "answer_generation"}
                )
            
            return None
            
        except Exception as e:
            logger.error(f"LLM æç¤ºè©ç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _generate_with_default_qa(self, 
                                      query: str,
                                      user_context: Dict[str, Any]) -> Optional[AnswerGenerationResult]:
        """ä½¿ç”¨é è¨­å•ç­”è™•ç†å™¨ç”Ÿæˆå›ç­”"""
        try:
            if not self.default_qa_processor:
                return None
            
            # å°‹æ‰¾æœ€ä½³åŒ¹é…
            match_result = self.default_qa_processor.find_best_match(query, 0.6)
            if not match_result:
                return None
            
            qa, confidence = match_result
            
            # ä½¿ç”¨æç¤ºè©æ¨¡æ¿æ ¼å¼åŒ–å›æ‡‰
            try:
                from config.prompt_templates import get_prompt_template, format_prompt
                faq_template = get_prompt_template("faq_fallback")
                content = format_prompt(
                    faq_template,
                    user_question=query,
                    matched_faq=qa.question,
                    suggested_categories=["å•†æ¥­", "æ•™è‚²", "å…¶ä»–"]
                )
            except ImportError:
                content = qa.answer
            
            return AnswerGenerationResult(
                content=content,
                confidence=confidence,
                sources=["default_qa"],
                processing_time=0.0,
                level_used="default_qa",
                recommendations=[],
                metadata={"category": qa.category, "tags": qa.tags}
            )
            
        except Exception as e:
            logger.error(f"é è¨­å•ç­”ç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _generate_with_web_search(self, 
                                      query: str,
                                      category: str,
                                      user_context: Dict[str, Any]) -> Optional[AnswerGenerationResult]:
        """ä½¿ç”¨ Web æœå°‹ç”Ÿæˆå›ç­”"""
        try:
            if not self.web_search_tool:
                return None
            
            from tools.web_search_tool import SearchRequest
            search_request = SearchRequest(
                query=f"{query} podcast æ¨è–¦",
                max_results=3,
                language="zh-TW"
            )
            
            web_results = await self.web_search_tool.search(search_request)
            
            if hasattr(web_results, 'results') and web_results.results:
                content = self._format_web_results_for_answer(web_results.results, query)
                confidence = getattr(web_results, 'confidence', 0.6)
                
                return AnswerGenerationResult(
                    content=content,
                    confidence=confidence,
                    sources=["web_search"],
                    processing_time=0.0,
                    level_used="web_search",
                    recommendations=[],
                    metadata={"results_count": len(web_results.results)}
                )
            
            return None
            
        except Exception as e:
            logger.error(f"Web æœå°‹ç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _generate_default_response(self, 
                                       query: str,
                                       user_context: Dict[str, Any]) -> AnswerGenerationResult:
        """ç”Ÿæˆé è¨­å›æ‡‰"""
        try:
            # ä½¿ç”¨é è¨­å›æ‡‰æç¤ºè©
            try:
                from config.prompt_templates import get_prompt_template, format_prompt
                default_template = get_prompt_template("default_fallback")
                content = format_prompt(default_template, user_question=query)
            except ImportError:
                content = "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•æ‰¾åˆ°ç›¸é—œçš„è³‡è¨Šã€‚è«‹å˜—è©¦é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚"
            
            return AnswerGenerationResult(
                content=content,
                confidence=0.0,
                sources=["default"],
                processing_time=0.0,
                level_used="default",
                recommendations=[],
                metadata={"fallback": True}
            )
            
        except Exception as e:
            logger.error(f"é è¨­å›æ‡‰ç”Ÿæˆå¤±æ•—: {e}")
            return AnswerGenerationResult(
                content="æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚",
                confidence=0.0,
                sources=["error"],
                processing_time=0.0,
                level_used="error",
                recommendations=[],
                metadata={"error": str(e)}
            )
    
    def _format_search_results_for_prompt(self, search_results: List[Any]) -> str:
        """æ ¼å¼åŒ–æœå°‹çµæœç”¨æ–¼æç¤ºè©"""
        if not search_results:
            return "ç„¡ç›¸é—œæœå°‹çµæœ"
        
        formatted_results = []
        for i, result in enumerate(search_results[:3], 1):
            if hasattr(result, 'content'):
                content = result.content
                if hasattr(result, 'episode_title') and result.episode_title:
                    content = f"{result.episode_title}: {content}"
                formatted_results.append(f"{i}. {content}")
        
        return "\n".join(formatted_results)
    
    def _extract_recommendations_from_content(self, content: str, search_results: List[Any]) -> List[PodcastRecommendation]:
        """å¾å…§å®¹ä¸­æå–æ¨è–¦ç¯€ç›®"""
        recommendations = []
        
        # å¾æœå°‹çµæœä¸­æå–
        if search_results:
            for result in search_results[:3]:
                if hasattr(result, 'content'):
                    recommendation = PodcastRecommendation(
                        title=getattr(result, 'episode_title', 'æœªçŸ¥æ¨™é¡Œ'),
                        episode=getattr(result, 'episode', ''),
                        podcast_name=getattr(result, 'podcast_name', 'æœªçŸ¥é »é“'),
                        description=result.content[:100] + "..." if len(result.content) > 100 else result.content,
                        confidence=getattr(result, 'confidence', 0.7),
                        category=getattr(result, 'category', 'å…¶ä»–'),
                        source="vector_search",
                        rss_id=getattr(result, 'rss_id', None),
                        audio_url=getattr(result, 'audio_url', None),
                        image_url=getattr(result, 'image_url', None)
                    )
                    recommendations.append(recommendation)
        
        return recommendations
    
    def _format_web_results_for_answer(self, web_results: List[Any], query: str) -> str:
        """æ ¼å¼åŒ– Web æœå°‹çµæœç‚ºå›ç­”"""
        if not web_results:
            return "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•æ‰¾åˆ°ç›¸é—œçš„è³‡è¨Šã€‚"
        
        # æ ¹æ“šæŸ¥è©¢é¡å‹ç”Ÿæˆä¸åŒæ ¼å¼çš„å›ç­”
        if "æ¨è–¦" in query or "podcast" in query.lower():
            # æ¨è–¦æ ¼å¼
            content = f"æ ¹æ“šæ‚¨çš„æŸ¥è©¢ã€Œ{query}ã€ï¼Œæˆ‘ç‚ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹ç›¸é—œè³‡è¨Šï¼š\n\n"
            
            for i, result in enumerate(web_results[:3], 1):
                title = getattr(result, 'title', 'æœªçŸ¥æ¨™é¡Œ')
                snippet = getattr(result, 'snippet', '')
                
                content += f"{i}. {title}\n"
                if snippet:
                    content += f"   {snippet[:80]}...\n"
                content += "\n"
            
            content += "ğŸ’¡ å»ºè­°æ‚¨å¯ä»¥é€²ä¸€æ­¥æè¿°æ‚¨çš„å…·é«”éœ€æ±‚ï¼Œæˆ‘å¯ä»¥ç‚ºæ‚¨æä¾›æ›´ç²¾æº–çš„æ¨è–¦ï¼"
        else:
            # ä¸€èˆ¬è³‡è¨Šæ ¼å¼
            content = "æˆ‘ç‚ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹ç›¸é—œè³‡è¨Šï¼š\n\n"
            
            for i, result in enumerate(web_results[:2], 1):
                title = getattr(result, 'title', 'æœªçŸ¥æ¨™é¡Œ')
                snippet = getattr(result, 'snippet', '')
                
                content += f"{i}. {title}\n"
                if snippet:
                    content += f"   {snippet}\n\n"
        
        return content
    
    def ensure_different_channels(self, recommendations: List[PodcastRecommendation]) -> List[PodcastRecommendation]:
        """ç¢ºä¿æ¨è–¦çš„ç¯€ç›®ä¾†è‡ªä¸åŒé »é“"""
        if not recommendations:
            return recommendations
        
        # æŒ‰ä¿¡å¿ƒåº¦æ’åº
        sorted_recommendations = sorted(recommendations, key=lambda x: x.confidence, reverse=True)
        
        # ç¢ºä¿ä¸åŒé »é“
        unique_channels = set()
        final_recommendations = []
        
        for rec in sorted_recommendations:
            if rec.podcast_name not in unique_channels:
                unique_channels.add(rec.podcast_name)
                final_recommendations.append(rec)
                
                # æœ€å¤šæ¨è–¦ 3 å€‹ä¸åŒé »é“çš„ç¯€ç›®
                if len(final_recommendations) >= 3:
                    break
        
        return final_recommendations
    
    def format_recommendations_for_display(self, recommendations: List[PodcastRecommendation]) -> str:
        """æ ¼å¼åŒ–æ¨è–¦ç¯€ç›®ç”¨æ–¼é¡¯ç¤º"""
        if not recommendations:
            return ""
        
        # ç¢ºä¿ä¸åŒé »é“
        unique_recommendations = self.ensure_different_channels(recommendations)
        
        content = ""
        for i, rec in enumerate(unique_recommendations, 1):
            content += f"{i}. ã€Š{rec.podcast_name}ã€‹ï¼š{rec.title}\n"
            if rec.description:
                content += f"   {rec.description}\n"
            content += f"   â­ ä¿¡å¿ƒåº¦ï¼š{rec.confidence:.1f}\n\n"
        
        return content
    
    def _is_summary_query(self, query: str) -> bool:
        """
        æª¢æ¸¬æ˜¯å¦ç‚ºæ‘˜è¦æŸ¥è©¢
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            bool: æ˜¯å¦ç‚ºæ‘˜è¦æŸ¥è©¢
        """
        # æª¢æ¸¬æ‘˜è¦ç›¸é—œé—œéµè©
        summary_keywords = ['æ‘˜è¦', 'summary', 'ç¸½çµ', 'æ¦‚è¦', 'é‡é»']
        episode_patterns = [r'EP\d+', r'ep\d+', r'ç¬¬\d+é›†', r'é›†æ•¸']
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ‘˜è¦é—œéµè©
        has_summary_keyword = any(keyword in query for keyword in summary_keywords)
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«é›†æ•¸æ¨¡å¼
        has_episode_pattern = any(re.search(pattern, query) for pattern in episode_patterns)
        
        return has_summary_keyword and has_episode_pattern
    
    async def _generate_summary_response(self, query: str, user_context: Dict[str, Any]) -> Optional[AnswerGenerationResult]:
        """
        ç”Ÿæˆæ‘˜è¦å›æ‡‰
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            user_context: ç”¨æˆ¶ä¸Šä¸‹æ–‡
            
        Returns:
            Optional[AnswerGenerationResult]: æ‘˜è¦å›æ‡‰çµæœ
        """
        try:
            # è§£ææŸ¥è©¢ä¸­çš„ podcast å’Œ episode è³‡è¨Š
            podcast_name, episode_tag = self._extract_podcast_episode_info(query)
            
            if not podcast_name or not episode_tag:
                logger.warning(f"ç„¡æ³•è§£æ podcast å’Œ episode è³‡è¨Š: {query}")
                return None
            
            # ç²å–æ–‡æœ¬æ“·å–å™¨
            text_fetcher = get_cross_db_text_fetcher()
            await text_fetcher.connect_databases()
            
            # æ“·å–é•·æ–‡æœ¬
            fetch_result = await text_fetcher.fetch_text(podcast_name, episode_tag)
            
            if not fetch_result.success:
                logger.warning(f"æ–‡æœ¬æ“·å–å¤±æ•—: {fetch_result.error_message}")
                return AnswerGenerationResult(
                    content=f"æŠ±æ­‰ï¼Œç„¡æ³•æ‰¾åˆ°ã€Œ{podcast_name} {episode_tag}ã€çš„ç›¸é—œå…§å®¹ã€‚è«‹ç¢ºèªç¯€ç›®åç¨±å’Œé›†æ•¸æ˜¯å¦æ­£ç¢ºã€‚",
                    confidence=0.0,
                    sources=["text_fetch_error"],
                    processing_time=fetch_result.processing_time,
                    level_used="summary_error",
                    recommendations=[],
                    metadata={"error": fetch_result.error_message}
                )
            
            # ç²å–æ‘˜è¦ç”Ÿæˆå™¨
            summary_generator = get_summary_generator()
            
            # ç”Ÿæˆæ‘˜è¦
            summary_result = await summary_generator.generate_summary(fetch_result.text, max_words=150)
            
            if not summary_result.success:
                logger.warning(f"æ‘˜è¦ç”Ÿæˆå¤±æ•—: {summary_result.error_message}")
                return AnswerGenerationResult(
                    content=f"æŠ±æ­‰ï¼Œç”Ÿæˆã€Œ{podcast_name} {episode_tag}ã€æ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚",
                    confidence=0.0,
                    sources=["summary_error"],
                    processing_time=summary_result.processing_time,
                    level_used="summary_error",
                    recommendations=[],
                    metadata={"error": summary_result.error_message}
                )
            
            # æ§‹å»ºå›æ‡‰å…§å®¹
            content = f"ğŸ“ **{podcast_name} {episode_tag} æ‘˜è¦**\n\n"
            content += f"{summary_result.summary}\n\n"
            content += f"ğŸ’¡ æ‘˜è¦å­—æ•¸ï¼š{summary_result.word_count} å­—"
            
            return AnswerGenerationResult(
                content=content,
                confidence=0.9,
                sources=["mongodb_text", "summary_generator"],
                processing_time=fetch_result.processing_time + summary_result.processing_time,
                level_used="summary_generation",
                recommendations=[],
                metadata={
                    "podcast_name": podcast_name,
                    "episode_tag": episode_tag,
                    "summary_quality": summary_result.quality_score,
                    "original_text_length": len(fetch_result.text)
                }
            )
            
        except Exception as e:
            logger.error(f"æ‘˜è¦å›æ‡‰ç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    def _extract_podcast_episode_info(self, query: str) -> Tuple[Optional[str], Optional[str]]:
        """
        å¾æŸ¥è©¢ä¸­æå– podcast åç¨±å’Œ episode æ¨™ç±¤
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            Tuple[Optional[str], Optional[str]]: (podcast_name, episode_tag)
        """
        try:
            # ç§»é™¤æ‘˜è¦ç›¸é—œé—œéµè©
            cleaned_query = query
            summary_keywords = ['æ‘˜è¦', 'summary', 'ç¸½çµ', 'æ¦‚è¦', 'é‡é»', 'æˆ‘æƒ³çŸ¥é“']
            for keyword in summary_keywords:
                cleaned_query = cleaned_query.replace(keyword, '').strip()
            
            # å°‹æ‰¾ EP æ¨¡å¼ - æ›´å¯¬é¬†çš„åŒ¹é…
            ep_patterns = [
                r'([^E]*?)(EP\d+)',  # æ¨™æº– EP æ¨¡å¼
                r'([^e]*?)(ep\d+)',  # å°å¯« ep æ¨¡å¼
                r'([^é›†]*?)(EP\d+)',  # åŒ…å«ã€Œé›†ã€å­—çš„æ¨¡å¼
                r'([^é›†]*?)(ep\d+)',  # åŒ…å«ã€Œé›†ã€å­—çš„å°å¯«æ¨¡å¼
            ]
            
            for pattern in ep_patterns:
                match = re.search(pattern, cleaned_query, re.IGNORECASE)
                if match:
                    podcast_name = match.group(1).strip()
                    episode_tag = match.group(2).upper()  # çµ±ä¸€ç‚ºå¤§å¯«
                    
                    # æ¸…ç† podcast_nameï¼Œç§»é™¤å¤šé¤˜çš„è©å½™
                    podcast_name = re.sub(r'[é›†æ‘˜è¦ç¸½çµæ¦‚è¦é‡é»]', '', podcast_name).strip()
                    
                    if podcast_name and episode_tag:
                        logger.info(f"è§£æçµæœ: podcast_name='{podcast_name}', episode_tag='{episode_tag}'")
                        return podcast_name, episode_tag
            
            # å°‹æ‰¾å…¶ä»–é›†æ•¸æ¨¡å¼
            episode_patterns = [
                r'([^ç¬¬]*?)(ç¬¬\d+é›†)',
                r'([^é›†]*?)(\d+é›†)',
            ]
            
            for pattern in episode_patterns:
                match = re.search(pattern, cleaned_query)
                if match:
                    podcast_name = match.group(1).strip()
                    episode_tag = match.group(2)
                    
                    # æ¸…ç† podcast_name
                    podcast_name = re.sub(r'[æ‘˜è¦ç¸½çµæ¦‚è¦é‡é»]', '', podcast_name).strip()
                    
                    if podcast_name and episode_tag:
                        logger.info(f"è§£æçµæœ: podcast_name='{podcast_name}', episode_tag='{episode_tag}'")
                        return podcast_name, episode_tag
            
            logger.warning(f"ç„¡æ³•è§£æ podcast å’Œ episode è³‡è¨Š: {query}")
            return None, None
            
        except Exception as e:
            logger.error(f"æå– podcast å’Œ episode è³‡è¨Šå¤±æ•—: {e}")
            return None, None


def create_answer_generator(llm_manager=None,
                           default_qa_processor=None,
                           web_search_tool=None,
                           prompt_templates=None,
                           agent_roles_manager=None) -> AnswerGenerator:
    """å‰µå»ºå›ç­”ç”Ÿæˆå™¨å¯¦ä¾‹"""
    return AnswerGenerator(
        llm_manager=llm_manager,
        default_qa_processor=default_qa_processor,
        web_search_tool=web_search_tool,
        prompt_templates=prompt_templates,
        agent_roles_manager=agent_roles_manager
    ) 