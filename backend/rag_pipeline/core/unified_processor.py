"""
çµ±ä¸€å…§å®¹è™•ç†å™¨ - é‡æ§‹ç‰ˆæœ¬
æ•´åˆæ‰€æœ‰å…§å®¹è™•ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ–‡æª”è™•ç†ã€MongoDB æ–‡æœ¬è™•ç†å’Œå…§å®¹åˆ†é¡
"""

import re
import json
import logging
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime
from pathlib import Path
import numpy as np
from pymongo import MongoClient
from pymilvus import connections, Collection, utility
from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM
import torch

# å°å…¥åˆ†é›¢çš„æ¨¡çµ„
from .content_models import ContentCategory, ContentMetadata, ContentSummary, ParagraphMetadata
from .content_categorizer import ContentCategorizer
from .content_summarizer import ContentSummarizer

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class UnifiedContentProcessor:
    """
    çµ±ä¸€å…§å®¹è™•ç†å™¨ - é‡æ§‹ç‰ˆæœ¬
    
    æ•´åˆåŠŸèƒ½ï¼š
    - æ–‡æª”è™•ç†å’Œçµæ§‹åŒ–
    - MongoDB é•·æ–‡æœ¬è™•ç†
    - å…§å®¹åˆ†é¡å’Œæ¨™ç±¤ç”Ÿæˆ
    - å‘é‡åŒ–å’Œå­˜å„²
    - æ‘˜è¦ç”Ÿæˆ
    """
    
    def __init__(
        self,
        data_dir: Optional[str] = None,
        mongodb_uri: str = "mongodb://bdse37:111111@worker3:30017/",
        mongodb_db: str = "podcast",
        mongodb_collection: str = "transcripts",
        milvus_host: str = "192.168.32.86",
        milvus_port: int = 19530,
        milvus_collection_name: str = "podwise_documents",
        qwen_model_name: str = "Qwen/Qwen2.5-7B-Instruct",
        embedding_model_name: str = "BAAI/bge-m3",
        max_tags_per_chunk: int = 10,
        enable_mongodb: bool = True,
        enable_milvus: bool = True
    ):
        """
        åˆå§‹åŒ–çµ±ä¸€å…§å®¹è™•ç†å™¨
        
        Args:
            data_dir: æœ¬åœ°è³‡æ–™ç›®éŒ„è·¯å¾‘
            mongodb_uri: MongoDB é€£æ¥å­—ä¸²
            mongodb_db: MongoDB è³‡æ–™åº«åç¨±
            mongodb_collection: MongoDB é›†åˆåç¨±
            milvus_host: Milvus ä¸»æ©Ÿåœ°å€
            milvus_port: Milvus ç«¯å£
            milvus_collection_name: Milvus é›†åˆåç¨±
            qwen_model_name: Qwen æ¨¡å‹åç¨±
            embedding_model_name: åµŒå…¥æ¨¡å‹åç¨±
            max_tags_per_chunk: æ¯å€‹æ–‡æœ¬å¡Šçš„æœ€å¤§æ¨™ç±¤æ•¸é‡
            enable_mongodb: æ˜¯å¦å•Ÿç”¨ MongoDB åŠŸèƒ½
            enable_milvus: æ˜¯å¦å•Ÿç”¨ Milvus åŠŸèƒ½
        """
        self.data_dir = Path(data_dir) if data_dir else None
        self.mongodb_uri = mongodb_uri
        self.mongodb_db = mongodb_db
        self.mongodb_collection = mongodb_collection
        self.milvus_host = milvus_host
        self.milvus_port = milvus_port
        self.milvus_collection_name = milvus_collection_name
        self.qwen_model_name = qwen_model_name
        self.embedding_model_name = embedding_model_name
        self.max_tags_per_chunk = max_tags_per_chunk
        
        # åˆå§‹åŒ–åˆ†é›¢çš„çµ„ä»¶
        self.categorizer = ContentCategorizer()
        self.summarizer = ContentSummarizer()
        
        # åˆå§‹åŒ–é€£æ¥å’Œæ¨¡å‹
        if enable_mongodb:
            self._init_mongodb()
        if enable_milvus:
            self._init_milvus()
        if enable_mongodb or enable_milvus:
            self._init_models()
            
    def _init_mongodb(self):
        """åˆå§‹åŒ– MongoDB é€£æ¥"""
        try:
            logger.info(f"ğŸ”— é€£æ¥åˆ° MongoDB: {self.mongodb_uri}")
            self.mongo_client = MongoClient(self.mongodb_uri)
            self.mongo_db = self.mongo_client[self.mongodb_db]
            self.mongo_collection = self.mongo_db[self.mongodb_collection]
            
            # æ¸¬è©¦é€£æ¥
            self.mongo_client.admin.command('ping')
            logger.info(f"âœ… æˆåŠŸé€£æ¥åˆ° MongoDB: {self.mongodb_db}.{self.mongodb_collection}")
        except Exception as e:
            logger.error(f"âŒ MongoDB é€£æ¥å¤±æ•—: {str(e)}")
            raise
            
    def _init_milvus(self):
        """åˆå§‹åŒ– Milvus é€£æ¥"""
        try:
            logger.info(f"ğŸ”— é€£æ¥åˆ° Milvus: {self.milvus_host}:{self.milvus_port}")
            connections.connect(
                alias="default",
                host=self.milvus_host,
                port=self.milvus_port
            )
            
            # æª¢æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å‰‡å‰µå»º
            if not utility.has_collection(self.milvus_collection_name):
                logger.info(f"ğŸ“ å‰µå»º Milvus é›†åˆ: {self.milvus_collection_name}")
                self._create_milvus_collection()
            else:
                logger.info(f"ğŸ“– è¼‰å…¥ç¾æœ‰ Milvus é›†åˆ: {self.milvus_collection_name}")
                self.milvus_collection = Collection(self.milvus_collection_name)
                self.milvus_collection.load()
                
            logger.info(f"âœ… æˆåŠŸé€£æ¥åˆ° Milvus: {self.milvus_collection_name}")
        except Exception as e:
            logger.error(f"âŒ Milvus é€£æ¥å¤±æ•—: {str(e)}")
            raise
            
    def _create_milvus_collection(self):
        """å‰µå»º Milvus é›†åˆ (ç¬¦åˆ podcast è³‡æ–™æ ¼å¼ï¼Œæ”¯æŒå¤šå€‹æ¨™ç±¤)"""
        from pymilvus import FieldSchema, CollectionSchema, DataType
        
        # æ ¹æ“šæ‚¨æŒ‡å®šçš„æ¬„ä½æ ¼å¼å‰µå»ºï¼Œæ”¯æŒæ›´å¤šæ¨™ç±¤
        fields = [
            FieldSchema(name="chunk_id", dtype=DataType.VARCHAR, max_length=64, is_primary=True),
            FieldSchema(name="chunk_index", dtype=DataType.INT64),
            FieldSchema(name="episode_id", dtype=DataType.INT64),
            FieldSchema(name="podcast_id", dtype=DataType.INT64),
            FieldSchema(name="episode_title", dtype=DataType.VARCHAR, max_length=255),
            FieldSchema(name="chunk_text", dtype=DataType.VARCHAR, max_length=1024),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1024),  # BGE-M3 ç¶­åº¦
            FieldSchema(name="language", dtype=DataType.VARCHAR, max_length=16),
            FieldSchema(name="created_at", dtype=DataType.VARCHAR, max_length=64),  # TIMESTAMP ç”¨ VARCHAR è¡¨ç¤º
            FieldSchema(name="source_model", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="podcast_name", dtype=DataType.VARCHAR, max_length=255),
            FieldSchema(name="author", dtype=DataType.VARCHAR, max_length=255),
            FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=64),
            # æ”¯æŒæ›´å¤šæ¨™ç±¤æ¬„ä½
            FieldSchema(name="tag_1", dtype=DataType.VARCHAR, max_length=1024),
            FieldSchema(name="tag_2", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_3", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_4", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_5", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_6", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_7", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_8", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_9", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="tag_10", dtype=DataType.VARCHAR, max_length=64)
        ]
        
        schema = CollectionSchema(fields, description="Podwise æ–‡æª”å‘é‡é›†åˆ")
        self.milvus_collection = Collection(self.milvus_collection_name, schema)
        
        # å‰µå»ºç´¢å¼•
        index_params = {
            "metric_type": "COSINE",
            "index_type": "IVF_FLAT",
            "params": {"nlist": 1024}
        }
        self.milvus_collection.create_index("embedding", index_params)
        self.milvus_collection.load()
        logger.info(f"âœ… æˆåŠŸå‰µå»º Milvus é›†åˆå’Œç´¢å¼•: {self.milvus_collection_name}")
        
    def _init_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            logger.info(f"ğŸ¤– è¼‰å…¥ Qwen æ¨¡å‹: {self.qwen_model_name}")
            self.qwen_tokenizer = AutoTokenizer.from_pretrained(self.qwen_model_name)
            self.qwen_model = AutoModelForCausalLM.from_pretrained(
                self.qwen_model_name,
                torch_dtype=torch.float16,
                device_map="auto"
            )
            
            logger.info(f"ğŸ”¤ è¼‰å…¥åµŒå…¥æ¨¡å‹: {self.embedding_model_name}")
            self.embedding_tokenizer = AutoTokenizer.from_pretrained(self.embedding_model_name)
            self.embedding_model = AutoModel.from_pretrained(
                self.embedding_model_name,
                torch_dtype=torch.float16,
                device_map="auto"
            )
            
            logger.info("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
            raise
            
    def process_document(
        self,
        content: str,
        metadata: Dict[str, Any],
        split_paragraphs: bool = True,
        generate_summary: bool = True
    ) -> Dict[str, Any]:
        """
        è™•ç†æ–‡æª”å…§å®¹
        
        Args:
            content: æ–‡æª”å…§å®¹
            metadata: æ–‡æª”å…ƒæ•¸æ“š
            split_paragraphs: æ˜¯å¦åˆ†å‰²æ®µè½
            generate_summary: æ˜¯å¦ç”Ÿæˆæ‘˜è¦
            
        Returns:
            Dict[str, Any]: è™•ç†çµæœ
        """
        try:
            # ä½¿ç”¨åˆ†é¡å™¨é€²è¡Œå…§å®¹åˆ†é¡
            category = self.categorizer.categorize_content(
                metadata.get("title", ""), 
                content
            )
            
            # ç”Ÿæˆæ‘˜è¦
            summary = None
            if generate_summary:
                summary = self.summarizer.generate_summary(content, category)
            
            # åˆ†å‰²æ®µè½
            paragraphs = []
            if split_paragraphs:
                paragraphs = self._split_paragraphs(content)
            
            # ç”Ÿæˆæ¨™ç±¤
            tags = self.generate_tags_with_qwen(content)
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = self.generate_embedding(content)
            
            return {
                "category": category,
                "summary": summary,
                "paragraphs": paragraphs,
                "tags": tags,
                "embedding": embedding,
                "metadata": metadata
            }
        except Exception as e:
            logger.error(f"âŒ æ–‡æª”è™•ç†å¤±æ•—: {str(e)}")
            raise
            
    def _split_paragraphs(self, content: str) -> List[str]:
        """åˆ†å‰²æ®µè½"""
        # ä½¿ç”¨å¤šç¨®åˆ†éš”ç¬¦åˆ†å‰²æ®µè½
        paragraphs = re.split(r'\n\s*\n|\r\n\s*\r\n', content)
        return [p.strip() for p in paragraphs if p.strip()]
        
    def generate_tags_with_qwen(self, text: str) -> List[str]:
        """ä½¿ç”¨ Qwen ç”Ÿæˆæ¨™ç±¤"""
        try:
            # ç°¡åŒ–çš„æ¨™ç±¤ç”Ÿæˆé‚è¼¯
            # é€™è£¡å¯ä»¥æ•´åˆæ›´è¤‡é›œçš„ LLM èª¿ç”¨
            words = text.split()
            # ç°¡å–®çš„é—œéµè©æå–
            tags = [word for word in words if len(word) > 2][:self.max_tags_per_chunk]
            return tags[:self.max_tags_per_chunk]
        except Exception as e:
            logger.error(f"âŒ æ¨™ç±¤ç”Ÿæˆå¤±æ•—: {str(e)}")
            return []
        
    def generate_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡"""
        try:
            inputs = self.embedding_tokenizer(
                text,
                return_tensors="pt", 
                max_length=512,
                truncation=True,
                padding=True
            )
            
            with torch.no_grad():
                outputs = self.embedding_model(**inputs)
                # ä½¿ç”¨å¹³å‡æ± åŒ–
                embeddings = outputs.last_hidden_state.mean(dim=1)
                return embeddings[0].cpu().numpy().tolist()
        except Exception as e:
            logger.error(f"âŒ åµŒå…¥ç”Ÿæˆå¤±æ•—: {str(e)}")
            return []
            
    def process_mongodb_documents(self, batch_size: int = 100):
        """è™•ç† MongoDB ä¸­çš„æ–‡æª”"""
        try:
            cursor = self.mongo_collection.find({}).batch_size(batch_size)
            
            for i, doc in enumerate(cursor):
                    try:
                        # æå–æ–‡æœ¬å…§å®¹
                        text = doc.get("transcript", "")
                        if not text:
                            continue
                            
                    # è™•ç†æ–‡æª”
                    result = self.process_document(
                        content=text,
                        metadata={
                            "episode_id": doc.get("episode_id"),
                            "podcast_id": doc.get("podcast_id"),
                            "title": doc.get("title", ""),
                            "author": doc.get("author", ""),
                            "source": "mongodb"
                        }
                    )
                    
                    # å­˜å„²åˆ° Milvus
                    if result["embedding"]:
                        self._insert_to_milvus(
                            text=text,
                            tags=result["tags"],
                            embedding=result["embedding"],
                            metadata=result["metadata"]
                        )
                    
                    if (i + 1) % 100 == 0:
                        logger.info(f"ğŸ“Š å·²è™•ç† {i + 1} å€‹æ–‡æª”")
                        
                    except Exception as e:
                    logger.error(f"âŒ è™•ç†æ–‡æª”å¤±æ•—: {str(e)}")
                        continue
            
        except Exception as e:
            logger.error(f"âŒ MongoDB æ–‡æª”è™•ç†å¤±æ•—: {str(e)}")
            raise
            
    def _insert_to_milvus(self, text: str, tags: List[str], embedding: List[float], metadata: Dict[str, Any]):
        """æ’å…¥æ•¸æ“šåˆ° Milvus"""
        try:
            # æº–å‚™æ¨™ç±¤æ•¸æ“š
            tag_data = tags + [""] * (10 - len(tags))  # ç¢ºä¿æœ‰10å€‹æ¨™ç±¤æ¬„ä½
            
            data = [
                [f"chunk_{metadata.get('episode_id', 0)}_{len(text)}"],  # chunk_id
                [0],  # chunk_index
                [metadata.get("episode_id", 0)],  # episode_id
                [metadata.get("podcast_id", 0)],  # podcast_id
                [metadata.get("title", "")],  # episode_title
                [text[:1024]],  # chunk_text (é™åˆ¶é•·åº¦)
                [embedding],  # embedding
                ["zh"],  # language
                [datetime.now().isoformat()],  # created_at
                [self.embedding_model_name],  # source_model
                [metadata.get("podcast_name", "")],  # podcast_name
                [metadata.get("author", "")],  # author
                [metadata.get("category", "")],  # category
                [tag_data[0]],  # tag_1
                [tag_data[1]],  # tag_2
                [tag_data[2]],  # tag_3
                [tag_data[3]],  # tag_4
                [tag_data[4]],  # tag_5
                [tag_data[5]],  # tag_6
                [tag_data[6]],  # tag_7
                [tag_data[7]],  # tag_8
                [tag_data[8]],  # tag_9
                [tag_data[9]]   # tag_10
            ]
            
            self.milvus_collection.insert(data)
            logger.debug(f"âœ… æˆåŠŸæ’å…¥æ•¸æ“šåˆ° Milvus")
            
        except Exception as e:
            logger.error(f"âŒ Milvus æ’å…¥å¤±æ•—: {str(e)}")
            
    def search_similar_texts(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æœå°‹ç›¸ä¼¼æ–‡æœ¬"""
        try:
            # ç”ŸæˆæŸ¥è©¢åµŒå…¥
            query_embedding = self.generate_embedding(query)
            if not query_embedding:
                return []
            
            # æœå°‹ç›¸ä¼¼å‘é‡
            search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}
            results = self.milvus_collection.search(
                data=[query_embedding],
                anns_field="embedding",
                param=search_params,
                limit=top_k,
                output_fields=["chunk_text", "episode_title", "author", "category"]
            )
            
            # æ ¼å¼åŒ–çµæœ
            formatted_results = []
            for hits in results:
                for hit in hits:
                    formatted_results.append({
                        "score": hit.score,
                        "text": hit.entity.get("chunk_text", ""),
                        "title": hit.entity.get("episode_title", ""),
                        "author": hit.entity.get("author", ""),
                        "category": hit.entity.get("category", "")
                    })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ ç›¸ä¼¼æ–‡æœ¬æœå°‹å¤±æ•—: {str(e)}")
            return []
            
    def close(self):
        """é—œé–‰é€£æ¥"""
        try:
            if hasattr(self, 'mongo_client'):
                self.mongo_client.close()
            if hasattr(self, 'milvus_collection'):
                self.milvus_collection.release()
            logger.info("âœ… é€£æ¥å·²é—œé–‰")
        except Exception as e:
            logger.error(f"âŒ é—œé–‰é€£æ¥å¤±æ•—: {str(e)}")