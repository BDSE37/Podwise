#!/usr/bin/env python3
"""
Podwise RAG Pipeline - å®‰å…¨å·¥å…·ä½¿ç”¨ç¯„ä¾‹

å±•ç¤ºå¦‚ä½•åœ¨ FastAPIã€LangChainã€CrewAI ä¸­æ•´åˆ Guardrails AI å®‰å…¨é©—è­‰
åŒ…å«å¯¦éš›çš„ä½¿ç”¨å ´æ™¯å’Œæœ€ä½³å¯¦è¸

ä½œè€…: Podwise Team
ç‰ˆæœ¬: 1.0.0
"""

import asyncio
from typing import Dict, Any, List
from fastapi import FastAPI, HTTPException, Depends
from fastapi.responses import JSONResponse
import logging

# å°å…¥å®‰å…¨å·¥å…·
from security_tool import (
    SecurityTool, SecurityConfig, SecurityLevel,
    security_check, async_security_check,
    create_security_tool, create_fastapi_middleware,
    create_langchain_validator, create_crewai_validator
)

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ===== FastAPI æ•´åˆç¯„ä¾‹ =====

def create_fastapi_app_with_security():
    """å‰µå»ºæ•´åˆå®‰å…¨é©—è­‰çš„ FastAPI æ‡‰ç”¨"""
    
    app = FastAPI(
        title="Podwise RAG Pipeline with Security",
        description="æ•´åˆ Guardrails AI å®‰å…¨é©—è­‰çš„ RAG Pipeline",
        version="1.0.0"
    )
    
    # å‰µå»ºå®‰å…¨å·¥å…·
    security_tool = create_security_tool(
        security_level=SecurityLevel.HIGH,
        blocked_keywords=["æƒ¡æ„", "æ”»æ“Š", "ç—…æ¯’", "é§­å®¢"],
        custom_patterns=[
            r"<script>.*</script>",
            r"javascript:",
            r"on\w+\s*=",
            r"eval\s*\(",
            r"document\.cookie"
        ]
    )
    
    # å‰µå»ºå®‰å…¨ä¸­é–“ä»¶
    security_middleware = create_fastapi_middleware(
        security_level=SecurityLevel.HIGH
    )
    
    # æ·»åŠ ä¸­é–“ä»¶
    app.middleware("http")(security_middleware)
    
    @app.post("/chat")
    @security_check(security_level=SecurityLevel.HIGH, raise_on_violation=True)
    async def chat_endpoint(message: str):
        """èŠå¤©ç«¯é» - ä½¿ç”¨å®‰å…¨æª¢æŸ¥è£é£¾å™¨"""
        try:
            # é€™è£¡æ˜¯æ‚¨çš„ RAG Pipeline é‚è¼¯
            response = f"æ”¶åˆ°å®‰å…¨çš„æ¶ˆæ¯: {message}"
            return {"response": response, "status": "success"}
        except Exception as e:
            raise HTTPException(status_code=400, detail=str(e))
    
    @app.post("/process-content")
    async def process_content_endpoint(content: str):
        """å…§å®¹è™•ç†ç«¯é» - æ‰‹å‹•å®‰å…¨æª¢æŸ¥"""
        # æ‰‹å‹•é©—è­‰å…§å®¹
        result = security_tool.validate_content(content)
        
        if not result.is_valid:
            return JSONResponse(
                status_code=400,
                content={
                    "error": "å®‰å…¨é©—è­‰å¤±æ•—",
                    "violations": result.violations,
                    "message": "å…§å®¹åŒ…å«ä¸å®‰å…¨çš„å…ƒç´ "
                }
            )
        
        # è™•ç†å®‰å…¨å…§å®¹
        processed_content = f"å·²è™•ç†å®‰å…¨å…§å®¹: {content}"
        return {"processed_content": processed_content, "status": "success"}
    
    @app.get("/security/stats")
    async def get_security_stats():
        """ç²å–å®‰å…¨é©—è­‰çµ±è¨ˆè³‡è¨Š"""
        stats = security_tool.get_stats()
        return {"security_stats": stats}
    
    return app


# ===== LangChain æ•´åˆç¯„ä¾‹ =====

class SecureLangChainProcessor:
    """æ•´åˆå®‰å…¨é©—è­‰çš„ LangChain è™•ç†å™¨"""
    
    def __init__(self):
        self.security_validator = create_langchain_validator(
            security_level=SecurityLevel.MEDIUM
        )
        self.logger = logging.getLogger(__name__)
    
    @security_check(security_level=SecurityLevel.MEDIUM)
    def process_prompt(self, prompt: str) -> str:
        """è™•ç† LangChain æç¤ºè©"""
        # é©—è­‰æç¤ºè©å®‰å…¨æ€§
        if not self.security_validator.validate_prompt(prompt):
            raise ValueError("æç¤ºè©åŒ…å«ä¸å®‰å…¨å…§å®¹")
        
        # é€™è£¡æ˜¯æ‚¨çš„ LangChain è™•ç†é‚è¼¯
        processed_prompt = f"å®‰å…¨è™•ç†çš„æç¤ºè©: {prompt}"
        return processed_prompt
    
    @security_check(security_level=SecurityLevel.HIGH)
    def process_response(self, response: str) -> str:
        """è™•ç† LangChain å›æ‡‰"""
        # é©—è­‰å›æ‡‰å®‰å…¨æ€§
        if not self.security_validator.validate_response(response):
            raise ValueError("å›æ‡‰åŒ…å«ä¸å®‰å…¨å…§å®¹")
        
        # é€™è£¡æ˜¯æ‚¨çš„å›æ‡‰è™•ç†é‚è¼¯
        processed_response = f"å®‰å…¨è™•ç†çš„å›æ‡‰: {response}"
        return processed_response


# ===== CrewAI æ•´åˆç¯„ä¾‹ =====

class SecureCrewAIProcessor:
    """æ•´åˆå®‰å…¨é©—è­‰çš„ CrewAI è™•ç†å™¨"""
    
    def __init__(self):
        self.security_validator = create_crewai_validator(
            security_level=SecurityLevel.HIGH
        )
        self.logger = logging.getLogger(__name__)
    
    @async_security_check(security_level=SecurityLevel.HIGH)
    async def process_agent_input(self, input_data: str) -> str:
        """è™•ç† CrewAI ä»£ç†è¼¸å…¥"""
        # é©—è­‰ä»£ç†è¼¸å…¥å®‰å…¨æ€§
        if not self.security_validator.validate_agent_input(input_data):
            raise ValueError("ä»£ç†è¼¸å…¥åŒ…å«ä¸å®‰å…¨å…§å®¹")
        
        # é€™è£¡æ˜¯æ‚¨çš„ CrewAI ä»£ç†è™•ç†é‚è¼¯
        processed_input = f"å®‰å…¨è™•ç†çš„ä»£ç†è¼¸å…¥: {input_data}"
        return processed_input
    
    @async_security_check(security_level=Security_level.HIGH)
    async def process_agent_output(self, output_data: str) -> str:
        """è™•ç† CrewAI ä»£ç†è¼¸å‡º"""
        # é©—è­‰ä»£ç†è¼¸å‡ºå®‰å…¨æ€§
        if not self.security_validator.validate_agent_output(output_data):
            raise ValueError("ä»£ç†è¼¸å‡ºåŒ…å«ä¸å®‰å…¨å…§å®¹")
        
        # é€™è£¡æ˜¯æ‚¨çš„ä»£ç†è¼¸å‡ºè™•ç†é‚è¼¯
        processed_output = f"å®‰å…¨è™•ç†çš„ä»£ç†è¼¸å‡º: {output_data}"
        return processed_output


# ===== RAG Pipeline æ•´åˆç¯„ä¾‹ =====

class SecureRAGPipeline:
    """æ•´åˆå®‰å…¨é©—è­‰çš„ RAG Pipeline"""
    
    def __init__(self):
        self.security_tool = create_security_tool(
            security_level=SecurityLevel.HIGH,
            blocked_keywords=[
                "æƒ¡æ„", "æ”»æ“Š", "ç—…æ¯’", "é§­å®¢", "æœ¨é¦¬",
                "é‡£é­š", "è©é¨™", "è‰²æƒ…", "æš´åŠ›", "ä»‡æ¨"
            ],
            custom_patterns=[
                r"<script>.*</script>",
                r"javascript:",
                r"on\w+\s*=",
                r"eval\s*\(",
                r"document\.cookie",
                r"window\.location",
                r"alert\s*\(",
                r"confirm\s*\(",
                r"prompt\s*\("
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    @security_check(security_level=SecurityLevel.HIGH)
    async def process_user_query(self, query: str) -> Dict[str, Any]:
        """è™•ç†ç”¨æˆ¶æŸ¥è©¢"""
        # å®‰å…¨é©—è­‰å·²é€šéè£é£¾å™¨è™•ç†
        
        # é€™è£¡æ˜¯æ‚¨çš„ RAG Pipeline é‚è¼¯
        # 1. å‘é‡æœå°‹
        # 2. å…§å®¹æª¢ç´¢
        # 3. å›æ‡‰ç”Ÿæˆ
        
        response = {
            "query": query,
            "response": f"å®‰å…¨è™•ç†çš„æŸ¥è©¢å›æ‡‰: {query}",
            "sources": ["source1", "source2"],
            "confidence": 0.95,
            "security_validated": True
        }
        
        return response
    
    @security_check(security_level=SecurityLevel.HIGH)
    async def process_content_chunk(self, chunk: str) -> Dict[str, Any]:
        """è™•ç†å…§å®¹åˆ†å¡Š"""
        # å®‰å…¨é©—è­‰å·²é€šéè£é£¾å™¨è™•ç†
        
        # é€™è£¡æ˜¯æ‚¨çš„å…§å®¹è™•ç†é‚è¼¯
        processed_chunk = {
            "original_chunk": chunk,
            "processed_chunk": f"å®‰å…¨è™•ç†çš„å…§å®¹: {chunk}",
            "embedding": [0.1, 0.2, 0.3],  # å‘é‡åµŒå…¥
            "tags": ["business", "technology"],
            "security_validated": True
        }
        
        return processed_chunk
    
    async def batch_process_content(self, contents: List[str]) -> List[Dict[str, Any]]:
        """æ‰¹æ¬¡è™•ç†å…§å®¹"""
        results = []
        
        for content in contents:
            try:
                result = await self.process_content_chunk(content)
                results.append(result)
            except ValueError as e:
                self.logger.warning(f"å…§å®¹å®‰å…¨é©—è­‰å¤±æ•—: {e}")
                results.append({
                    "original_chunk": content,
                    "error": "å®‰å…¨é©—è­‰å¤±æ•—",
                    "security_validated": False
                })
        
        return results


# ===== ä½¿ç”¨ç¯„ä¾‹ =====

async def main():
    """ä¸»å‡½æ•¸ - å±•ç¤ºå„ç¨®ä½¿ç”¨æ–¹å¼"""
    
    print("ğŸš€ Podwise å®‰å…¨å·¥å…·ä½¿ç”¨ç¯„ä¾‹")
    print("=" * 50)
    
    # 1. åŸºæœ¬å®‰å…¨å·¥å…·ä½¿ç”¨
    print("\n1. åŸºæœ¬å®‰å…¨å·¥å…·ä½¿ç”¨:")
    security_tool = create_security_tool(
        security_level=SecurityLevel.HIGH,
        blocked_keywords=["æƒ¡æ„", "æ”»æ“Š"],
        custom_patterns=[r"<script>.*</script>"]
    )
    
    # æ¸¬è©¦å®‰å…¨å…§å®¹
    safe_content = "é€™æ˜¯ä¸€å€‹æ­£å¸¸çš„æ¸¬è©¦å…§å®¹"
    result = security_tool.validate_content(safe_content)
    print(f"å®‰å…¨å…§å®¹é©—è­‰: {result.is_valid}")
    
    # æ¸¬è©¦ä¸å®‰å…¨å…§å®¹
    unsafe_content = "é€™æ˜¯ä¸€å€‹æƒ¡æ„æ”»æ“Šçš„å…§å®¹ <script>alert('xss')</script>"
    result = security_tool.validate_content(unsafe_content)
    print(f"ä¸å®‰å…¨å…§å®¹é©—è­‰: {result.is_valid}")
    print(f"é•è¦é …ç›®: {result.violations}")
    
    # 2. LangChain æ•´åˆ
    print("\n2. LangChain æ•´åˆ:")
    langchain_processor = SecureLangChainProcessor()
    
    try:
        safe_prompt = "è«‹è§£é‡‹æ©Ÿå™¨å­¸ç¿’çš„åŸºæœ¬æ¦‚å¿µ"
        processed_prompt = langchain_processor.process_prompt(safe_prompt)
        print(f"å®‰å…¨æç¤ºè©è™•ç†: {processed_prompt}")
    except ValueError as e:
        print(f"æç¤ºè©é©—è­‰å¤±æ•—: {e}")
    
    # 3. CrewAI æ•´åˆ
    print("\n3. CrewAI æ•´åˆ:")
    crewai_processor = SecureCrewAIProcessor()
    
    try:
        safe_input = "åˆ†æå¸‚å ´è¶¨å‹¢"
        processed_input = await crewai_processor.process_agent_input(safe_input)
        print(f"å®‰å…¨ä»£ç†è¼¸å…¥è™•ç†: {processed_input}")
    except ValueError as e:
        print(f"ä»£ç†è¼¸å…¥é©—è­‰å¤±æ•—: {e}")
    
    # 4. RAG Pipeline æ•´åˆ
    print("\n4. RAG Pipeline æ•´åˆ:")
    rag_pipeline = SecureRAGPipeline()
    
    try:
        safe_query = "ä»€éº¼æ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
        response = await rag_pipeline.process_user_query(safe_query)
        print(f"å®‰å…¨æŸ¥è©¢è™•ç†: {response}")
    except ValueError as e:
        print(f"æŸ¥è©¢é©—è­‰å¤±æ•—: {e}")
    
    # 5. æ‰¹æ¬¡è™•ç†
    print("\n5. æ‰¹æ¬¡è™•ç†:")
    contents = [
        "é€™æ˜¯å®‰å…¨çš„å…§å®¹",
        "é€™æ˜¯æƒ¡æ„æ”»æ“Šçš„å…§å®¹",
        "é€™æ˜¯æ­£å¸¸çš„æŠ€è¡“è¨è«–",
        "<script>alert('xss')</script>"
    ]
    
    batch_results = await rag_pipeline.batch_process_content(contents)
    for i, result in enumerate(batch_results):
        print(f"å…§å®¹ {i+1}: {'é€šé' if result['security_validated'] else 'å¤±æ•—'}")
    
    # 6. çµ±è¨ˆè³‡è¨Š
    print("\n6. å®‰å…¨çµ±è¨ˆè³‡è¨Š:")
    stats = security_tool.get_stats()
    print(f"ç¸½é©—è­‰æ¬¡æ•¸: {stats['total_validations']}")
    print(f"é€šéæ¬¡æ•¸: {stats['passed_validations']}")
    print(f"å¤±æ•—æ¬¡æ•¸: {stats['failed_validations']}")
    print(f"æˆåŠŸç‡: {stats['success_rate']:.2%}")
    print(f"å¹³å‡è™•ç†æ™‚é–“: {stats['average_processing_time']:.4f}ç§’")


if __name__ == "__main__":
    # åŸ·è¡Œç¯„ä¾‹
    asyncio.run(main()) 