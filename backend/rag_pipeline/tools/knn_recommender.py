#!/usr/bin/env python3
"""
KNN æ¨è–¦å·¥å…·æ¨¡çµ„

æ­¤æ¨¡çµ„å¯¦ç¾åŸºæ–¼å‘é‡ç›¸ä¼¼åº¦çš„ K-Nearest Neighbors æ¨è–¦ç®—æ³•ï¼Œ
æ”¯æ´å•†æ¥­å’Œæ•™è‚²é¡åˆ¥çš„ Podcast æ¨è–¦ï¼Œæä¾›é«˜ç²¾åº¦çš„å…§å®¹åŒ¹é…ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- åŸºæ–¼å‘é‡ç›¸ä¼¼åº¦çš„ KNN æ¨è–¦
- æ”¯æ´å¤šç¨®ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•
- é¡åˆ¥éæ¿¾å’Œçµ±è¨ˆåˆ†æ
- æ¨è–¦çµæœçš„è©³ç´°æ¨ç†èªªæ˜
- æ€§èƒ½ç›£æ§å’Œå„ªåŒ–

ä½œè€…: Podwise Team
ç‰ˆæœ¬: 2.0.0
"""

import logging
import numpy as np
from typing import List, Dict, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
import json
import time
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class PodcastItem:
    """
    Podcast é …ç›®æ•¸æ“šé¡åˆ¥
    
    æ­¤é¡åˆ¥å°è£äº† Podcast é …ç›®çš„å®Œæ•´è³‡è¨Šï¼ŒåŒ…å«åŸºæœ¬å±¬æ€§ã€
    å‘é‡è¡¨ç¤ºå’Œå…ƒæ•¸æ“šã€‚
    
    Attributes:
        rss_id: RSS è­˜åˆ¥ç¢¼
        title: Podcast æ¨™é¡Œ
        description: æè¿°å…§å®¹
        category: é¡åˆ¥ ("å•†æ¥­" æˆ– "æ•™è‚²")
        tags: æ¨™ç±¤åˆ—è¡¨
        vector: å‘é‡è¡¨ç¤º
        updated_at: æ›´æ–°æ™‚é–“
        confidence: ä¿¡å¿ƒå€¼
    """
    rss_id: str
    title: str
    description: str
    category: str
    tags: List[str] = field(default_factory=list)
    vector: Optional[np.ndarray] = None
    updated_at: Optional[str] = None
    confidence: float = 0.0
    
    def __post_init__(self) -> None:
        """é©—è­‰æ•¸æ“šå®Œæ•´æ€§"""
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError("ä¿¡å¿ƒå€¼å¿…é ˆåœ¨ 0.0 åˆ° 1.0 ä¹‹é–“")
        
        if self.category not in ["å•†æ¥­", "æ•™è‚²"]:
            raise ValueError("ç„¡æ•ˆçš„é¡åˆ¥å€¼")


@dataclass(frozen=True)
class RecommendationResult:
    """
    æ¨è–¦çµæœæ•¸æ“šé¡åˆ¥
    
    æ­¤é¡åˆ¥å°è£äº† KNN æ¨è–¦çš„å®Œæ•´çµæœï¼ŒåŒ…å«æ¨è–¦é …ç›®ã€
    ç›¸ä¼¼åº¦åˆ†æ•¸å’Œè™•ç†å…ƒæ•¸æ“šã€‚
    
    Attributes:
        recommendations: æ¨è–¦çš„ Podcast é …ç›®åˆ—è¡¨
        query_vector: æŸ¥è©¢å‘é‡
        similarity_scores: ç›¸ä¼¼åº¦åˆ†æ•¸åˆ—è¡¨
        category: æ¨è–¦é¡åˆ¥
        confidence: æ•´é«”ä¿¡å¿ƒå€¼
        reasoning: æ¨è–¦æ¨ç†èªªæ˜
        processing_time: è™•ç†æ™‚é–“
    """
    recommendations: List[PodcastItem]
    query_vector: np.ndarray
    similarity_scores: List[float] = field(default_factory=list)
    category: str = "æ··åˆ"
    confidence: float = 0.0
    reasoning: str = ""
    processing_time: float = 0.0
    
    def __post_init__(self) -> None:
        """é©—è­‰æ•¸æ“šå®Œæ•´æ€§"""
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError("ä¿¡å¿ƒå€¼å¿…é ˆåœ¨ 0.0 åˆ° 1.0 ä¹‹é–“")
        
        if self.processing_time < 0:
            raise ValueError("è™•ç†æ™‚é–“ä¸èƒ½ç‚ºè² æ•¸")


class SimilarityMetric(ABC):
    """ç›¸ä¼¼åº¦åº¦é‡æŠ½è±¡åŸºé¡"""
    
    @abstractmethod
    def calculate_similarity(self, vector1: np.ndarray, vector2: np.ndarray) -> float:
        """è¨ˆç®—å…©å€‹å‘é‡ä¹‹é–“çš„ç›¸ä¼¼åº¦"""
        pass
    
    @abstractmethod
    def get_metric_name(self) -> str:
        """ç²å–åº¦é‡æ–¹æ³•åç¨±"""
        pass


class CosineSimilarity(SimilarityMetric):
    """é¤˜å¼¦ç›¸ä¼¼åº¦åº¦é‡"""
    
    def calculate_similarity(self, vector1: np.ndarray, vector2: np.ndarray) -> float:
        """è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦"""
        return float(cosine_similarity([vector1], [vector2])[0][0])
    
    def get_metric_name(self) -> str:
        return "cosine"


class EuclideanSimilarity(SimilarityMetric):
    """æ­å¹¾é‡Œå¾—è·é›¢ç›¸ä¼¼åº¦åº¦é‡"""
    
    def calculate_similarity(self, vector1: np.ndarray, vector2: np.ndarray) -> float:
        """è¨ˆç®—åŸºæ–¼æ­å¹¾é‡Œå¾—è·é›¢çš„ç›¸ä¼¼åº¦"""
        distance = np.linalg.norm(vector1 - vector2)
        return float(1.0 / (1.0 + distance))
    
    def get_metric_name(self) -> str:
        return "euclidean"


class ManhattanSimilarity(SimilarityMetric):
    """æ›¼å“ˆé “è·é›¢ç›¸ä¼¼åº¦åº¦é‡"""
    
    def calculate_similarity(self, vector1: np.ndarray, vector2: np.ndarray) -> float:
        """è¨ˆç®—åŸºæ–¼æ›¼å“ˆé “è·é›¢çš„ç›¸ä¼¼åº¦"""
        distance = np.sum(np.abs(vector1 - vector2))
        return float(1.0 / (1.0 + distance))
    
    def get_metric_name(self) -> str:
        return "manhattan"


class SimilarityMetricFactory:
    """ç›¸ä¼¼åº¦åº¦é‡å·¥å» é¡åˆ¥"""
    
    _metrics = {
        "cosine": CosineSimilarity,
        "euclidean": EuclideanSimilarity,
        "manhattan": ManhattanSimilarity
    }
    
    @classmethod
    def create_metric(cls, metric_name: str) -> SimilarityMetric:
        """
        å‰µå»ºç›¸ä¼¼åº¦åº¦é‡å¯¦ä¾‹
        
        Args:
            metric_name: åº¦é‡æ–¹æ³•åç¨±
            
        Returns:
            SimilarityMetric å¯¦ä¾‹
            
        Raises:
            ValueError: ç•¶åº¦é‡æ–¹æ³•åç¨±ç„¡æ•ˆæ™‚
        """
        if metric_name not in cls._metrics:
            raise ValueError(f"ä¸æ”¯æ´çš„åº¦é‡æ–¹æ³•: {metric_name}")
        
        return cls._metrics[metric_name]()


class RecommendationAnalyzer:
    """æ¨è–¦åˆ†æå™¨"""
    
    def __init__(self) -> None:
        """åˆå§‹åŒ–æ¨è–¦åˆ†æå™¨"""
        pass
    
    def generate_reasoning(self, recommendations: List[PodcastItem], 
                          similarity_scores: List[float], 
                          category_filter: Optional[str],
                          k: int,
                          metric_name: str) -> str:
        """
        ç”Ÿæˆæ¨è–¦æ¨ç†èªªæ˜
        
        Args:
            recommendations: æ¨è–¦é …ç›®åˆ—è¡¨
            similarity_scores: ç›¸ä¼¼åº¦åˆ†æ•¸åˆ—è¡¨
            category_filter: é¡åˆ¥éæ¿¾å™¨
            k: KNN åƒæ•¸
            metric_name: åº¦é‡æ–¹æ³•åç¨±
            
        Returns:
            æ¨ç†èªªæ˜æ–‡å­—
        """
        if not recommendations:
            return "æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„ Podcast æ¨è–¦"
        
        category = category_filter or "æ··åˆé¡åˆ¥"
        avg_similarity = np.mean(similarity_scores)
        
        # çµ±è¨ˆé¡åˆ¥åˆ†å¸ƒ
        category_counts = self._count_categories(recommendations)
        category_distribution = self._format_category_distribution(category_counts)
        
        reasoning = f"""
åŸºæ–¼ KNN ç®—æ³• ({k}-è¿‘é„°, {metric_name}) çš„ {category} æ¨è–¦çµæœï¼š

ğŸ“Š ç›¸ä¼¼åº¦çµ±è¨ˆï¼š
- å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}
- æœ€é«˜ç›¸ä¼¼åº¦: {max(similarity_scores):.3f}
- æœ€ä½ç›¸ä¼¼åº¦: {min(similarity_scores):.3f}

ğŸ“‚ é¡åˆ¥åˆ†å¸ƒ: {category_distribution}

ğŸ¯ æ¨è–¦ç†ç”±: æ ¹æ“šå‘é‡ç›¸ä¼¼åº¦åŒ¹é…ï¼Œé¸æ“‡æœ€ç›¸é—œçš„ {len(recommendations)} å€‹ Podcast
        """.strip()
        
        return reasoning
    
    def _count_categories(self, recommendations: List[PodcastItem]) -> Dict[str, int]:
        """çµ±è¨ˆé¡åˆ¥åˆ†å¸ƒ"""
        category_counts = {}
        for item in recommendations:
            category_counts[item.category] = category_counts.get(item.category, 0) + 1
        return category_counts
    
    def _format_category_distribution(self, category_counts: Dict[str, int]) -> str:
        """æ ¼å¼åŒ–é¡åˆ¥åˆ†å¸ƒ"""
        return ", ".join([f"{cat}: {count}å€‹" for cat, count in category_counts.items()])


class KNNRecommender:
    """
    K-Nearest Neighbors æ¨è–¦å™¨
    
    æ­¤é¡åˆ¥å¯¦ç¾åŸºæ–¼å‘é‡ç›¸ä¼¼åº¦çš„ KNN æ¨è–¦ç®—æ³•ï¼Œæ”¯æ´å¤šç¨®
    ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•å’Œé¡åˆ¥éæ¿¾åŠŸèƒ½ã€‚
    
    ä¸»è¦åŠŸèƒ½ï¼š
    - åŸºæ–¼å‘é‡ç›¸ä¼¼åº¦çš„ KNN æ¨è–¦
    - æ”¯æ´å¤šç¨®ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•
    - é¡åˆ¥éæ¿¾å’Œçµ±è¨ˆåˆ†æ
    - æ¨è–¦çµæœçš„è©³ç´°æ¨ç†èªªæ˜
    - æ€§èƒ½ç›£æ§å’Œå„ªåŒ–
    """
    
    def __init__(self, k: int = 5, metric: str = "cosine") -> None:
        """
        åˆå§‹åŒ– KNN æ¨è–¦å™¨
        
        Args:
            k: é„°å±…æ•¸é‡
            metric: ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³• ("cosine", "euclidean", "manhattan")
            
        Raises:
            ValueError: ç•¶åƒæ•¸ç„¡æ•ˆæ™‚
        """
        if k <= 0:
            raise ValueError("k å¿…é ˆå¤§æ–¼ 0")
        
        self.k = k
        self.metric = metric
        self.similarity_metric = SimilarityMetricFactory.create_metric(metric)
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.nn_model: Optional[NearestNeighbors] = None
        self.podcast_items: List[PodcastItem] = []
        self.vectors: List[np.ndarray] = []
        self.categories: List[str] = []
        self.recommendation_analyzer = RecommendationAnalyzer()
        
        # åˆå§‹åŒ– KNN æ¨¡å‹
        self._initialize_model()
        
        logger.info(f"KNN æ¨è–¦å™¨åˆå§‹åŒ–å®Œæˆ (k={k}, metric={metric})")
    
    def _initialize_model(self) -> None:
        """åˆå§‹åŒ– KNN æ¨¡å‹"""
        self.nn_model = NearestNeighbors(
            n_neighbors=self.k,
            metric=self.metric,
            algorithm='auto'
        )
    
    def add_podcast_items(self, items: List[PodcastItem]) -> None:
        """
        æ·»åŠ  Podcast é …ç›®åˆ°æ¨è–¦ç³»çµ±
        
        Args:
            items: Podcast é …ç›®åˆ—è¡¨
            
        Raises:
            ValueError: ç•¶é …ç›®åˆ—è¡¨ç‚ºç©ºæˆ–é …ç›®ç„¡æ•ˆæ™‚
        """
        if not items:
            raise ValueError("é …ç›®åˆ—è¡¨ä¸èƒ½ç‚ºç©º")
        
        valid_items = []
        for item in items:
            if item.vector is not None:
                valid_items.append(item)
                self.podcast_items.append(item)
                self.vectors.append(item.vector)
                self.categories.append(item.category)
        
        # é‡æ–°è¨“ç·´æ¨¡å‹
        if self.vectors and self.nn_model is not None:
            vectors_array = np.array(self.vectors)
            self.nn_model.fit(vectors_array)
            logger.info(f"å·²æ·»åŠ  {len(valid_items)} å€‹æœ‰æ•ˆ Podcast é …ç›®ï¼Œç¸½è¨ˆ {len(self.podcast_items)} å€‹")
    
    def recommend(self, query_vector: np.ndarray, 
                 category_filter: Optional[str] = None, 
                 top_k: int = 3) -> RecommendationResult:
        """
        åŸ·è¡Œ KNN æ¨è–¦
        
        Args:
            query_vector: æŸ¥è©¢å‘é‡
            category_filter: é¡åˆ¥éæ¿¾å™¨ ("å•†æ¥­" æˆ– "æ•™è‚²")
            top_k: è¿”å›æ¨è–¦æ•¸é‡
            
        Returns:
            RecommendationResult: æ¨è–¦çµæœ
            
        Raises:
            ValueError: ç•¶åƒæ•¸ç„¡æ•ˆæ™‚
        """
        if top_k <= 0:
            raise ValueError("top_k å¿…é ˆå¤§æ–¼ 0")
        
        start_time = time.time()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„é …ç›®
        if len(self.podcast_items) == 0:
            return self._create_empty_result(query_vector, category_filter, start_time)
        
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²åˆå§‹åŒ–
        if self.nn_model is None:
            return self._create_empty_result(query_vector, category_filter, start_time, 
                                           "KNN æ¨¡å‹æœªåˆå§‹åŒ–")
        
        # åŸ·è¡Œ KNN æœå°‹
        distances, indices = self.nn_model.kneighbors([query_vector])
        
        # ç²å–å€™é¸é …ç›®
        candidates = self._get_candidates(indices[0], distances[0], category_filter)
        
        # æ’åºä¸¦é¸æ“‡ top_k
        candidates.sort(key=lambda x: x[1], reverse=True)
        top_candidates = candidates[:top_k]
        
        # æ§‹å»ºçµæœ
        recommendations = [item for item, _ in top_candidates]
        similarity_scores = [score for _, score in top_candidates]
        
        # è¨ˆç®—æ•´é«”ä¿¡å¿ƒå€¼
        confidence = float(np.mean(similarity_scores)) if similarity_scores else 0.0
        
        # ç”Ÿæˆæ¨ç†èªªæ˜
        reasoning = self.recommendation_analyzer.generate_reasoning(
            recommendations, similarity_scores, category_filter, self.k, self.metric
        )
        
        processing_time = time.time() - start_time
        
        return RecommendationResult(
            recommendations=recommendations,
            query_vector=query_vector,
            similarity_scores=similarity_scores,
            category=category_filter or "æ··åˆ",
            confidence=confidence,
            reasoning=reasoning,
            processing_time=processing_time
        )
    
    def _create_empty_result(self, query_vector: np.ndarray, 
                           category_filter: Optional[str], 
                           start_time: float,
                           reason: str = "æ²’æœ‰å¯ç”¨çš„ Podcast é …ç›®") -> RecommendationResult:
        """å‰µå»ºç©ºçµæœ"""
        return RecommendationResult(
            recommendations=[],
            query_vector=query_vector,
            similarity_scores=[],
            category=category_filter or "æœªçŸ¥",
            confidence=0.0,
            reasoning=reason,
            processing_time=time.time() - start_time
        )
    
    def _get_candidates(self, indices: np.ndarray, distances: np.ndarray, 
                       category_filter: Optional[str]) -> List[Tuple[PodcastItem, float]]:
        """ç²å–å€™é¸é …ç›®"""
        candidates = []
        for i, idx in enumerate(indices):
            item = self.podcast_items[idx]
            similarity = 1 - distances[i]  # è½‰æ›è·é›¢ç‚ºç›¸ä¼¼åº¦
            
            # æ‡‰ç”¨é¡åˆ¥éæ¿¾
            if category_filter and item.category != category_filter:
                continue
            
            candidates.append((item, similarity))
        
        return candidates
    
    def get_category_statistics(self) -> Dict[str, Any]:
        """
        ç²å–é¡åˆ¥çµ±è¨ˆè³‡è¨Š
        
        Returns:
            é¡åˆ¥çµ±è¨ˆå­—å…¸
        """
        if not self.categories:
            return {"total": 0, "categories": {}}
        
        category_counts = {}
        for category in self.categories:
            category_counts[category] = category_counts.get(category, 0) + 1
        
        return {
            "total": len(self.categories),
            "categories": category_counts,
            "model_ready": self.nn_model is not None and len(self.vectors) > 0
        }
    
    def filter_by_category(self, category: str) -> List[PodcastItem]:
        """
        æŒ‰é¡åˆ¥éæ¿¾ Podcast é …ç›®
        
        Args:
            category: é¡åˆ¥åç¨±
            
        Returns:
            éæ¿¾å¾Œçš„é …ç›®åˆ—è¡¨
        """
        return [item for item in self.podcast_items if item.category == category]
    
    def get_similar_items(self, item_id: str, top_k: int = 5) -> List[Tuple[PodcastItem, float]]:
        """
        ç²å–ç›¸ä¼¼é …ç›®
        
        Args:
            item_id: é …ç›® ID
            top_k: è¿”å›æ•¸é‡
            
        Returns:
            ç›¸ä¼¼é …ç›®å’Œç›¸ä¼¼åº¦çš„å…ƒçµ„åˆ—è¡¨
        """
        # æ‰¾åˆ°ç›®æ¨™é …ç›®
        target_item = None
        for item in self.podcast_items:
            if item.rss_id == item_id:
                target_item = item
                break
        
        if target_item is None or target_item.vector is None:
            return []
        
        # è¨ˆç®—èˆ‡æ‰€æœ‰é …ç›®çš„ç›¸ä¼¼åº¦
        similarities = []
        for item in self.podcast_items:
            if item.rss_id != item_id and item.vector is not None:
                similarity = self.similarity_metric.calculate_similarity(
                    target_item.vector, item.vector
                )
                similarities.append((item, similarity))
        
        # æ’åºä¸¦è¿”å› top_k
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
    
    def export_recommendations_to_json(self, result: RecommendationResult, 
                                     filepath: str) -> None:
        """
        åŒ¯å‡ºæ¨è–¦çµæœåˆ° JSON æª”æ¡ˆ
        
        Args:
            result: æ¨è–¦çµæœ
            filepath: æª”æ¡ˆè·¯å¾‘
        """
        data = {
            "recommendations": [
                {
                    "rss_id": item.rss_id,
                    "title": item.title,
                    "description": item.description,
                    "category": item.category,
                    "tags": item.tags,
                    "confidence": item.confidence,
                    "updated_at": item.updated_at
                }
                for item in result.recommendations
            ],
            "metadata": {
                "query_vector_shape": result.query_vector.shape,
                "similarity_scores": result.similarity_scores,
                "category": result.category,
                "confidence": result.confidence,
                "processing_time": result.processing_time,
                "export_timestamp": str(datetime.now()),
                "version": "2.0.0"
            },
            "reasoning": result.reasoning
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ¨è–¦çµæœå·²åŒ¯å‡ºåˆ°: {filepath}")
    
    def clear_data(self) -> None:
        """æ¸…é™¤æ‰€æœ‰æ•¸æ“š"""
        self.podcast_items.clear()
        self.vectors.clear()
        self.categories.clear()
        self.nn_model = None
        logger.info("å·²æ¸…é™¤æ‰€æœ‰æ•¸æ“š")


def test_knn_recommender() -> None:
    """æ¸¬è©¦ KNN æ¨è–¦å™¨åŠŸèƒ½"""
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    test_items = [
        PodcastItem(
            rss_id="rss_001",
            title="è‚¡ç™Œ EP310",
            description="å°è‚¡æŠ•è³‡åˆ†æèˆ‡å¸‚å ´è¶¨å‹¢",
            category="å•†æ¥­",
            tags=["è‚¡ç¥¨", "æŠ•è³‡", "å°è‚¡", "è²¡ç¶“"],
            vector=np.array([0.8, 0.6, 0.9, 0.7, 0.8, 0.6, 0.9, 0.7]),
            updated_at="2025-01-15",
            confidence=0.9
        ),
        PodcastItem(
            rss_id="rss_002",
            title="å¤§äººå­¸ EP110",
            description="è·æ¶¯ç™¼å±•èˆ‡å€‹äººæˆé•·æŒ‡å—",
            category="æ•™è‚²",
            tags=["è·æ¶¯", "æˆé•·", "æŠ€èƒ½", "å­¸ç¿’"],
            vector=np.array([0.3, 0.8, 0.4, 0.9, 0.3, 0.8, 0.4, 0.9]),
            updated_at="2025-01-14",
            confidence=0.85
        ),
        PodcastItem(
            rss_id="rss_003",
            title="è²¡å ±ç‹— Podcast",
            description="è²¡å ±åˆ†æèˆ‡æŠ•è³‡ç­–ç•¥",
            category="å•†æ¥­",
            tags=["è²¡å ±", "æŠ•è³‡", "åˆ†æ", "ç­–ç•¥"],
            vector=np.array([0.9, 0.5, 0.8, 0.6, 0.9, 0.5, 0.8, 0.6]),
            updated_at="2025-01-13",
            confidence=0.88
        )
    ]
    
    # åˆå§‹åŒ–æ¨è–¦å™¨
    recommender = KNNRecommender(k=3, metric="cosine")
    recommender.add_podcast_items(test_items)
    
    # æ¸¬è©¦æŸ¥è©¢
    query_vector = np.array([0.7, 0.7, 0.8, 0.8, 0.7, 0.7, 0.8, 0.8])
    
    # åŸ·è¡Œæ¨è–¦
    result = recommender.recommend(query_vector, category_filter="å•†æ¥­", top_k=2)
    
    print("=== KNN æ¨è–¦å™¨æ¸¬è©¦ ===")
    print(f"æŸ¥è©¢å‘é‡: {query_vector}")
    print(f"æ¨è–¦é¡åˆ¥: {result.category}")
    print(f"ä¿¡å¿ƒå€¼: {result.confidence:.3f}")
    print(f"è™•ç†æ™‚é–“: {result.processing_time:.3f} ç§’")
    print(f"æ¨è–¦é …ç›®æ•¸é‡: {len(result.recommendations)}")
    print(f"æ¨ç†èªªæ˜: {result.reasoning}")
    
    # é¡¯ç¤ºæ¨è–¦é …ç›®
    for i, item in enumerate(result.recommendations):
        print(f"\næ¨è–¦ {i+1}: {item.title}")
        print(f"  é¡åˆ¥: {item.category}")
        print(f"  ç›¸ä¼¼åº¦: {result.similarity_scores[i]:.3f}")
        print(f"  æè¿°: {item.description}")


if __name__ == "__main__":
    test_knn_recommender() 