#!/usr/bin/env python3
"""
Podwise RAG Pipeline - MCP æ•´åˆæ¨¡çµ„

æ•´åˆ Model Context Protocol (MCP) ä»¥å¢å¼· RAG Pipeline åŠŸèƒ½ï¼š
- å¤–éƒ¨å·¥å…·æ•´åˆ
- è³‡æºç®¡ç†
- å‹•æ…‹å·¥å…·èª¿ç”¨
- ä¸Šä¸‹æ–‡ç®¡ç†

ä½œè€…: Podwise Team
ç‰ˆæœ¬: 1.0.0
"""

import asyncio
import logging
import yaml
import json
from typing import Dict, Any, Optional, List, Callable
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

# å°å…¥ Langfuse è¿½è¹¤
from .langfuse_tracking import langfuse_trace

logger = logging.getLogger(__name__)


@dataclass
class MCPTool:
    """MCP å·¥å…·å®šç¾©"""
    name: str
    description: str
    input_schema: Dict[str, Any]
    handler: Callable


@dataclass
class MCPResource:
    """MCP è³‡æºå®šç¾©"""
    uri: str
    mime_type: str
    content: bytes
    metadata: Dict[str, Any]


class PodwiseMCPIntegration:
    """
    Podwise MCP æ•´åˆé¡åˆ¥
    
    æä¾›èˆ‡å¤–éƒ¨å·¥å…·å’Œè³‡æºçš„æ•´åˆåŠŸèƒ½
    """
    
    def __init__(self, 
                 config_path: str = "config/mcp_config.yaml",
                 enable_tools: bool = True,
                 enable_resources: bool = True):
        """
        åˆå§‹åŒ– MCP æ•´åˆ
        
        Args:
            config_path: MCP é…ç½®æª”æ¡ˆè·¯å¾‘
            enable_tools: æ˜¯å¦å•Ÿç”¨å·¥å…·åŠŸèƒ½
            enable_resources: æ˜¯å¦å•Ÿç”¨è³‡æºåŠŸèƒ½
        """
        self.config_path = config_path
        self.enable_tools = enable_tools
        self.enable_resources = enable_resources
        
        # è¼‰å…¥é…ç½®
        self.config = self._load_config()
        
        # è¨»å†Šçš„å·¥å…·
        self.registered_tools: Dict[str, MCPTool] = {}
        
        # è³‡æºå¿«å–
        self.resource_cache: Dict[str, MCPResource] = {}
        
        # åˆå§‹åŒ–å·¥å…·
        self._initialize_tools()
        
        logger.info("âœ… Podwise MCP æ•´åˆåˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥ MCP é…ç½®"""
        try:
            config_file = Path(__file__).parent.parent / self.config_path
            if config_file.exists():
                with open(config_file, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            else:
                logger.warning(f"MCP é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {config_file}")
                return {"mcp": {}}
        except Exception as e:
            logger.error(f"è¼‰å…¥ MCP é…ç½®å¤±æ•—: {e}")
            return {"mcp": {}}
    
    def _initialize_tools(self):
        """åˆå§‹åŒ–å…§å»ºå·¥å…·"""
        if not self.enable_tools:
            return
        
        # è¨»å†Š Podcast æœå°‹å·¥å…·
        self.register_tool(
            name="search_podcasts",
            description="æœå°‹ Podcast è³‡è¨Š",
            input_schema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "æœå°‹æŸ¥è©¢"},
                    "category": {"type": "string", "description": "Podcast é¡åˆ¥"},
                    "limit": {"type": "integer", "description": "çµæœæ•¸é‡é™åˆ¶"}
                },
                "required": ["query"]
            },
            handler=self._search_podcasts_handler
        )
        
        # è¨»å†Šæƒ…æ„Ÿåˆ†æå·¥å…·
        self.register_tool(
            name="analyze_sentiment",
            description="åˆ†ææ–‡æœ¬æƒ…æ„Ÿ",
            input_schema={
                "type": "object",
                "properties": {
                    "text": {"type": "string", "description": "è¦åˆ†æçš„æ–‡æœ¬"},
                    "analyzer_type": {"type": "string", "enum": ["chinese", "vader"], "description": "åˆ†æå™¨é¡å‹"}
                },
                "required": ["text"]
            },
            handler=self._analyze_sentiment_handler
        )
        
        # è¨»å†Š Apple Podcast æ’åå·¥å…·
        self.register_tool(
            name="get_apple_podcast_ranking",
            description="ç²å– Apple Podcast æ’åè³‡è¨Š",
            input_schema={
                "type": "object",
                "properties": {
                    "rss_id": {"type": "string", "description": "Podcast RSS ID"},
                    "include_details": {"type": "boolean", "description": "æ˜¯å¦åŒ…å«è©³ç´°è³‡è¨Š"}
                },
                "required": ["rss_id"]
            },
            handler=self._get_apple_ranking_handler
        )
        
        # è¨»å†Šå‘é‡æœå°‹å·¥å…·
        self.register_tool(
            name="vector_search",
            description="åŸ·è¡Œå‘é‡æœå°‹",
            input_schema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "æœå°‹æŸ¥è©¢"},
                    "top_k": {"type": "integer", "description": "è¿”å›çµæœæ•¸é‡"},
                    "similarity_threshold": {"type": "number", "description": "ç›¸ä¼¼åº¦é–¾å€¼"}
                },
                "required": ["query"]
            },
            handler=self._vector_search_handler
        )
        
        # è¨»å†Šå…§å®¹åˆ†é¡å·¥å…·
        self.register_tool(
            name="classify_content",
            description="åˆ†é¡å…§å®¹",
            input_schema={
                "type": "object",
                "properties": {
                    "content": {"type": "string", "description": "è¦åˆ†é¡çš„å…§å®¹"},
                    "categories": {"type": "array", "items": {"type": "string"}, "description": "å¯é¸åˆ†é¡åˆ—è¡¨"}
                },
                "required": ["content"]
            },
            handler=self._classify_content_handler
        )
        
        logger.info(f"âœ… å·²è¨»å†Š {len(self.registered_tools)} å€‹ MCP å·¥å…·")
    
    def register_tool(self, name: str, description: str, input_schema: Dict[str, Any], handler: Callable):
        """
        è¨»å†Š MCP å·¥å…·
        
        Args:
            name: å·¥å…·åç¨±
            description: å·¥å…·æè¿°
            input_schema: è¼¸å…¥åƒæ•¸ schema
            handler: å·¥å…·è™•ç†å‡½æ•¸
        """
        self.registered_tools[name] = MCPTool(
            name=name,
            description=description,
            input_schema=input_schema,
            handler=handler
        )
        logger.info(f"âœ… è¨»å†Š MCP å·¥å…·: {name}")
    
    async def list_available_tools(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºå¯ç”¨çš„å·¥å…·
        
        Returns:
            List[Dict[str, Any]]: å¯ç”¨å·¥å…·åˆ—è¡¨
        """
        tools = []
        
        for tool_name, tool in self.registered_tools.items():
            tools.append({
                "name": tool_name,
                "description": tool.description,
                "input_schema": tool.input_schema
            })
        
        return tools
    
    @langfuse_trace("tool_call")
    async def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """
        èª¿ç”¨å·¥å…·
        
        Args:
            tool_name: å·¥å…·åç¨±
            arguments: å·¥å…·åƒæ•¸
            
        Returns:
            Dict[str, Any]: å·¥å…·èª¿ç”¨çµæœ
        """
        try:
            if tool_name not in self.registered_tools:
                raise ValueError(f"å·¥å…· '{tool_name}' ä¸å­˜åœ¨")
            
            tool = self.registered_tools[tool_name]
            result = await tool.handler(arguments)
            
            return {
                "success": True,
                "tool_name": tool_name,
                "result": result,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"èª¿ç”¨å·¥å…· '{tool_name}' å¤±æ•—: {e}")
            return {
                "success": False,
                "tool_name": tool_name,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _search_podcasts_handler(self, arguments: Dict[str, Any]) -> str:
        """Podcast æœå°‹å·¥å…·è™•ç†å™¨"""
        query = arguments.get("query", "")
        category = arguments.get("category", "")
        limit = arguments.get("limit", 10)
        
        # æ¨¡æ“¬æœå°‹çµæœ
        results = [
            {"title": "ç§‘æŠ€æ—©çŸ¥é“", "category": "technology", "rating": 4.5},
            {"title": "å•†æ¥­å°±æ˜¯é€™æ¨£", "category": "business", "rating": 4.2},
            {"title": "å­¸ç¿’æˆé•·", "category": "education", "rating": 4.7}
        ]
        
        if category:
            results = [r for r in results if r["category"] == category]
        
        return f"æ‰¾åˆ° {len(results)} å€‹ç›¸é—œ Podcast: {results[:limit]}"
    
    async def _analyze_sentiment_handler(self, arguments: Dict[str, Any]) -> str:
        """æƒ…æ„Ÿåˆ†æå·¥å…·è™•ç†å™¨"""
        text = arguments.get("text", "")
        analyzer_type = arguments.get("analyzer_type", "chinese")
        
        # æ¨¡æ“¬æƒ…æ„Ÿåˆ†æçµæœ
        sentiment_scores = {
            "positive": 0.7,
            "negative": 0.1,
            "neutral": 0.2
        }
        
        if "å¾ˆæ£’" in text or "å¾ˆå¥½" in text:
            label = "positive"
        elif "ç³Ÿç³•" in text or "ä¸å¥½" in text:
            label = "negative"
        else:
            label = "neutral"
        
        return f"æƒ…æ„Ÿåˆ†æçµæœ: {label} (ä¿¡å¿ƒåº¦: 0.85), åˆ†æå™¨: {analyzer_type}"
    
    async def _get_apple_ranking_handler(self, arguments: Dict[str, Any]) -> str:
        """Apple Podcast æ’åå·¥å…·è™•ç†å™¨"""
        rss_id = arguments.get("rss_id", "")
        include_details = arguments.get("include_details", False)
        
        # æ¨¡æ“¬ Apple Podcast æ’åæ•¸æ“š
        ranking_data = {
            "rss_id": rss_id,
            "apple_rating": 4.5,
            "apple_review_count": 1250,
            "user_click_rate": 0.75,
            "comment_sentiment_score": 0.8
        }
        
        if include_details:
            return f"è©³ç´°æ’åè³‡è¨Š: {json.dumps(ranking_data, ensure_ascii=False, indent=2)}"
        else:
            return f"Apple Podcast æ’å: {ranking_data['apple_rating']}/5 æ˜Ÿ ({ranking_data['apple_review_count']} è©•è«–)"
    
    async def _vector_search_handler(self, arguments: Dict[str, Any]) -> str:
        """å‘é‡æœå°‹å·¥å…·è™•ç†å™¨"""
        query = arguments.get("query", "")
        top_k = arguments.get("top_k", 5)
        similarity_threshold = arguments.get("similarity_threshold", 0.7)
        
        # æ¨¡æ“¬å‘é‡æœå°‹çµæœ
        results = [
            {"id": "1", "title": "ç›¸é—œ Podcast 1", "similarity": 0.95},
            {"id": "2", "title": "ç›¸é—œ Podcast 2", "similarity": 0.88},
            {"id": "3", "title": "ç›¸é—œ Podcast 3", "similarity": 0.82}
        ]
        
        # éæ¿¾ç›¸ä¼¼åº¦
        filtered_results = [r for r in results if r["similarity"] >= similarity_threshold]
        
        return f"å‘é‡æœå°‹çµæœ: æ‰¾åˆ° {len(filtered_results)} å€‹ç›¸é—œçµæœ (é–¾å€¼: {similarity_threshold})"
    
    async def _classify_content_handler(self, arguments: Dict[str, Any]) -> str:
        """å…§å®¹åˆ†é¡å·¥å…·è™•ç†å™¨"""
        content = arguments.get("content", "")
        categories = arguments.get("categories", ["business", "education", "technology", "entertainment"])
        
        # ç°¡å–®çš„é—œéµå­—åˆ†é¡
        category_keywords = {
            "business": ["å•†æ¥­", "æŠ•è³‡", "å‰µæ¥­", "å¸‚å ´", "ç¶“æ¿Ÿ"],
            "education": ["æ•™è‚²", "å­¸ç¿’", "èª²ç¨‹", "çŸ¥è­˜", "åŸ¹è¨“"],
            "technology": ["ç§‘æŠ€", "æŠ€è¡“", "ç¨‹å¼", "AI", "å‰µæ–°"],
            "entertainment": ["å¨›æ¨‚", "éŸ³æ¨‚", "é›»å½±", "éŠæˆ²", "ä¼‘é–’"]
        }
        
        scores = {}
        for category in categories:
            score = 0
            for keyword in category_keywords.get(category, []):
                if keyword in content:
                    score += 1
            scores[category] = score
        
        # æ‰¾å‡ºæœ€é«˜åˆ†çš„åˆ†é¡
        best_category = max(scores.items(), key=lambda x: x[1])
        
        return f"å…§å®¹åˆ†é¡çµæœ: {best_category[0]} (ä¿¡å¿ƒåº¦: {best_category[1]}/{len(category_keywords.get(best_category[0], []))})"
    
    async def add_resource(self, uri: str, mime_type: str, content: bytes, metadata: Optional[Dict[str, Any]] = None):
        """
        æ·»åŠ è³‡æº
        
        Args:
            uri: è³‡æº URI
            mime_type: MIME é¡å‹
            content: è³‡æºå…§å®¹
            metadata: å…ƒæ•¸æ“š
        """
        if not self.enable_resources:
            return
        
        self.resource_cache[uri] = MCPResource(
            uri=uri,
            mime_type=mime_type,
            content=content,
            metadata=metadata or {}
        )
        logger.info(f"âœ… å·²æ·»åŠ è³‡æº: {uri}")
    
    async def get_resource(self, uri: str) -> Optional[MCPResource]:
        """
        ç²å–è³‡æº
        
        Args:
            uri: è³‡æº URI
            
        Returns:
            Optional[MCPResource]: è³‡æºå°è±¡
        """
        return self.resource_cache.get(uri)
    
    async def list_resources(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰è³‡æº URI
        
        Returns:
            List[str]: è³‡æº URI åˆ—è¡¨
        """
        return list(self.resource_cache.keys())
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æª¢æŸ¥"""
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "tools_enabled": self.enable_tools,
            "resources_enabled": self.enable_resources,
            "registered_tools_count": len(self.registered_tools),
            "cached_resources_count": len(self.resource_cache),
            "config_loaded": bool(self.config)
        }
    
    async def enhance_response(self, 
                              original_content: str, 
                              user_query: str, 
                              category: str = "å…¶ä»–",
                              context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨ MCP å·¥å…·å¢å¼·å›æ‡‰å…§å®¹
        
        Args:
            original_content: åŸå§‹å›æ‡‰å…§å®¹
            user_query: ç”¨æˆ¶æŸ¥è©¢
            category: æŸ¥è©¢åˆ†é¡
            context: ä¸Šä¸‹æ–‡è³‡è¨Š
            
        Returns:
            Dict[str, Any]: å¢å¼·çµæœ
        """
        try:
            enhanced_content = original_content
            
            # ä½¿ç”¨æƒ…æ„Ÿåˆ†æå·¥å…·åˆ†æåŸå§‹å…§å®¹
            sentiment_result = await self.call_tool("analyze_sentiment", {
                "text": original_content,
                "analyzer_type": "chinese"
            })
            
            # ä½¿ç”¨å…§å®¹åˆ†é¡å·¥å…·ç¢ºèªåˆ†é¡
            classification_result = await self.call_tool("classify_content", {
                "content": original_content,
                "categories": ["business", "education", "technology", "entertainment"]
            })
            
            # æ ¹æ“šåˆ†é¡å’Œæƒ…æ„Ÿåˆ†æçµæœå¢å¼·å…§å®¹
            if sentiment_result.get("success"):
                sentiment_info = sentiment_result.get("result", "")
                if "positive" in sentiment_info.lower():
                    enhanced_content += "\n\nğŸ’¡ å°æé†’ï¼šé€™å€‹æ¨è–¦çœ‹èµ·ä¾†å¾ˆå—æ­¡è¿å–”ï¼"
                elif "negative" in sentiment_info.lower():
                    enhanced_content += "\n\nâš ï¸ æ³¨æ„ï¼šé€™å€‹å…§å®¹å¯èƒ½éœ€è¦æ‚¨é€²ä¸€æ­¥è©•ä¼°ã€‚"
            
            # æ·»åŠ åˆ†é¡ç›¸é—œçš„å»ºè­°
            if classification_result.get("success"):
                class_info = classification_result.get("result", "")
                if "business" in class_info.lower():
                    enhanced_content += "\n\nğŸ’¼ å•†æ¥­é¡å…§å®¹ï¼šå»ºè­°æ‚¨é—œæ³¨å¯¦ç”¨æ€§å’Œé¢¨éšªç®¡ç†ã€‚"
                elif "education" in class_info.lower():
                    enhanced_content += "\n\nğŸ“š æ•™è‚²é¡å…§å®¹ï¼šå»ºè­°æ‚¨é—œæ³¨å­¸ç¿’æ•ˆæœå’Œå¯¦ç”¨æ€§ã€‚"
            
            # ä½¿ç”¨å‘é‡æœå°‹å·¥å…·æä¾›é¡å¤–å»ºè­°
            search_result = await self.call_tool("vector_search", {
                "query": user_query,
                "top_k": 3,
                "similarity_threshold": 0.7
            })
            
            if search_result.get("success"):
                enhanced_content += f"\n\nğŸ” ç›¸é—œæœå°‹ï¼š{search_result.get('result', '')}"
            
            return {
                "success": True,
                "enhanced_content": enhanced_content,
                "original_content": original_content,
                "enhancements_applied": [
                    "sentiment_analysis",
                    "content_classification", 
                    "vector_search"
                ],
                "metadata": {
                    "sentiment_result": sentiment_result,
                    "classification_result": classification_result,
                    "search_result": search_result
                }
            }
            
        except Exception as e:
            logger.error(f"MCP å›æ‡‰å¢å¼·å¤±æ•—: {e}")
            return {
                "success": False,
                "enhanced_content": original_content,
                "error": str(e)
            }
    
    def get_config(self) -> Dict[str, Any]:
        """ç²å–é…ç½®"""
        return self.config


# å…¨åŸŸå¯¦ä¾‹
_mcp_integration_instance: Optional[PodwiseMCPIntegration] = None


def get_mcp_integration() -> PodwiseMCPIntegration:
    """ç²å– MCP æ•´åˆå¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰"""
    global _mcp_integration_instance
    if _mcp_integration_instance is None:
        _mcp_integration_instance = PodwiseMCPIntegration()
    return _mcp_integration_instance


async def main():
    """ä¸»å‡½æ•¸ - ç”¨æ–¼æ¸¬è©¦"""
    # å‰µå»º MCP æ•´åˆå¯¦ä¾‹
    mcp = PodwiseMCPIntegration()
    
    # åˆ—å‡ºå¯ç”¨å·¥å…·
    tools = await mcp.list_available_tools()
    print(f"å¯ç”¨å·¥å…·æ•¸é‡: {len(tools)}")
    
    # æ¸¬è©¦å·¥å…·èª¿ç”¨
    result = await mcp.call_tool("analyze_sentiment", {
        "text": "é€™å€‹ Podcast çœŸçš„å¾ˆæ£’ï¼",
        "analyzer_type": "chinese"
    })
    
    print(f"å·¥å…·èª¿ç”¨çµæœ: {result}")
    
    # å¥åº·æª¢æŸ¥
    health = await mcp.health_check()
    print(f"å¥åº·ç‹€æ…‹: {health['status']}")


if __name__ == "__main__":
    asyncio.run(main()) 