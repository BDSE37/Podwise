{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0c9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: braintrust in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (0.1.8)\n",
      "Requirement already satisfied: autoevals in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (0.0.129)\n",
      "Requirement already satisfied: openai in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (1.55.3)\n",
      "Requirement already satisfied: GitPython in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (3.1.44)\n",
      "Requirement already satisfied: requests in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (2.31.0)\n",
      "Requirement already satisfied: chevron in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.2.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (1.3.0)\n",
      "Requirement already satisfied: python-dotenv in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (1.0.0)\n",
      "Requirement already satisfied: sseclient-py in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (1.8.0)\n",
      "Requirement already satisfied: python-slugify in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (8.0.4)\n",
      "Requirement already satisfied: typing_extensions>=4.1.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (4.14.1)\n",
      "Requirement already satisfied: polyleven in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (0.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (6.0.2)\n",
      "Requirement already satisfied: braintrust_core==0.0.59 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (0.0.59)\n",
      "Requirement already satisfied: jsonschema in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (4.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from GitPython->braintrust) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython->braintrust) (5.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (0.26.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from python-slugify->braintrust) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests->braintrust) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests->braintrust) (2.5.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install braintrust autoevals openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27065f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 Unnamed: 1            Unnamed: 2                  Unnamed: 3  \\\n",
      "0            æå•äºº         é¡åˆ¥   å•é¡Œ (keywordsè«‹å¹«æˆ‘æ¨™ç´…å­—)  Mappingåˆ°çš„tag (è«‹åƒè€ƒtagåˆ—è¡¨ç¬¬Cåˆ—)   \n",
      "1  LI HSIN HSIEH         å…¶ä»–    æœ€è¿‘NVIDIAå¥½åƒå¾ˆç´…ï¼Œä»–æ˜¯ä»€éº¼?                      NVIDIA   \n",
      "2         Ashley         å…¶ä»–  ä½ å¯ä»¥æ¨è–¦å¹¾å€‹é©åˆä¸Šç­æ—æ”¾é¬†è½çš„ç¯€ç›®å—ï¼Ÿ                         NaN   \n",
      "3         Ashley         å…¶ä»–         æœ‰æ²’æœ‰æ¯æ—¥ï¼æ¯é€±æ¨è–¦æ¸…å–®ï¼Ÿ                         NaN   \n",
      "4         Ashley         å…¶ä»–  æœ‰é©åˆç¡å‰è½çš„æ”¾é¬† podcast å—ï¼Ÿ                         NaN   \n",
      "\n",
      "                                          Unnamed: 4         Unnamed: 5  \\\n",
      "0                                                 ç­”æ¡ˆ      ä¿®æ”¹æ–¹å‘(ä¸Šæ¬¡çš„ä¿®æ”¹å»ºè­°)   \n",
      "1  ä½ å•åˆ°è¶…ç†±é–€çš„è©±é¡Œï¼æœ€è¿‘ NVIDIA çœŸçš„å¾ˆç´…ï¼Œè‚¡åƒ¹ä¹Ÿä¸€ç›´åœ¨æ¼²ï¼Œå¾ˆå¤šäººéƒ½åœ¨é—œæ³¨ä»–å€‘çš„å‹•å‘ï¼...                NaN   \n",
      "2  ç•¶ç„¶å¯ä»¥ï¼é€™é‚Šæœ‰å¹¾å€‹é©åˆä¸‹ç­å¾Œæ”¾é¬†å¿ƒæƒ…çš„ Podcast ç¯€ç›®ï¼Œå…§å®¹è¼•é¬†æœ‰è¶£ï¼Œå¯ä»¥è®“ä½ æš«æ™‚é ...             ç°¡å–®/å…¥æ‰‹/   \n",
      "3  æœ‰çš„ï¼æˆ‘å€‘æœƒä¸å®šæœŸæ•´ç†ä¸€äº›ä¸»é¡Œæ¸…å–®ï¼Œä»¥ä¸‹æ˜¯æœ€æ–°ä¸€æœŸçš„é€±æ¨è–¦ï¼š\\n\\nğŸ“… æœ¬é€±ä¸»é¡Œï¼šã€Šæ™‚é–“ç®¡ç†...  å»ºç«‹å¦å¤–ä¸€å€‹åŸºæ–¼ç¶²é åŠŸèƒ½çš„å•é¡Œåˆ—è¡¨   \n",
      "4  ç•¶ç„¶æœ‰ï¼Œé€™é‚Šæ˜¯å¹¾å€‹ç¡å‰è¶…æ¨è–¦çš„ podcastï¼Œè²éŸ³æº«æŸ”ã€ç¯€å¥èˆ’ç·©ï¼Œéå¸¸é©åˆæ”¾é¬†å¿ƒæƒ…å…¥çœ ï¼š\\...                 æ”¾é¬†   \n",
      "\n",
      "   Unnamed: 6 Unnamed: 7  \n",
      "0         NaN        NaN  \n",
      "1         NaN        NaN  \n",
      "2         NaN        NaN  \n",
      "3         NaN             \n",
      "4         NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "csv_path = \"../scripts/csv/default_QA.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.head()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f088055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "\n",
    "def load_enviroments():\n",
    "    load_dotenv()\n",
    "    braintrust_api_key  =   os.getenv('braintrust_api_key')\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    return braintrust_api_key,openai_api_key\n",
    "braintrust_api_key, openai_api_key = load_enviroments()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "from braintrust import init_logger, traced, wrap_openai, Eval\n",
    "from openai import OpenAI\n",
    "\n",
    "logger = init_logger(project=\"Podwise\", api_key=braintrust_api_key)\n",
    "client = wrap_openai(OpenAI())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fe3ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import Field, BaseModel\n",
    "\n",
    "class QAPair(BaseModel):\n",
    "    reference: str = Field(..., description=\"The exact text segment from the original context that this Q&A is based on\")\n",
    "    question: str = Field(description=\"A single question about the content\")\n",
    "    answer: str = Field(..., description=\"Answer\")\n",
    "\n",
    "class QAPairs(BaseModel):\n",
    "    pairs: List[QAPair] = Field(..., description=\"List of question/answer pairs\")\n",
    "\n",
    "@traced\n",
    "def produce_questions(content):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Please generate 2 question/answer pairs from the following text, focusing specifically on podcast recommendations related to business and education topics.\n",
    "For each pair, provide a single question, a unique answer, and include the exact text segment from the original context that the Q&A is based on.\n",
    "\n",
    "IMPORTANT:\n",
    "1. Focus ONLY on business-related, entrepreneurship, management, marketing, leadership, lifelong learning, career development, or educational podcast topics.\n",
    "2. All questions and answers MUST be in Traditional Chinese (Taiwan).\n",
    "3. Use terminology and expressions commonly used in Taiwan's business and education sectors.\n",
    "4. If the context doesn't contain direct podcast recommendations, extract the most relevant aspects that could guide podcast listening decisions for business and education audiences.\n",
    "5. For each Q&A pair, include the exact text from the original context that contains the information used for the Q&A. This should be copied verbatim from the input context.\n",
    "\n",
    "Context: <context>{content}</context>\"\"\",\n",
    "            }\n",
    "        ],\n",
    "        response_format=QAPairs\n",
    "    )\n",
    "\n",
    "    parsed_result = completion.choices[0].message.parsed\n",
    "    pairs = parsed_result.pairs\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c544606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QAPair(reference='æœ‰å“ªäº›é »é“æœ‰æåˆ°é»ƒä»å‹³å˜›?', question='åœ¨å°‹æ‰¾èˆ‡æ¥­å‹™ç™¼å±•ç›¸é—œçš„æ’­å®¢æ¨è–¦æ™‚ï¼Œæœ‰å“ªäº›é »é“æœƒæåŠé»ƒä»å‹³ï¼Ÿ', answer='ç›®å‰çš„å…§å®¹ä¸¦æ²’æœ‰ç›´æ¥æ¨è–¦ä»»ä½•æ¶‰åŠé»ƒä»å‹³çš„æ¥­å‹™æˆ–é ˜å°ç›¸é—œæ’­å®¢é »é“ã€‚'),\n",
       " QAPair(reference='æœ‰å“ªäº›é »é“æœ‰æåˆ°é»ƒä»å‹³å˜›?', question='å¦‚æœè¦å¾æ•™è‚²æˆ–è·æ¶¯ç™¼å±•è§’åº¦æŒ‘é¸æ’­å®¢ï¼Œé€™æ®µæ–‡å­—æœ‰æä¾›ä»€éº¼æŒ‡å¼•å—ï¼Ÿ', answer='é€™æ®µæ–‡å­—æœªç›´æ¥æä¾›èˆ‡æ•™è‚²æˆ–è·æ¶¯ç™¼å±•ç›¸é—œçš„æ’­å®¢æ¨è–¦è³‡è¨Šã€‚')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = produce_questions('æœ‰å“ªäº›é »é“æœ‰æåˆ°é»ƒä»å‹³å˜›?')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "828aa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = x[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8b4fb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': 'æœ‰å“ªäº›é »é“æœ‰æåˆ°é»ƒä»å‹³å˜›?',\n",
       " 'question': 'æœ‰å“ªäº›é »é“æœƒè¨è«–èˆ‡å•†æ¥­èˆ‡æ•™è‚²ç›¸é—œçš„è©±é¡Œï¼Œæ¯”å¦‚ä¼æ¥­é ˜å°èˆ‡ç”¢æ¥­è¶¨å‹¢ï¼Ÿ',\n",
       " 'answer': 'é›–ç„¶åŸæ–‡åƒ…æåˆ°ã€Œæœ‰å“ªäº›é »é“æœ‰æåˆ°é»ƒä»å‹³å—ï¼Ÿã€ä½†ç”±æ­¤å¯ä»¥æ¨æ¸¬ï¼Œé—œæ³¨ç§‘æŠ€é ˜è¢–é»ƒä»å‹³çš„é »é“å¾€å¾€æœƒæ¶‰åŠå•†æ¥­ç­–ç•¥ã€é ˜å°åŠ›åŠç”¢æ¥­å‹•æ…‹çš„è¨è«–ï¼Œéå¸¸é©åˆæƒ³äº†è§£ä¼æ¥­ç®¡ç†èˆ‡ç”¢æ¥­è¶¨å‹¢çš„è½çœ¾ã€‚',\n",
       " 'test': 1234}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h['test'] = 1234\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6a75a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, header=1)\n",
    "\n",
    "dataset = []\n",
    "for idx, row in df.iterrows():\n",
    "    context = row['ç­”æ¡ˆ']  \n",
    "    pairs = produce_questions(context)\n",
    "    for pair in pairs:\n",
    "        h = pair.model_dump()\n",
    "        h[\"row_index\"] = idx\n",
    "        dataset.append(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dcfbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = []\n",
    "for qa in dataset:\n",
    "    eval_dataset.append(\n",
    "        {\n",
    "            \"input\": qa['question'],\n",
    "            \"expected\": qa['answer'],\n",
    "            \"metadata\": {\n",
    "                \"reference\": qa.get('reference', ''),  \n",
    "                'row_index': qa['row_index'],\n",
    "                'file_name': 'default_QA.csv'\n",
    "            },\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fdd4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NoRAG\n",
    "def simple_qa(question):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c0a6a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment No RAG-2571c55b is running at https://www.braintrust.dev/app/BDSE/p/Podwise/experiments/No%20RAG-2571c55b\n",
      "`Eval()` was called from an async context. For better performance, it is recommended to use `await EvalAsync()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-5' coro=<_EvalCommon.<locals>.run_to_completion() running at /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages/braintrust/framework.py:688>>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Podwise [experiment_name=No RAG] (data): 116it [00:00, 63883.83it/s]\n",
      "Podwise [experiment_name=No RAG] (tasks): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [03:53<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "No RAG-2571c55b compared to No RAG-0a53a921:\n",
      "56.03% 'Factuality' score\n",
      "\n",
      "1753066089.96s start\n",
      "1753066187.87s end\n",
      "31.69s duration\n",
      "7.91s llm_duration\n",
      "28.81tok prompt_tokens\n",
      "425.50tok completion_tokens\n",
      "454.31tok total_tokens\n",
      "0.00$ estimated_cost\n",
      "0tok prompt_cached_tokens\n",
      "0tok prompt_cache_creation_tokens\n",
      "\n",
      "See results for No RAG-2571c55b at https://www.braintrust.dev/app/BDSE/p/Podwise/experiments/No%20RAG-2571c55b\n"
     ]
    }
   ],
   "source": [
    "import autoevals\n",
    "\n",
    "Eval(\n",
    "    name=\"Podwise\",\n",
    "    experiment_name=\"No RAG\",\n",
    "    data=eval_dataset,\n",
    "    task=simple_qa,\n",
    "    scores=[autoevals.Factuality(model=\"gpt-4.1\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11bf2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection\n",
    "\n",
    "# 0. å»ºç«‹é€£ç·šï¼ˆæ”¹æˆä½ çš„ host / port / å¸³å¯†ï¼‰\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=\"192.168.32.86\",\n",
    "    port=\"19530\",\n",
    ")\n",
    "\n",
    "# 1. å–å¾—å·²å­˜åœ¨çš„ collectionï¼Œä¸¦ load é€²è¨˜æ†¶é«”\n",
    "col = Collection(\"podcast_chunks\")   # â† ä½ çš„ collection å\n",
    "col.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c55c411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain_text_splitters in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain_text_splitters) (0.3.69)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (23.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.7.1)\n",
      "Requirement already satisfied: certifi in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e61f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken_ext.openai_public          # å…ˆè¨»å†Š OpenAI ç·¨ç¢¼\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\") # gpt-4o æ˜¯ o200k_baseï¼Œä¹‹å‰ç‰ˆæœ¬ gpt-4-turbo å’Œ gpt-3.5-turbo æ˜¯ cl100k_base\n",
    "\n",
    "def length_function(text: str):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(length_function=length_function, chunk_size=800, chunk_overlap=200, separators=[\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \".\",\n",
    "    \",\",\n",
    "    \"\\u200b\",  # Zero-width space\n",
    "    \"\\uff0c\",  # Fullwidth comma ï¼Œ\n",
    "    \"\\u3001\",  # Ideographic comma ã€\n",
    "    \"\\uff0e\",  # Fullwidth full stop ï¼\n",
    "    \"\\u3002\",  # Ideographic full stop ã€‚\n",
    "    \"\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4bac9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "  response = client.embeddings.create(\n",
    "      input=text,\n",
    "      model=\"bge-m3\"\n",
    "  )\n",
    "\n",
    "  return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ee972df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `bge-m3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_idx, page_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df):          \u001b[38;5;66;03m# df è£¡çš„å…ƒç´ éƒ½æ˜¯ str\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     chunks      \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(page_text)\n\u001b[0;32m---> 14\u001b[0m     embeddings  \u001b[38;5;241m=\u001b[39m [get_embeddings(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chunks]          \u001b[38;5;66;03m# âš ï¸ 1024 ç¶­\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     n           \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunks)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# === æº–å‚™å„æ¬„ä½è³‡æ–™ ===\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[79], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_idx, page_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df):          \u001b[38;5;66;03m# df è£¡çš„å…ƒç´ éƒ½æ˜¯ str\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     chunks      \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(page_text)\n\u001b[0;32m---> 14\u001b[0m     embeddings  \u001b[38;5;241m=\u001b[39m [\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chunks]          \u001b[38;5;66;03m# âš ï¸ 1024 ç¶­\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     n           \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunks)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# === æº–å‚™å„æ¬„ä½è³‡æ–™ ===\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_embeddings\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbge-m3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/braintrust/oai.py:591\u001b[0m, in \u001b[0;36mEmbeddingV1Wrapper.create\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEmbeddingWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_raw_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/braintrust/oai.py:461\u001b[0m, in \u001b[0;36mBaseWrapper.create\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_params(kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m start_span(\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge_dicts(\u001b[38;5;28mdict\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, span_attributes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: SpanTypeAttribute\u001b[38;5;241m.\u001b[39mLLM}), params)\n\u001b[1;32m    460\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m span:\n\u001b[0;32m--> 461\u001b[0m     create_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(create_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparse\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    464\u001b[0m         raw_response \u001b[38;5;241m=\u001b[39m create_response\u001b[38;5;241m.\u001b[39mparse()\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_legacy_response.py:356\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `bge-m3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "from pymilvus import Collection\n",
    "\n",
    "# 0ï¸âƒ£ é€£ç·šã€å–å¾—æ­£å¼ collection â”€â”€ å·²å®Œæˆå¯ç•¥\n",
    "# connections.connect(... )\n",
    "col = Collection(\"podcast_chunks\")\n",
    "\n",
    "# 1ï¸âƒ£ å¦‚æœæ²’æœ‰ test åˆ†å€å°±å…ˆå»ºä¸€å€‹\n",
    "if \"test\" not in [p.name for p in col.partitions]:\n",
    "    col.create_partition(\"test\")\n",
    "\n",
    "# 2ï¸âƒ£ é€é åˆ‡ç‰‡ â†’ æ‰¹é‡å¯«å…¥ test åˆ†å€\n",
    "for page_idx, page_text in enumerate(df):          # df è£¡çš„å…ƒç´ éƒ½æ˜¯ str\n",
    "    chunks      = text_splitter.split_text(page_text)\n",
    "    embeddings  = [get_embeddings(c) for c in chunks]          # âš ï¸ 1024 ç¶­\n",
    "    n           = len(chunks)\n",
    "\n",
    "    # === æº–å‚™å„æ¬„ä½è³‡æ–™ ===\n",
    "    chunk_ids       = [f\"TEST_ep0_p{page_idx}_c{i}\" for i in range(n)]\n",
    "    chunk_indexes   = list(range(n))\n",
    "    episode_ids     = [0] * n           # ç„¡çœŸå¯¦ episode å°±å…ˆç”¨ 0 / -1\n",
    "    podcast_ids     = [0] * n\n",
    "    blank           = [\"\"] * n\n",
    "    zeros           = [0.0] * n\n",
    "    languages       = [\"test\"] * n      # æˆ– \"zh\"\n",
    "    source_models   = [\"text-embedding-3-small\"] * n\n",
    "    tags            = [\"test\"] * n\n",
    "\n",
    "    # æŒ‰ schema é †åºçµ„æˆ data list\n",
    "    data = [\n",
    "        chunk_ids,\n",
    "        chunk_indexes,\n",
    "        episode_ids,\n",
    "        podcast_ids,\n",
    "        blank,          # podcast_name\n",
    "        blank,          # author\n",
    "        blank,          # category\n",
    "        blank,          # episode_title\n",
    "        blank,          # duration\n",
    "        blank,          # published_date\n",
    "        zeros,          # apple_rating\n",
    "        zeros,          # sentiment_rating\n",
    "        zeros,          # total_rating\n",
    "        chunks,         # chunk_text\n",
    "        embeddings,     # embedding (1024-dim vector)\n",
    "        languages,      # language\n",
    "        blank,          # created_at\n",
    "        source_models,  # source_model\n",
    "        tags            # tags\n",
    "    ]\n",
    "\n",
    "    col.insert(data, partition_name=\"test\")   # â­ å¯«é€² test åˆ†å€\n",
    "\n",
    "# 3ï¸âƒ£ è½ç›¤\n",
    "col.flush()\n",
    "print(\"âœ… æ¸¬è©¦ç‰‡æ®µå·²å…¨éƒ¨å¯«å…¥ã€podcast_chunksã€çš„ test åˆ†å€\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
