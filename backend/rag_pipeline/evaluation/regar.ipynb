# RAG 系統完整架構
# 使用 Milvus 向量資料庫 + bge-m3 + Qwen2.5-Taiwan-7B-Instruct

## 1. 環境設置和套件安裝

```bash
# 執行此區塊前請先安裝必要套件
!pip install pymilvus transformers torch sentence-transformers pandas numpy openai huggingface_hub accelerate bitsandbytes
```

## 2. 導入必要套件

```python
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Tuple
import os
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Milvus 相關
from pymilvus import connections, Collection, utility, FieldSchema, CollectionSchema, DataType

# 模型相關
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

# OpenAI (如果需要備用)
import openai
```

## 3. 配置參數設定

```python
# 配置參數
class Config:
    # Milvus 配置
    MILVUS_HOST = "localhost"  # 請根據您的設置修改
    MILVUS_PORT = "19530"     # 請根據您的設置修改
    COLLECTION_NAME = "podwise_chunks"
    
    # 向量維度
    VECTOR_DIM = 1024
    
    # 模型配置
    EMBEDDING_MODEL = "BAAI/bge-m3"
    LLM_MODEL = "benchang1110/Qwen2.5-Taiwan-7B-Instruct"
    
    # OpenAI 配置 (備用)
    OPENAI_API_KEY = "your-openai-api-key"  # 請填入您的 OpenAI API Key
    
    # 檢索參數
    TOP_K = 5
    SIMILARITY_THRESHOLD = 0.7
    
    # 生成參數
    MAX_LENGTH = 2048
    TEMPERATURE = 0.7

config = Config()
```

## 4. 初始化模型和連接

```python
class RAGSystem:
    def __init__(self):
        self.config = config
        self.embedding_model = None
        self.llm_model = None
        self.tokenizer = None
        self.collection = None
        
    def initialize_embedding_model(self):
        """初始化嵌入模型 bge-m3"""
        print("正在載入嵌入模型...")
        self.embedding_model = SentenceTransformer(self.config.EMBEDDING_MODEL)
        print("嵌入模型載入完成")
        
    def initialize_llm_model(self):
        """初始化 LLM 模型"""
        print("正在載入 LLM 模型...")
        self.tokenizer = AutoTokenizer.from_pretrained(self.config.LLM_MODEL)
        
        # 使用 GPU 如果可用
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        self.llm_model = AutoModelForCausalLM.from_pretrained(
            self.config.LLM_MODEL,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            device_map="auto" if device == "cuda" else None,
            trust_remote_code=True
        )
        print(f"LLM 模型載入完成，使用設備: {device}")
        
    def connect_milvus(self):
        """連接 Milvus 資料庫"""
        try:
            connections.connect("default", host=self.config.MILVUS_HOST, port=self.config.MILVUS_PORT)
            print("成功連接到 Milvus")
            
            # 檢查集合是否存在
            if utility.has_collection(self.config.COLLECTION_NAME):
                self.collection = Collection(self.config.COLLECTION_NAME)
                self.collection.load()
                print(f"成功載入集合: {self.config.COLLECTION_NAME}")
            else:
                print(f"集合 {self.config.COLLECTION_NAME} 不存在")
                
        except Exception as e:
            print(f"連接 Milvus 失敗: {e}")
            
    def initialize_all(self):
        """初始化所有組件"""
        self.initialize_embedding_model()
        self.initialize_llm_model()
        self.connect_milvus()

# 創建 RAG 系統實例
rag_system = RAGSystem()
```

## 5. 載入測試資料

```python
def load_test_data(csv_path: str) -> pd.DataFrame:
    """載入測試 CSV 資料"""
    try:
        df = pd.read_csv(csv_path)
        print(f"成功載入測試資料，共 {len(df)} 筆")
        print("資料欄位:", df.columns.tolist())
        return df
    except Exception as e:
        print(f"載入測試資料失敗: {e}")
        return None

# 請指定您的 CSV 檔案路徑
CSV_PATH = "your_test_data.csv"  # 請修改為您的檔案路徑
test_data = load_test_data(CSV_PATH)

# 顯示資料概覽
if test_data is not None:
    print("\n資料概覽:")
    print(test_data.head())
```

## 6. 查詢向量化

```python
def vectorize_query(query: str) -> np.ndarray:
    """將查詢文本轉換為向量"""
    if rag_system.embedding_model is None:
        raise ValueError("嵌入模型未初始化")
        
    embedding = rag_system.embedding_model.encode([query])
    return embedding[0].astype(np.float32)

# 測試向量化功能
test_query = "什麼是人工智慧？"
test_vector = vectorize_query(test_query)
print(f"測試查詢: {test_query}")
print(f"向量維度: {test_vector.shape}")
print(f"向量前5個值: {test_vector[:5]}")
```

## 7. 向量檢索功能

```python
def search_similar_chunks(query_vector: np.ndarray, top_k: int = None) -> List[Dict]:
    """在 Milvus 中搜尋相似的文本塊"""
    if top_k is None:
        top_k = config.TOP_K
        
    if rag_system.collection is None:
        raise ValueError("Milvus 集合未連接")
        
    search_params = {
        "metric_type": "COSINE",
        "params": {"nprobe": 16}
    }
    
    # 執行向量搜尋
    results = rag_system.collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=[
            "chunk_id", "chunk_text", "podcast_name", "author", 
            "episode_title", "category", "published_date"
        ]
    )
    
    retrieved_chunks = []
    for hits in results:
        for hit in hits:
            chunk_data = {
                "chunk_id": hit.entity.get("chunk_id"),
                "chunk_text": hit.entity.get("chunk_text"),
                "podcast_name": hit.entity.get("podcast_name"),
                "author": hit.entity.get("author"),
                "episode_title": hit.entity.get("episode_title"),
                "category": hit.entity.get("category"),
                "published_date": hit.entity.get("published_date"),
                "similarity_score": hit.score
            }
            retrieved_chunks.append(chunk_data)
    
    return retrieved_chunks
```

## 8. LLM 文本生成

```python
def generate_response(query: str, context_chunks: List[Dict]) -> str:
    """使用檢索到的上下文生成回答"""
    
    # 構建上下文
    context_text = ""
    for i, chunk in enumerate(context_chunks, 1):
        context_text += f"\n參考資料 {i}:\n"
        context_text += f"來源: {chunk['podcast_name']} - {chunk['episode_title']}\n"
        context_text += f"內容: {chunk['chunk_text']}\n"
        context_text += f"相似度: {chunk['similarity_score']:.4f}\n"
    
    # 構建提示詞
    prompt = f"""基於以下參考資料回答問題。請提供準確、有用的回答，並在適當時引用資料來源。

參考資料:
{context_text}

問題: {query}

回答:"""
    
    # 使用模型生成回答
    inputs = rag_system.tokenizer.encode(prompt, return_tensors="pt")
    
    with torch.no_grad():
        outputs = rag_system.llm_model.generate(
            inputs,
            max_length=len(inputs[0]) + config.MAX_LENGTH,
            temperature=config.TEMPERATURE,
            do_sample=True,
            pad_token_id=rag_system.tokenizer.eos_token_id
        )
    
    # 解碼回答
    full_response = rag_system.tokenizer.decode(outputs[0], skip_special_tokens=True)
    response = full_response[len(prompt):].strip()
    
    return response
```

## 9. 完整的 RAG 查詢流程

```python
def rag_query(query: str) -> Dict[str, Any]:
    """完整的 RAG 查詢流程"""
    
    print(f"\n🔍 查詢: {query}")
    print("=" * 80)
    
    # 步驟 1: 查詢向量化
    print("1. 正在進行查詢向量化...")
    query_vector = vectorize_query(query)
    
    # 步驟 2: 向量檢索
    print("2. 正在檢索相關文檔...")
    retrieved_chunks = search_similar_chunks(query_vector)
    
    if not retrieved_chunks:
        return {
            "query": query,
            "answer": "抱歉，沒有找到相關的資料。",
            "retrieved_chunks": [],
            "timestamp": datetime.now().isoformat()
        }
    
    # 步驟 3: 生成回答
    print("3. 正在生成回答...")
    answer = generate_response(query, retrieved_chunks)
    
    # 步驟 4: 整理結果
    result = {
        "query": query,
        "answer": answer,
        "retrieved_chunks": retrieved_chunks,
        "timestamp": datetime.now().isoformat()
    }
    
    print("4. 查詢完成!")
    return result
```

## 10. 測試集評估功能

```python
def evaluate_test_set(test_df: pd.DataFrame, query_column: str, expected_answer_column: str = None):
    """評估測試集"""
    
    results = []
    
    print(f"開始評估測試集，共 {len(test_df)} 個查詢...")
    
    for index, row in test_df.iterrows():
        query = row[query_column]
        expected_answer = row[expected_answer_column] if expected_answer_column else None
        
        print(f"\n處理第 {index + 1}/{len(test_df)} 個查詢...")
        
        try:
            result = rag_query(query)
            result['test_index'] = index
            result['expected_answer'] = expected_answer
            results.append(result)
            
        except Exception as e:
            print(f"查詢失敗: {e}")
            results.append({
                "test_index": index,
                "query": query,
                "answer": f"錯誤: {e}",
                "expected_answer": expected_answer,
                "retrieved_chunks": [],
                "timestamp": datetime.now().isoformat()
            })
    
    return results

def save_evaluation_results(results: List[Dict], output_path: str):
    """儲存評估結果"""
    results_df = pd.DataFrame(results)
    results_df.to_csv(output_path, index=False, encoding='utf-8')
    print(f"評估結果已儲存至: {output_path}")
```

## 11. 主要執行區塊

```python
# 初始化系統
print("正在初始化 RAG 系統...")
rag_system.initialize_all()

# 如果有測試資料，進行評估
if test_data is not None and len(test_data) > 0:
    # 假設測試資料有 'query' 欄位，如果有期望答案欄位請指定
    QUERY_COLUMN = "query"  # 請根據您的資料修改
    EXPECTED_ANSWER_COLUMN = None  # 如果有期望答案欄位，請指定欄位名稱
    
    # 執行測試集評估
    evaluation_results = evaluate_test_set(test_data, QUERY_COLUMN, EXPECTED_ANSWER_COLUMN)
    
    # 儲存結果
    output_path = f"rag_evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    save_evaluation_results(evaluation_results, output_path)
    
else:
    print("未找到測試資料，可以手動測試查詢:")
    
    # 手動測試範例
    test_queries = [
        "什麼是人工智慧？",
        "如何學習程式設計？",
        "健康飲食的建議有哪些？"
    ]
    
    for query in test_queries:
        result = rag_query(query)
        print(f"\n📋 查詢結果:")
        print(f"問題: {result['query']}")
        print(f"回答: {result['answer']}")
        print(f"檢索到 {len(result['retrieved_chunks'])} 個相關文檔")
```

## 12. 結果分析和視覺化

```python
def analyze_results(results: List[Dict]):
    """分析評估結果"""
    
    print("\n📊 評估結果分析:")
    print("=" * 50)
    
    total_queries = len(results)
    successful_queries = sum(1 for r in results if not r['answer'].startswith('錯誤:'))
    
    print(f"總查詢數: {total_queries}")
    print(f"成功查詢數: {successful_queries}")
    print(f"成功率: {successful_queries/total_queries*100:.2f}%")
    
    # 檢索文檔數量統計
    doc_counts = [len(r['retrieved_chunks']) for r in results if r['retrieved_chunks']]
    if doc_counts:
        print(f"平均檢索文檔數: {np.mean(doc_counts):.2f}")
        print(f"檢索文檔數範圍: {min(doc_counts)} - {max(doc_counts)}")
    
    # 相似度分數統計
    similarity_scores = []
    for result in results:
        for chunk in result.get('retrieved_chunks', []):
            similarity_scores.append(chunk['similarity_score'])
    
    if similarity_scores:
        print(f"平均相似度分數: {np.mean(similarity_scores):.4f}")
        print(f"相似度分數範圍: {min(similarity_scores):.4f} - {max(similarity_scores):.4f}")

# 如果有評估結果，進行分析
if 'evaluation_results' in locals():
    analyze_results(evaluation_results)
```

## 13. 工具函數

```python
def display_query_details(result: Dict):
    """顯示查詢的詳細結果"""
    print(f"\n🔍 查詢: {result['query']}")
    print(f"⏰ 時間: {result['timestamp']}")
    print(f"\n💡 回答:\n{result['answer']}")
    
    print(f"\n📚 檢索到的相關文檔 ({len(result['retrieved_chunks'])} 個):")
    for i, chunk in enumerate(result['retrieved_chunks'], 1):
        print(f"\n文檔 {i}:")
        print(f"  來源: {chunk['podcast_name']} - {chunk['episode_title']}")
        print(f"  作者: {chunk['author']}")
        print(f"  分類: {chunk['category']}")
        print(f"  相似度: {chunk['similarity_score']:.4f}")
        print(f"  內容預覽: {chunk['chunk_text'][:200]}...")

def interactive_query():
    """互動式查詢介面"""
    while True:
        query = input("\n請輸入查詢 (輸入 'quit' 結束): ").strip()
        
        if query.lower() == 'quit':
            break
            
        if not query:
            continue
            
        try:
            result = rag_query(query)
            display_query_details(result)
        except Exception as e:
            print(f"查詢錯誤: {e}")

# 啟動互動式查詢 (可選)
# interactive_query()
```

print("✅ RAG 系統架構完成！")
print("請確保:")
print("1. 修改 Config 類別中的參數以符合您的環境")
print("2. 確保 Milvus 服務正在運行")
print("3. 指定正確的測試 CSV 檔案路徑")
print("4. 根據您的 CSV 欄位名稱修改 QUERY_COLUMN 變數")