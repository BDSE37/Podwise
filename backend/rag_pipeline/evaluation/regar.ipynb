{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0c9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: braintrust in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (0.1.8)\n",
      "Requirement already satisfied: autoevals in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (0.0.129)\n",
      "Requirement already satisfied: openai in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (1.55.3)\n",
      "Requirement already satisfied: GitPython in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (3.1.44)\n",
      "Requirement already satisfied: requests in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (2.31.0)\n",
      "Requirement already satisfied: chevron in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.2.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (1.3.0)\n",
      "Requirement already satisfied: python-dotenv in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (1.0.0)\n",
      "Requirement already satisfied: sseclient-py in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (1.8.0)\n",
      "Requirement already satisfied: python-slugify in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (8.0.4)\n",
      "Requirement already satisfied: typing_extensions>=4.1.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from braintrust) (4.14.1)\n",
      "Requirement already satisfied: polyleven in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (0.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (6.0.2)\n",
      "Requirement already satisfied: braintrust_core==0.0.59 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (0.0.59)\n",
      "Requirement already satisfied: jsonschema in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from autoevals) (4.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from GitPython->braintrust) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython->braintrust) (5.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonschema->autoevals) (0.26.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from python-slugify->braintrust) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests->braintrust) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests->braintrust) (2.5.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install braintrust autoevals openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f27065f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 Unnamed: 1            Unnamed: 2                  Unnamed: 3  \\\n",
      "0            提問人         類別   問題 (keywords請幫我標紅字)  Mapping到的tag (請參考tag列表第C列)   \n",
      "1  LI HSIN HSIEH         其他    最近NVIDIA好像很紅，他是什麼?                      NVIDIA   \n",
      "2         Ashley         其他  你可以推薦幾個適合上班族放鬆聽的節目嗎？                         NaN   \n",
      "3         Ashley         其他         有沒有每日／每週推薦清單？                         NaN   \n",
      "4         Ashley         其他  有適合睡前聽的放鬆 podcast 嗎？                         NaN   \n",
      "\n",
      "                                          Unnamed: 4         Unnamed: 5  \\\n",
      "0                                                 答案      修改方向(上次的修改建議)   \n",
      "1  你問到超熱門的話題！最近 NVIDIA 真的很紅，股價也一直在漲，很多人都在關注他們的動向！...                NaN   \n",
      "2  當然可以！這邊有幾個適合下班後放鬆心情的 Podcast 節目，內容輕鬆有趣，可以讓你暫時遠...             簡單/入手/   \n",
      "3  有的！我們會不定期整理一些主題清單，以下是最新一期的週推薦：\\n\\n📅 本週主題：《時間管理...  建立另外一個基於網頁功能的問題列表   \n",
      "4  當然有，這邊是幾個睡前超推薦的 podcast，聲音溫柔、節奏舒緩，非常適合放鬆心情入眠：\\...                 放鬆   \n",
      "\n",
      "   Unnamed: 6 Unnamed: 7  \n",
      "0         NaN        NaN  \n",
      "1         NaN        NaN  \n",
      "2         NaN        NaN  \n",
      "3         NaN             \n",
      "4         NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "csv_path = \"../scripts/csv/default_QA.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.head()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f088055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "\n",
    "def load_enviroments():\n",
    "    load_dotenv()\n",
    "    braintrust_api_key  =   os.getenv('braintrust_api_key')\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    return braintrust_api_key,openai_api_key\n",
    "braintrust_api_key, openai_api_key = load_enviroments()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "from braintrust import init_logger, traced, wrap_openai, Eval\n",
    "from openai import OpenAI\n",
    "\n",
    "logger = init_logger(project=\"Podwise\", api_key=braintrust_api_key)\n",
    "client = wrap_openai(OpenAI())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fe3ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import Field, BaseModel\n",
    "\n",
    "class QAPair(BaseModel):\n",
    "    reference: str = Field(..., description=\"The exact text segment from the original context that this Q&A is based on\")\n",
    "    question: str = Field(description=\"A single question about the content\")\n",
    "    answer: str = Field(..., description=\"Answer\")\n",
    "\n",
    "class QAPairs(BaseModel):\n",
    "    pairs: List[QAPair] = Field(..., description=\"List of question/answer pairs\")\n",
    "\n",
    "@traced\n",
    "def produce_questions(content):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Please generate 2 question/answer pairs from the following text, focusing specifically on podcast recommendations related to business and education topics.\n",
    "For each pair, provide a single question, a unique answer, and include the exact text segment from the original context that the Q&A is based on.\n",
    "\n",
    "IMPORTANT:\n",
    "1. Focus ONLY on business-related, entrepreneurship, management, marketing, leadership, lifelong learning, career development, or educational podcast topics.\n",
    "2. All questions and answers MUST be in Traditional Chinese (Taiwan).\n",
    "3. Use terminology and expressions commonly used in Taiwan's business and education sectors.\n",
    "4. If the context doesn't contain direct podcast recommendations, extract the most relevant aspects that could guide podcast listening decisions for business and education audiences.\n",
    "5. For each Q&A pair, include the exact text from the original context that contains the information used for the Q&A. This should be copied verbatim from the input context.\n",
    "\n",
    "Context: <context>{content}</context>\"\"\",\n",
    "            }\n",
    "        ],\n",
    "        response_format=QAPairs\n",
    "    )\n",
    "\n",
    "    parsed_result = completion.choices[0].message.parsed\n",
    "    pairs = parsed_result.pairs\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c544606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QAPair(reference='有哪些頻道有提到黃仁勳嘛?', question='在尋找與業務發展相關的播客推薦時，有哪些頻道會提及黃仁勳？', answer='目前的內容並沒有直接推薦任何涉及黃仁勳的業務或領導相關播客頻道。'),\n",
       " QAPair(reference='有哪些頻道有提到黃仁勳嘛?', question='如果要從教育或職涯發展角度挑選播客，這段文字有提供什麼指引嗎？', answer='這段文字未直接提供與教育或職涯發展相關的播客推薦資訊。')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = produce_questions('有哪些頻道有提到黃仁勳嘛?')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "828aa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = x[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8b4fb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': '有哪些頻道有提到黃仁勳嘛?',\n",
       " 'question': '有哪些頻道會討論與商業與教育相關的話題，比如企業領導與產業趨勢？',\n",
       " 'answer': '雖然原文僅提到「有哪些頻道有提到黃仁勳嗎？」但由此可以推測，關注科技領袖黃仁勳的頻道往往會涉及商業策略、領導力及產業動態的討論，非常適合想了解企業管理與產業趨勢的聽眾。',\n",
       " 'test': 1234}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h['test'] = 1234\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6a75a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, header=1)\n",
    "\n",
    "dataset = []\n",
    "for idx, row in df.iterrows():\n",
    "    context = row['答案']  \n",
    "    pairs = produce_questions(context)\n",
    "    for pair in pairs:\n",
    "        h = pair.model_dump()\n",
    "        h[\"row_index\"] = idx\n",
    "        dataset.append(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dcfbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = []\n",
    "for qa in dataset:\n",
    "    eval_dataset.append(\n",
    "        {\n",
    "            \"input\": qa['question'],\n",
    "            \"expected\": qa['answer'],\n",
    "            \"metadata\": {\n",
    "                \"reference\": qa.get('reference', ''),  \n",
    "                'row_index': qa['row_index'],\n",
    "                'file_name': 'default_QA.csv'\n",
    "            },\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fdd4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NoRAG\n",
    "def simple_qa(question):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c0a6a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment No RAG-2571c55b is running at https://www.braintrust.dev/app/BDSE/p/Podwise/experiments/No%20RAG-2571c55b\n",
      "`Eval()` was called from an async context. For better performance, it is recommended to use `await EvalAsync()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-5' coro=<_EvalCommon.<locals>.run_to_completion() running at /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages/braintrust/framework.py:688>>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Podwise [experiment_name=No RAG] (data): 116it [00:00, 63883.83it/s]\n",
      "Podwise [experiment_name=No RAG] (tasks): 100%|██████████| 116/116 [03:53<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "No RAG-2571c55b compared to No RAG-0a53a921:\n",
      "56.03% 'Factuality' score\n",
      "\n",
      "1753066089.96s start\n",
      "1753066187.87s end\n",
      "31.69s duration\n",
      "7.91s llm_duration\n",
      "28.81tok prompt_tokens\n",
      "425.50tok completion_tokens\n",
      "454.31tok total_tokens\n",
      "0.00$ estimated_cost\n",
      "0tok prompt_cached_tokens\n",
      "0tok prompt_cache_creation_tokens\n",
      "\n",
      "See results for No RAG-2571c55b at https://www.braintrust.dev/app/BDSE/p/Podwise/experiments/No%20RAG-2571c55b\n"
     ]
    }
   ],
   "source": [
    "import autoevals\n",
    "\n",
    "Eval(\n",
    "    name=\"Podwise\",\n",
    "    experiment_name=\"No RAG\",\n",
    "    data=eval_dataset,\n",
    "    task=simple_qa,\n",
    "    scores=[autoevals.Factuality(model=\"gpt-4.1\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11bf2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection\n",
    "\n",
    "# 0. 建立連線（改成你的 host / port / 帳密）\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=\"192.168.32.86\",\n",
    "    port=\"19530\",\n",
    ")\n",
    "\n",
    "# 1. 取得已存在的 collection，並 load 進記憶體\n",
    "col = Collection(\"podcast_chunks\")   # ← 你的 collection 名\n",
    "col.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c55c411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain_text_splitters in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain_text_splitters) (0.3.69)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (23.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.7.1)\n",
      "Requirement already satisfied: certifi in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/bai/Desktop/Podwise/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e61f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken_ext.openai_public          # 先註冊 OpenAI 編碼\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\") # gpt-4o 是 o200k_base，之前版本 gpt-4-turbo 和 gpt-3.5-turbo 是 cl100k_base\n",
    "\n",
    "def length_function(text: str):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(length_function=length_function, chunk_size=800, chunk_overlap=200, separators=[\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \".\",\n",
    "    \",\",\n",
    "    \"\\u200b\",  # Zero-width space\n",
    "    \"\\uff0c\",  # Fullwidth comma ，\n",
    "    \"\\u3001\",  # Ideographic comma 、\n",
    "    \"\\uff0e\",  # Fullwidth full stop ．\n",
    "    \"\\u3002\",  # Ideographic full stop 。\n",
    "    \"\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4bac9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "  response = client.embeddings.create(\n",
    "      input=text,\n",
    "      model=\"bge-m3\"\n",
    "  )\n",
    "\n",
    "  return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ee972df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `bge-m3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_idx, page_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df):          \u001b[38;5;66;03m# df 裡的元素都是 str\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     chunks      \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(page_text)\n\u001b[0;32m---> 14\u001b[0m     embeddings  \u001b[38;5;241m=\u001b[39m [get_embeddings(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chunks]          \u001b[38;5;66;03m# ⚠️ 1024 維\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     n           \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunks)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# === 準備各欄位資料 ===\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[79], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_idx, page_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df):          \u001b[38;5;66;03m# df 裡的元素都是 str\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     chunks      \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(page_text)\n\u001b[0;32m---> 14\u001b[0m     embeddings  \u001b[38;5;241m=\u001b[39m [\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chunks]          \u001b[38;5;66;03m# ⚠️ 1024 維\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     n           \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunks)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# === 準備各欄位資料 ===\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_embeddings\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbge-m3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/braintrust/oai.py:591\u001b[0m, in \u001b[0;36mEmbeddingV1Wrapper.create\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEmbeddingWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_raw_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/braintrust/oai.py:461\u001b[0m, in \u001b[0;36mBaseWrapper.create\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_params(kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m start_span(\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge_dicts(\u001b[38;5;28mdict\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, span_attributes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: SpanTypeAttribute\u001b[38;5;241m.\u001b[39mLLM}), params)\n\u001b[1;32m    460\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m span:\n\u001b[0;32m--> 461\u001b[0m     create_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(create_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparse\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    464\u001b[0m         raw_response \u001b[38;5;241m=\u001b[39m create_response\u001b[38;5;241m.\u001b[39mparse()\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_legacy_response.py:356\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Podwise/.venv/lib/python3.10/site-packages/openai/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `bge-m3` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "from pymilvus import Collection\n",
    "\n",
    "# 0️⃣ 連線、取得正式 collection ── 已完成可略\n",
    "# connections.connect(... )\n",
    "col = Collection(\"podcast_chunks\")\n",
    "\n",
    "# 1️⃣ 如果沒有 test 分區就先建一個\n",
    "if \"test\" not in [p.name for p in col.partitions]:\n",
    "    col.create_partition(\"test\")\n",
    "\n",
    "# 2️⃣ 逐頁切片 → 批量寫入 test 分區\n",
    "for page_idx, page_text in enumerate(df):          # df 裡的元素都是 str\n",
    "    chunks      = text_splitter.split_text(page_text)\n",
    "    embeddings  = [get_embeddings(c) for c in chunks]          # ⚠️ 1024 維\n",
    "    n           = len(chunks)\n",
    "\n",
    "    # === 準備各欄位資料 ===\n",
    "    chunk_ids       = [f\"TEST_ep0_p{page_idx}_c{i}\" for i in range(n)]\n",
    "    chunk_indexes   = list(range(n))\n",
    "    episode_ids     = [0] * n           # 無真實 episode 就先用 0 / -1\n",
    "    podcast_ids     = [0] * n\n",
    "    blank           = [\"\"] * n\n",
    "    zeros           = [0.0] * n\n",
    "    languages       = [\"test\"] * n      # 或 \"zh\"\n",
    "    source_models   = [\"text-embedding-3-small\"] * n\n",
    "    tags            = [\"test\"] * n\n",
    "\n",
    "    # 按 schema 順序組成 data list\n",
    "    data = [\n",
    "        chunk_ids,\n",
    "        chunk_indexes,\n",
    "        episode_ids,\n",
    "        podcast_ids,\n",
    "        blank,          # podcast_name\n",
    "        blank,          # author\n",
    "        blank,          # category\n",
    "        blank,          # episode_title\n",
    "        blank,          # duration\n",
    "        blank,          # published_date\n",
    "        zeros,          # apple_rating\n",
    "        zeros,          # sentiment_rating\n",
    "        zeros,          # total_rating\n",
    "        chunks,         # chunk_text\n",
    "        embeddings,     # embedding (1024-dim vector)\n",
    "        languages,      # language\n",
    "        blank,          # created_at\n",
    "        source_models,  # source_model\n",
    "        tags            # tags\n",
    "    ]\n",
    "\n",
    "    col.insert(data, partition_name=\"test\")   # ⭐ 寫進 test 分區\n",
    "\n",
    "# 3️⃣ 落盤\n",
    "col.flush()\n",
    "print(\"✅ 測試片段已全部寫入『podcast_chunks』的 test 分區\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
