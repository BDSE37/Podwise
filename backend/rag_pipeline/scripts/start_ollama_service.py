#!/usr/bin/env python3
"""
Ollama æœå‹™å•Ÿå‹•è…³æœ¬

è‡ªå‹•å•Ÿå‹• Ollama æœå‹™ä¸¦è¼‰å…¥æŒ‡å®šæ¨¡å‹
ä½œè€…: Podwise Team
ç‰ˆæœ¬: 1.0.0
"""

import subprocess
import time
import logging
import requests
from typing import Optional, List

logger = logging.getLogger(__name__)


class OllamaServiceManager:
    """Ollama æœå‹™ç®¡ç†å™¨"""
    
    def __init__(self, models: Optional[List[str]] = None):
        # é è¨­è¼‰å…¥å…©å€‹æ¨¡å‹
        self.models = models or [
            "benchang1110/Qwen2.5-Taiwan-7B-Instruct",
            "Qwen/Qwen3-8B"
        ]
        self.ollama_url = "http://localhost:11434"
        self.is_running = False
    
    def start_ollama_service(self) -> bool:
        """å•Ÿå‹• Ollama æœå‹™"""
        try:
            # æª¢æŸ¥ Ollama æ˜¯å¦å·²åœ¨é‹è¡Œ
            if self._check_ollama_running():
                logger.info("âœ… Ollama æœå‹™å·²åœ¨é‹è¡Œ")
                self.is_running = True
                return True
            
            # å•Ÿå‹• Ollama æœå‹™
            logger.info("ğŸš€ å•Ÿå‹• Ollama æœå‹™...")
            subprocess.Popen(["ollama", "serve"], 
                           stdout=subprocess.DEVNULL, 
                           stderr=subprocess.DEVNULL)
            
            # ç­‰å¾…æœå‹™å•Ÿå‹•
            for i in range(30):  # æœ€å¤šç­‰å¾… 30 ç§’
                time.sleep(1)
                if self._check_ollama_running():
                    logger.info("âœ… Ollama æœå‹™å•Ÿå‹•æˆåŠŸ")
                    self.is_running = True
                    return True
            
            logger.error("âŒ Ollama æœå‹™å•Ÿå‹•è¶…æ™‚")
            return False
            
        except Exception as e:
            logger.error(f"âŒ å•Ÿå‹• Ollama æœå‹™å¤±æ•—: {e}")
            return False
    
    def load_model(self) -> bool:
        """è¼‰å…¥æŒ‡å®šæ¨¡å‹"""
        try:
            if not self.is_running:
                logger.error("âŒ Ollama æœå‹™æœªé‹è¡Œ")
                return False
            
            logger.info(f"ğŸ“¥ è¼‰å…¥æ¨¡å‹: {self.models}")
            
            # ä½¿ç”¨ ollama pull è¼‰å…¥æ¨¡å‹
            for model_name in self.models:
                result = subprocess.run(
                    ["ollama", "pull", model_name],
                    capture_output=True,
                    text=True,
                    timeout=300  # 5åˆ†é˜è¶…æ™‚
                )
                
                if result.returncode == 0:
                    logger.info(f"âœ… æ¨¡å‹ {model_name} è¼‰å…¥æˆåŠŸ")
                else:
                    logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {result.stderr}")
                    return False
            return True
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ æ¨¡å‹è¼‰å…¥è¶…æ™‚")
            return False
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            return False
    
    def test_model(self) -> bool:
        """æ¸¬è©¦æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        try:
            if not self.is_running:
                return False
            
            # ç™¼é€ç°¡å–®çš„æ¸¬è©¦è«‹æ±‚
            test_data = {
                "model": self.models[0], # æ¸¬è©¦ç¬¬ä¸€å€‹æ¨¡å‹
                "prompt": "ä½ å¥½",
                "stream": False
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=test_data,
                timeout=30
            )
            
            if response.status_code == 200:
                logger.info("âœ… æ¨¡å‹æ¸¬è©¦æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def _check_ollama_running(self) -> bool:
        """æª¢æŸ¥ Ollama æ˜¯å¦åœ¨é‹è¡Œ"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_available_models(self) -> list:
        """ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        try:
            if not self._check_ollama_running():
                return []
            
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=10)
            if response.status_code == 200:
                data = response.json()
                return [model["name"] for model in data.get("models", [])]
            else:
                return []
                
        except Exception as e:
            logger.error(f"ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {e}")
            return []
    
    def stop_service(self):
        """åœæ­¢ Ollama æœå‹™"""
        try:
            subprocess.run(["pkill", "ollama"], 
                         stdout=subprocess.DEVNULL, 
                         stderr=subprocess.DEVNULL)
            logger.info("ğŸ›‘ Ollama æœå‹™å·²åœæ­¢")
            self.is_running = False
        except Exception as e:
            logger.error(f"åœæ­¢ Ollama æœå‹™å¤±æ•—: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Ollama æœå‹™ç®¡ç†å™¨")
    parser.add_argument("--models", nargs="+", 
                       default=["benchang1110/Qwen2.5-Taiwan-7B-Instruct", "Qwen/Qwen3-8B"],
                       help="è¦è¼‰å…¥çš„æ¨¡å‹åç¨±åˆ—è¡¨")
    parser.add_argument("--action", choices=["start", "stop", "test"], 
                       default="start", help="åŸ·è¡Œå‹•ä½œ")
    
    args = parser.parse_args()
    
    # è¨­å®šæ—¥èªŒ
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(levelname)s - %(message)s')
    
    manager = OllamaServiceManager(args.models)
    
    if args.action == "start":
        # å•Ÿå‹•æœå‹™
        if manager.start_ollama_service():
            # è¼‰å…¥æ¨¡å‹
            if manager.load_model():
                # æ¸¬è©¦æ¨¡å‹
                if manager.test_model():
                    logger.info("ğŸ‰ Ollama æœå‹™å®Œå…¨å°±ç·’ï¼")
                else:
                    logger.error("âŒ æ¨¡å‹æ¸¬è©¦å¤±æ•—")
            else:
                logger.error("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—")
        else:
            logger.error("âŒ æœå‹™å•Ÿå‹•å¤±æ•—")
    
    elif args.action == "stop":
        manager.stop_service()
    
    elif args.action == "test":
        if manager._check_ollama_running():
            models = manager.get_available_models()
            logger.info(f"å¯ç”¨æ¨¡å‹: {models}")
            if manager.test_model():
                logger.info("âœ… æœå‹™æ¸¬è©¦æˆåŠŸ")
            else:
                logger.error("âŒ æœå‹™æ¸¬è©¦å¤±æ•—")
        else:
            logger.error("âŒ Ollama æœå‹™æœªé‹è¡Œ")


if __name__ == "__main__":
    main() 