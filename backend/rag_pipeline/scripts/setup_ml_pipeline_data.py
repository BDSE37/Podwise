#!/usr/bin/env python3
"""
ML Pipeline è³‡æ–™è¨­å®šè…³æœ¬

ç‚º ML Pipeline æº–å‚™æ¸¬è©¦è³‡æ–™å’Œæ¨¡æ“¬è³‡æ–™
ä½œè€…: Podwise Team
ç‰ˆæœ¬: 1.0.0
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, Any, List
from datetime import datetime, timedelta
import random

logger = logging.getLogger(__name__)


class MLPipelineDataSetup:
    """ML Pipeline è³‡æ–™è¨­å®šå™¨"""
    
    def __init__(self):
        self.podcast_categories = [
            "å•†æ¥­è²¡ç¶“", "ç§‘æŠ€å‰µæ–°", "æ•™è‚²å­¸ç¿’", "å¥åº·ç”Ÿæ´»", 
            "å¨›æ¨‚ä¼‘é–’", "ç¤¾æœƒæ–‡åŒ–", "åœ‹éš›æ–°è", "ç§‘å­¸æ¢ç´¢"
        ]
        
        self.podcast_names = [
            "å•†æ¥­é€±åˆŠ", "ç§‘æŠ€æ—©çŸ¥é“", "å­¸ç¿’æˆé•·", "å¥åº·ç”Ÿæ´»æŒ‡å—",
            "å¨›æ¨‚æ–°è", "ç¤¾æœƒè§€å¯Ÿ", "åœ‹éš›è¦–é‡", "ç§‘å­¸æ¢ç´¢"
        ]
    
    def create_mock_podcast_data(self, num_episodes: int = 100) -> pd.DataFrame:
        """å‰µå»ºæ¨¡æ“¬ Podcast è³‡æ–™"""
        logger.info(f"å‰µå»º {num_episodes} å€‹æ¨¡æ“¬ Podcast è³‡æ–™")
        
        data = []
        for i in range(num_episodes):
            episode = {
                'episode_id': f'episode_{i+1:04d}',
                'episode_title': f'{random.choice(self.podcast_names)} - ç¬¬{i+1}é›†',
                'description': f'é€™æ˜¯ç¬¬{i+1}é›†çš„è©³ç´°æè¿°ï¼ŒåŒ…å«è±å¯Œçš„å…§å®¹å’Œè³‡è¨Šã€‚',
                'category': random.choice(self.podcast_categories),
                'tags': self._generate_random_tags(),
                'duration': random.randint(1800, 7200),  # 30-120åˆ†é˜
                'publish_date': datetime.now() - timedelta(days=random.randint(1, 365)),
                'rating': round(random.uniform(3.5, 5.0), 1),
                'view_count': random.randint(100, 10000),
                'like_count': random.randint(10, 1000)
            }
            data.append(episode)
        
        df = pd.DataFrame(data)
        logger.info(f"âœ… å‰µå»º Podcast è³‡æ–™æˆåŠŸ: {len(df)} ç­†")
        return df
    
    def create_mock_user_history(self, num_users: int = 50, num_interactions: int = 200) -> pd.DataFrame:
        """å‰µå»ºæ¨¡æ“¬ç”¨æˆ¶æ­·å²è³‡æ–™"""
        logger.info(f"å‰µå»º {num_users} å€‹ç”¨æˆ¶çš„ {num_interactions} ç­†äº’å‹•è³‡æ–™")
        
        data = []
        for i in range(num_interactions):
            interaction = {
                'user_id': f'user_{random.randint(1, num_users):03d}',
                'episode_id': f'episode_{random.randint(1, 100):04d}',
                'rating': random.randint(1, 5),
                'like_count': random.randint(0, 10),
                'preview_play_count': random.randint(0, 50),
                'interaction_date': datetime.now() - timedelta(days=random.randint(1, 90)),
                'interaction_type': random.choice(['play', 'like', 'share', 'comment']),
                'duration_watched': random.randint(60, 3600)  # 1-60åˆ†é˜
            }
            data.append(interaction)
        
        df = pd.DataFrame(data)
        logger.info(f"âœ… å‰µå»ºç”¨æˆ¶æ­·å²è³‡æ–™æˆåŠŸ: {len(df)} ç­†")
        return df
    
    def create_mock_user_preferences(self, num_users: int = 50) -> pd.DataFrame:
        """å‰µå»ºæ¨¡æ“¬ç”¨æˆ¶åå¥½è³‡æ–™"""
        logger.info(f"å‰µå»º {num_users} å€‹ç”¨æˆ¶çš„åå¥½è³‡æ–™")
        
        data = []
        for i in range(num_users):
            user_prefs = {
                'user_id': f'user_{i+1:03d}',
                'preferred_categories': random.sample(self.podcast_categories, random.randint(1, 3)),
                'preferred_duration': random.choice(['short', 'medium', 'long']),
                'preferred_language': random.choice(['zh-TW', 'en-US', 'ja-JP']),
                'notification_enabled': random.choice([True, False]),
                'created_at': datetime.now() - timedelta(days=random.randint(1, 365)),
                'last_updated': datetime.now() - timedelta(days=random.randint(1, 30))
            }
            data.append(user_prefs)
        
        df = pd.DataFrame(data)
        logger.info(f"âœ… å‰µå»ºç”¨æˆ¶åå¥½è³‡æ–™æˆåŠŸ: {len(df)} ç­†")
        return df
    
    def _generate_random_tags(self) -> List[str]:
        """ç”Ÿæˆéš¨æ©Ÿæ¨™ç±¤"""
        all_tags = [
            "æŠ•è³‡ç†è²¡", "ç§‘æŠ€å‰µæ–°", "å‰µæ¥­æ•…äº‹", "è·å ´ç™¼å±•", "å¥åº·é¤Šç”Ÿ",
            "å¿ƒç†å­¸", "æ­·å²æ–‡åŒ–", "åœ‹éš›é—œä¿‚", "ç’°å¢ƒä¿è­·", "è—è¡“è¨­è¨ˆ",
            "éŸ³æ¨‚æ¬£è³", "é›»å½±è©•è«–", "ç¾é£Ÿæ–‡åŒ–", "æ—…éŠæ¢ç´¢", "é‹å‹•å¥èº«",
            "è¦ªå­æ•™è‚²", "äººéš›é—œä¿‚", "æ™‚é–“ç®¡ç†", "å­¸ç¿’æ–¹æ³•", "å‰µæ„æ€ç¶­"
        ]
        
        num_tags = random.randint(2, 5)
        return random.sample(all_tags, num_tags)
    
    def save_mock_data(self, output_dir: str = "data/mock_data"):
        """å„²å­˜æ¨¡æ“¬è³‡æ–™"""
        import os
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(output_dir, exist_ok=True)
        
        # å‰µå»ºå„ç¨®æ¨¡æ“¬è³‡æ–™
        podcast_data = self.create_mock_podcast_data()
        user_history = self.create_mock_user_history()
        user_preferences = self.create_mock_user_preferences()
        
        # å„²å­˜ç‚º CSV æª”æ¡ˆ
        podcast_data.to_csv(f"{output_dir}/podcast_data.csv", index=False)
        user_history.to_csv(f"{output_dir}/user_history.csv", index=False)
        user_preferences.to_csv(f"{output_dir}/user_preferences.csv", index=False)
        
        logger.info(f"âœ… æ¨¡æ“¬è³‡æ–™å·²å„²å­˜åˆ° {output_dir}")
        
        return {
            'podcast_data': podcast_data,
            'user_history': user_history,
            'user_preferences': user_preferences
        }
    
    def create_ml_pipeline_config(self) -> Dict[str, Any]:
        """å‰µå»º ML Pipeline é…ç½®"""
        config = {
            'data_paths': {
                'podcast_data': 'data/mock_data/podcast_data.csv',
                'user_history': 'data/mock_data/user_history.csv',
                'user_preferences': 'data/mock_data/user_preferences.csv'
            },
            'model_config': {
                'recommendation_algorithm': 'collaborative_filtering',
                'similarity_metric': 'cosine',
                'top_k_recommendations': 10,
                'min_interactions': 5
            },
            'training_config': {
                'test_size': 0.2,
                'random_state': 42,
                'cross_validation_folds': 5
            },
            'evaluation_metrics': [
                'precision_at_k',
                'recall_at_k',
                'ndcg_at_k',
                'map_at_k'
            ]
        }
        
        logger.info("âœ… ML Pipeline é…ç½®å·²å‰µå»º")
        return config


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ML Pipeline è³‡æ–™è¨­å®š")
    parser.add_argument("--output-dir", default="data/mock_data", 
                       help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--num-episodes", type=int, default=100,
                       help="Podcast é›†æ•¸")
    parser.add_argument("--num-users", type=int, default=50,
                       help="ç”¨æˆ¶æ•¸é‡")
    parser.add_argument("--num-interactions", type=int, default=200,
                       help="äº’å‹•æ•¸é‡")
    
    args = parser.parse_args()
    
    # è¨­å®šæ—¥èªŒ
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(levelname)s - %(message)s')
    
    # å‰µå»ºè³‡æ–™è¨­å®šå™¨
    setup = MLPipelineDataSetup()
    
    # å‰µå»ºæ¨¡æ“¬è³‡æ–™
    data = setup.save_mock_data(args.output_dir)
    
    # å‰µå»ºé…ç½®
    config = setup.create_ml_pipeline_config()
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    print("\nğŸ“Š è³‡æ–™çµ±è¨ˆ:")
    print(f"Podcast è³‡æ–™: {len(data['podcast_data'])} ç­†")
    print(f"ç”¨æˆ¶æ­·å²: {len(data['user_history'])} ç­†")
    print(f"ç”¨æˆ¶åå¥½: {len(data['user_preferences'])} ç­†")
    
    print("\nğŸ¯ é…ç½®è³‡è¨Š:")
    for key, value in config.items():
        print(f"{key}: {value}")


if __name__ == "__main__":
    main() 