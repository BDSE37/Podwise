#!/bin/bash

# Kubernetes ç‰ˆæœ¬ Ollama æ¨¡å‹ä¿®å¾©è…³æœ¬
# è§£æ±ºå‘é‡ç¶­åº¦ä¸åŒ¹é…å’Œ LLM æ¨¡å‹ä¸å­˜åœ¨å•é¡Œ

set -e

echo "ğŸ”§ é–‹å§‹ä¿®å¾© Kubernetes Ollama æ¨¡å‹..."

# æª¢æŸ¥ kubectl
if ! command -v kubectl &> /dev/null; then
    echo "âŒ kubectl æœªå®‰è£"
    exit 1
fi

# ç²å– Ollama Pod
echo "ğŸ” ç²å– Ollama Pod..."
OLLAMA_POD=$(kubectl get pods -n podwise -l app=ollama-service -o jsonpath='{.items[0].metadata.name}')
if [ -z "$OLLAMA_POD" ]; then
    echo "âŒ ç„¡æ³•ç²å– Ollama Pod"
    exit 1
fi

echo "ğŸ“‹ Ollama Pod: $OLLAMA_POD"

# æª¢æŸ¥ Ollama æœå‹™
echo "ğŸ” æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹..."
sleep 10
if ! kubectl exec -n podwise $OLLAMA_POD -- curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âŒ Ollama æœå‹™æœªæ­£å¸¸é‹è¡Œ"
    exit 1
fi

echo "âœ… Ollama æœå‹™æ­£å¸¸"

# ä¸‹è¼‰å¿…è¦çš„åµŒå…¥æ¨¡å‹
echo "ğŸ“¥ ä¸‹è¼‰åµŒå…¥æ¨¡å‹..."

echo "ğŸ“¥ ä¸‹è¼‰ BGE-M3 åµŒå…¥æ¨¡å‹ (1024ç¶­)..."
kubectl exec -n podwise $OLLAMA_POD -- ollama pull BAAI/bge-m3

echo "ğŸ“¥ ä¸‹è¼‰ Nomic åµŒå…¥æ¨¡å‹ (å‚™ç”¨)..."
kubectl exec -n podwise $OLLAMA_POD -- ollama pull nomic-embed-text

echo "ğŸ“¥ ä¸‹è¼‰ All-MiniLM åµŒå…¥æ¨¡å‹ (å‚™ç”¨)..."
kubectl exec -n podwise $OLLAMA_POD -- ollama pull all-minilm

# ä¸‹è¼‰å¿…è¦çš„ LLM æ¨¡å‹
echo "ğŸ“¥ ä¸‹è¼‰ LLM æ¨¡å‹..."

echo "ğŸ“¥ ä¸‹è¼‰å°ç£ç‰ˆæœ¬æ¨¡å‹..."
kubectl exec -n podwise $OLLAMA_POD -- ollama pull weiren119/Qwen2.5-Taiwan-8B-Instruct

echo "ğŸ“¥ ä¸‹è¼‰ Qwen2.5 æ¨¡å‹..."
kubectl exec -n podwise $OLLAMA_POD -- ollama pull Qwen/Qwen2.5-8B-Instruct

echo "ğŸ“¥ ä¸‹è¼‰ Qwen3 æ¨¡å‹..."
kubectl exec -n podwise $OLLAMA_POD -- ollama pull qwen2.5:8b

echo "ğŸ“¥ ä¸‹è¼‰ GPT-3.5 æ¨¡å‹..."
kubectl exec -n podwise $OLLAMA_POD -- ollama pull gpt-3.5-turbo

# é©—è­‰æ¨¡å‹
echo "âœ… é©—è­‰æ¨¡å‹..."
kubectl exec -n podwise $OLLAMA_POD -- ollama list

echo "ğŸ§ª æ¸¬è©¦å°ç£ç‰ˆæœ¬æ¨¡å‹..."
kubectl exec -n podwise $OLLAMA_POD -- ollama run qwen2.5-taiwan-7b-instruct "ä½ å¥½ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼šä½ æ˜¯èª°ï¼Ÿ" --timeout 30

echo "ğŸ§ª æ¸¬è©¦ BGE-M3 åµŒå…¥æ¨¡å‹..."
kubectl exec -n podwise $OLLAMA_POD -- bash -c '
curl -X POST http://localhost:11434/api/embeddings \
  -H "Content-Type: application/json" \
  -d '"'"'{"model": "bge-m3", "prompt": "æ¸¬è©¦æ–‡æœ¬"}'"'"' | jq ".embedding | length"
'

echo "ğŸ‰ Kubernetes Ollama æ¨¡å‹ä¿®å¾©å®Œæˆï¼"
echo ""
echo "ğŸ“‹ å¯ç”¨æ¨¡å‹:"
kubectl exec -n podwise $OLLAMA_POD -- ollama list
echo ""
echo "ğŸŒ Ollama æœå‹™: http://worker1:31134"
echo "ğŸ“š ä¸»è¦æ¨¡å‹:"
echo "   - qwen2.5-taiwan-7b-instruct (å°ç£ç‰ˆæœ¬)"
echo "   - bge-m3 (1024ç¶­åµŒå…¥)"
echo ""
echo "ğŸ§ª æ¸¬è©¦å‘½ä»¤:"
echo "   kubectl exec -n podwise $OLLAMA_POD -- ollama run qwen2.5-taiwan-7b-instruct 'ä½ å¥½'"
echo "   kubectl exec -n podwise $OLLAMA_POD -- curl -X POST http://localhost:11434/api/embeddings -H 'Content-Type: application/json' -d '{\"model\": \"bge-m3\", \"prompt\": \"æ¸¬è©¦\"}'" 