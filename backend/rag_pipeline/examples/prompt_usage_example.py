#!/usr/bin/env python3
"""
Podwise RAG å•ç­”æ©Ÿå™¨äººæç¤ºè©ä½¿ç”¨ç¯„ä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æç¤ºè©æ¨¡æ¿é€²è¡Œï¼š
1. å•é¡Œåˆ†é¡
2. èªæ„æª¢ç´¢ï¼ˆæ•´åˆ text2vec-base-chinese å’Œ TAG_info.csvï¼‰
3. å°ˆå®¶è©•ä¼°
4. é ˜å°è€…æ±ºç­–
5. å›ç­”ç”Ÿæˆ
6. Langfuse é›²ç«¯ç›£æ§ LLM æ€è€ƒéç¨‹

ä½œè€…: Podwise Team
ç‰ˆæœ¬: 1.0.0
"""

import json
import sys
import os
import time
import uuid
from datetime import datetime

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.prompt_templates import PodwisePromptTemplates, format_prompt, get_prompt_template
from config.integrated_config import get_config
from utils.langfuse_integration import get_langfuse_monitor


def demonstrate_langfuse_monitoring():
    """å±•ç¤º Langfuse ç›£æ§åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ“Š Langfuse é›²ç«¯ç›£æ§å±•ç¤º")
    print("=" * 60)
    
    # ç²å– Langfuse ç›£æ§å™¨
    monitor = get_langfuse_monitor()
    
    if not monitor.is_enabled():
        print("âš ï¸ Langfuse ç›£æ§æœªå•Ÿç”¨")
        print("   è«‹è¨­å®šç’°å¢ƒè®Šæ•¸ï¼š")
        print("   - LANGFUSE_PUBLIC_KEY")
        print("   - LANGFUSE_SECRET_KEY")
        print("   - LANGFUSE_HOST (å¯é¸ï¼Œé è¨­ç‚º https://cloud.langfuse.com)")
        return
    
    print("âœ… Langfuse ç›£æ§å·²å•Ÿç”¨")
    
    # å‰µå»ºè¿½è¹¤
    trace_id = monitor.create_trace(
        name="RAG Pipeline å®Œæ•´æµç¨‹æ¼”ç¤º",
        user_id="demo_user_001",
        metadata={
            "demo_type": "prompt_usage_example",
            "version": "1.0.0",
            "timestamp": datetime.now().isoformat()
        }
    )
    
    if trace_id:
        print(f"ğŸ“ˆ è¿½è¹¤ ID: {trace_id}")
        print(f"ğŸŒ è¿½è¹¤ URL: {monitor.get_trace_url(trace_id)}")
        
        # æ¨¡æ“¬æ€è€ƒéç¨‹è¿½è¹¤
        thinking_steps = [
            {
                "type": "query_analysis",
                "input": {"query": "æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡"},
                "output": {"keywords": ["å­¸ç¿’", "æŠ•è³‡", "ç†è²¡"], "intent": "educational"},
                "confidence": 0.9
            },
            {
                "type": "category_classification",
                "input": {"keywords": ["å­¸ç¿’", "æŠ•è³‡", "ç†è²¡"]},
                "output": {"category": "å•†æ¥­", "confidence": 0.85},
                "confidence": 0.85
            },
            {
                "type": "semantic_retrieval",
                "input": {"query": "æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡", "category": "å•†æ¥­"},
                "output": {"results_count": 5, "avg_confidence": 0.78},
                "confidence": 0.78
            }
        ]
        
        monitor.trace_thinking_process(
            trace_id=trace_id,
            query="æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡ï¼Œæœ‰ä»€éº¼æ¨è–¦çš„ Podcast å—ï¼Ÿ",
            thinking_steps=thinking_steps,
            final_decision="æ¨è–¦å•†æ¥­é¡æŠ•è³‡ç†è²¡ç¯€ç›®"
        )
        
        # æ¨¡æ“¬æ¨¡å‹é¸æ“‡è¿½è¹¤
        monitor.trace_model_selection(
            trace_id=trace_id,
            available_models=["qwen2.5-7b", "qwen2.5-14b", "qwen2.5-32b"],
            selected_model="qwen2.5-14b",
            selection_reason="å¹³è¡¡æ•ˆèƒ½å’Œæº–ç¢ºæ€§",
            performance_metrics={
                "response_time": 2.5,
                "accuracy": 0.92,
                "cost": "medium"
            }
        )
        
        # æ¨¡æ“¬ä»£ç†äº’å‹•è¿½è¹¤
        monitor.trace_agent_interactions(
            trace_id=trace_id,
            agent_name="BusinessExpert",
            agent_role="å•†æ¥­å°ˆå®¶",
            input_data={"query": "æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡", "category": "å•†æ¥­"},
            output_data={"recommendations": 3, "confidence": 0.85},
            confidence=0.85,
            processing_time=1.2
        )
        
        # æ¨¡æ“¬èªæ„æª¢ç´¢è¿½è¹¤
        monitor.trace_semantic_retrieval(
            trace_id=trace_id,
            query="æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡",
            semantic_score=0.82,
            tag_matches=[
                {"tag": "æŠ•è³‡", "score": 0.9, "matched_words": ["æŠ•è³‡"]},
                {"tag": "ç†è²¡", "score": 0.85, "matched_words": ["ç†è²¡"]}
            ],
            hybrid_score=0.835,
            final_results=[
                {"title": "è‚¡ç™Œ EP123_æŠ•è³‡æ–°æ‰‹å¿…è½", "confidence": 0.85},
                {"title": "äººç”Ÿå¯¦ç”¨å•†å­¸é™¢ EP45_ç†è²¡è¦åŠƒ", "confidence": 0.75}
            ]
        )
        
        # æ¨¡æ“¬å®Œæ•´ RAG Pipeline è¿½è¹¤
        monitor.trace_rag_pipeline(
            trace_id=trace_id,
            query="æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡ï¼Œæœ‰ä»€éº¼æ¨è–¦çš„ Podcast å—ï¼Ÿ",
            category="å•†æ¥­",
            rag_results={
                "category_result": {"category": "å•†æ¥­", "confidence": 0.85},
                "rag_result": [
                    {"title": "è‚¡ç™Œ EP123_æŠ•è³‡æ–°æ‰‹å¿…è½", "confidence": 0.85},
                    {"title": "äººç”Ÿå¯¦ç”¨å•†å­¸é™¢ EP45_ç†è²¡è¦åŠƒ", "confidence": 0.75}
                ]
            },
            final_response="æ ¹æ“šæ‚¨çš„æŠ•è³‡ç†è²¡éœ€æ±‚ï¼Œæˆ‘æ¨è–¦ä»¥ä¸‹ç¯€ç›®ï¼š1. è‚¡ç™Œ EP123_æŠ•è³‡æ–°æ‰‹å¿…è½ 2. äººç”Ÿå¯¦ç”¨å•†å­¸é™¢ EP45_ç†è²¡è¦åŠƒ",
            confidence=0.85,
            processing_time=3.2
        )
        
        # çµæŸè¿½è¹¤
        monitor.end_trace(trace_id, "success")
        print("âœ… è¿½è¹¤å®Œæˆ")
        
    else:
        print("âŒ å‰µå»ºè¿½è¹¤å¤±æ•—")


def demonstrate_semantic_retrieval():
    """å±•ç¤ºèªæ„æª¢ç´¢å’Œæ¨™ç±¤æ¯”å°åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ” èªæ„æª¢ç´¢å’Œæ¨™ç±¤æ¯”å°åŠŸèƒ½å±•ç¤º")
    print("=" * 60)
    
    # ç²å–èªæ„æª¢ç´¢é…ç½®
    config_manager = get_config()
    
    # é¡¯ç¤ºé…ç½®è³‡è¨Š
    print("\nğŸ“‹ èªæ„æª¢ç´¢é…ç½®ï¼š")
    model_config = config_manager.get_model_config()
    print(f"  æ¨¡å‹ï¼š{model_config['model_name']}")
    print(f"  è·¯å¾‘ï¼š{model_config['model_path']}")
    print(f"  æœ€å¤§é•·åº¦ï¼š{model_config['max_length']}")
    
    retrieval_config = config_manager.get_retrieval_config()
    print(f"  èªæ„æ¬Šé‡ï¼š{retrieval_config['semantic_weight_factor']}")
    print(f"  æ¨™ç±¤æ¬Šé‡ï¼š{retrieval_config['tag_weight_factor']}")
    print(f"  ä¿¡å¿ƒåº¦é–¾å€¼ï¼š0.7")
    
    # é¡¯ç¤ºæ¨™ç±¤çµ±è¨ˆ
    tag_stats = config_manager.get_tag_statistics()
    print(f"\nğŸ“Š æ¨™ç±¤çµ±è¨ˆï¼š")
    if "error" not in tag_stats:
        print(f"  ç¸½æ¨™ç±¤æ•¸ï¼š{tag_stats['total_tags']}")
        for category, count in tag_stats['categories'].items():
            print(f"  {category}ï¼š{count} å€‹æ¨™ç±¤")
    else:
        print(f"  æ¨™ç±¤è¼‰å…¥ç‹€æ…‹ï¼š{tag_stats['error']}")
    
    # æ¸¬è©¦æ¨™ç±¤åŒ¹é…
    test_queries = [
        "æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡ï¼Œæœ‰ä»€éº¼æ¨è–¦çš„ Podcast å—ï¼Ÿ",
        "æœ€è¿‘æƒ³äº†è§£ AI æŠ€è¡“ç™¼å±•è¶¨å‹¢",
        "é€šå‹¤æ™‚æƒ³è½ä¸€äº›è¼•é¬†çš„ç¯€ç›®",
        "æƒ³å­¸ç¿’è·æ¶¯è¦åŠƒå’Œå€‹äººæˆé•·"
    ]
    
    print(f"\nğŸ§ª æ¨™ç±¤åŒ¹é…æ¸¬è©¦ï¼š")
    for i, query in enumerate(test_queries, 1):
        print(f"\n{i}. æŸ¥è©¢ï¼š{query}")
        matches = config_manager.match_query_tags(query)
        
        if matches:
            print("   åŒ¹é…æ¨™ç±¤ï¼š")
            for tag, score, matched_words in matches[:3]:
                print(f"     {tag}: {score:.2f} ({', '.join(matched_words)})")
        else:
            print("   ç„¡åŒ¹é…æ¨™ç±¤")
    
    # æ¸¬è©¦æ··åˆåˆ†æ•¸è¨ˆç®—
    print(f"\nğŸ“ˆ æ··åˆåˆ†æ•¸è¨ˆç®—ç¯„ä¾‹ï¼š")
    test_cases = [
        (0.8, 0.6, "é«˜èªæ„ + ä¸­æ¨™ç±¤"),
        (0.6, 0.8, "ä¸­èªæ„ + é«˜æ¨™ç±¤"),
        (0.9, 0.9, "é«˜èªæ„ + é«˜æ¨™ç±¤"),
        (0.4, 0.3, "ä½èªæ„ + ä½æ¨™ç±¤")
    ]
    
    for semantic_score, tag_score, description in test_cases:
        hybrid_score = config_manager.calculate_hybrid_score(semantic_score, tag_score)
        confidence = "âœ… é€šé" if hybrid_score >= 0.7 else "âŒ ä¸é€šé"
        print(f"  {description}: èªæ„={semantic_score:.1f}, æ¨™ç±¤={tag_score:.1f}, æ··åˆ={hybrid_score:.3f} {confidence}")


def demonstrate_prompt_usage():
    """å±•ç¤ºæç¤ºè©æ¨¡æ¿ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ğŸ¯ æç¤ºè©æ¨¡æ¿ä½¿ç”¨å±•ç¤º")
    print("=" * 60)
    
    # æ¸¬è©¦ç”¨æˆ¶å•é¡Œ
    user_question = "æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡ï¼Œæœ‰ä»€éº¼æ¨è–¦çš„ Podcast å—ï¼Ÿ"
    print(f"\nğŸ‘¤ ç”¨æˆ¶å•é¡Œï¼š{user_question}")
    
    # 1. å•é¡Œåˆ†é¡
    print(f"\nğŸ“Š 1. å•é¡Œåˆ†é¡")
    classifier_prompt = get_prompt_template("category_classifier")
    formatted_classifier = format_prompt(classifier_prompt, user_question=user_question)
    print(f"åˆ†é¡æç¤ºè©é•·åº¦ï¼š{len(formatted_classifier)} å­—å…ƒ")
    
    # æ¨¡æ“¬åˆ†é¡çµæœ
    category_result = {
        "categories": [
            {
                "category": "å•†æ¥­",
                "confidence": 0.85,
                "keywords": ["æŠ•è³‡", "ç†è²¡"],
                "reasoning": "ç”¨æˆ¶æ˜ç¢ºæåˆ°æŠ•è³‡ç†è²¡ï¼Œå±¬æ–¼å•†æ¥­é¡åˆ¥"
            },
            {
                "category": "æ•™è‚²",
                "confidence": 0.45,
                "keywords": ["å­¸ç¿’"],
                "reasoning": "æåˆ°å­¸ç¿’ï¼Œä½†ä¸»è¦å…§å®¹æ˜¯æŠ•è³‡ç†è²¡"
            }
        ],
        "primary_category": "å•†æ¥­",
        "is_multi_category": False,
        "cross_category_keywords": []
    }
    
    # 2. èªæ„æª¢ç´¢
    print(f"\nğŸ” 2. èªæ„æª¢ç´¢")
    retrieval_prompt = get_prompt_template("semantic_retrieval")
    formatted_retrieval = format_prompt(
        retrieval_prompt, 
        user_query=user_question,
        category_result=json.dumps(category_result, ensure_ascii=False, indent=2)
    )
    print(f"æª¢ç´¢æç¤ºè©é•·åº¦ï¼š{len(formatted_retrieval)} å­—å…ƒ")
    
    # æ¨¡æ“¬æª¢ç´¢çµæœ
    search_results = [
        {
            "title": "è‚¡ç™Œ EP123_æŠ•è³‡æ–°æ‰‹å¿…è½",
            "episode": "EP123",
            "rss_id": "stock_cancer_123",
            "category": "å•†æ¥­",
            "similarity_score": 0.85,
            "tag_score": 0.7,
            "hybrid_score": 0.805,
            "updated_at": "2024-01-15",
            "summary": "å°ˆé–€ç‚ºæŠ•è³‡æ–°æ‰‹è¨­è¨ˆçš„ç†è²¡è§€å¿µåˆ†äº«"
        },
        {
            "title": "äººç”Ÿå¯¦ç”¨å•†å­¸é™¢ EP45_ç†è²¡è¦åŠƒ",
            "episode": "EP45",
            "rss_id": "business_school_45",
            "category": "å•†æ¥­",
            "similarity_score": 0.75,
            "tag_score": 0.8,
            "hybrid_score": 0.765,
            "updated_at": "2024-01-10",
            "summary": "å¯¦ç”¨çš„ç†è²¡è¦åŠƒå»ºè­°å’Œç­–ç•¥"
        }
    ]
    
    # 3. å°ˆå®¶è©•ä¼°
    print(f"\nğŸ“ 3. å°ˆå®¶è©•ä¼°")
    expert_prompt = get_prompt_template("business_expert")
    formatted_expert = format_prompt(
        expert_prompt,
        search_results=json.dumps(search_results, ensure_ascii=False, indent=2),
        user_question=user_question
    )
    print(f"å°ˆå®¶è©•ä¼°æç¤ºè©é•·åº¦ï¼š{len(formatted_expert)} å­—å…ƒ")
    
    # æ¨¡æ“¬å°ˆå®¶è©•ä¼°çµæœ
    expert_results = {
        "category": "å•†æ¥­",
        "recommendations": [
            {
                "title": "è‚¡ç™Œ EP123_æŠ•è³‡æ–°æ‰‹å¿…è½",
                "episode": "EP123",
                "rss_id": "stock_cancer_123",
                "confidence": 0.85,
                "updated_at": "2024-01-15",
                "reason": "å°ˆé–€ç‚ºæŠ•è³‡æ–°æ‰‹è¨­è¨ˆï¼Œå…§å®¹å¯¦ç”¨æ˜“æ‡‚"
            },
            {
                "title": "äººç”Ÿå¯¦ç”¨å•†å­¸é™¢ EP45_ç†è²¡è¦åŠƒ",
                "episode": "EP45",
                "rss_id": "business_school_45",
                "confidence": 0.75,
                "updated_at": "2024-01-10",
                "reason": "æä¾›å¯¦ç”¨çš„ç†è²¡è¦åŠƒå»ºè­°"
            }
        ],
        "status": "success",
        "high_confidence_count": 2
    }
    
    # 4. é ˜å°è€…æ±ºç­–
    print(f"\nğŸ‘‘ 4. é ˜å°è€…æ±ºç­–")
    leader_prompt = get_prompt_template("leader_decision")
    formatted_leader = format_prompt(
        leader_prompt,
        expert_results=json.dumps(expert_results, ensure_ascii=False, indent=2),
        user_question=user_question
    )
    print(f"é ˜å°è€…æ±ºç­–æç¤ºè©é•·åº¦ï¼š{len(formatted_leader)} å­—å…ƒ")
    
    # 5. å›ç­”ç”Ÿæˆ
    print(f"\nğŸ’¬ 5. å›ç­”ç”Ÿæˆ")
    answer_prompt = get_prompt_template("answer_generation")
    formatted_answer = format_prompt(
        answer_prompt,
        user_question=user_question,
        final_recommendations=json.dumps(expert_results["recommendations"], ensure_ascii=False, indent=2),
        explanation="æ ¹æ“šæ‚¨çš„æŠ•è³‡ç†è²¡éœ€æ±‚ï¼Œæ¨è–¦äº†å…©å€‹é«˜å“è³ªçš„å•†æ¥­é¡ç¯€ç›®"
    )
    print(f"å›ç­”ç”Ÿæˆæç¤ºè©é•·åº¦ï¼š{len(formatted_answer)} å­—å…ƒ")


def demonstrate_web_search_fallback():
    """å±•ç¤º Web Search å‚™æ´æ©Ÿåˆ¶"""
    print("\n" + "=" * 60)
    print("ğŸŒ Web Search å‚™æ´æ©Ÿåˆ¶å±•ç¤º")
    print("=" * 60)
    
    # æ¨¡æ“¬ä¿¡å¿ƒåº¦ä¸è¶³çš„æƒ…æ³
    low_confidence_results = {
        "category": "å…¶ä»–",
        "recommendations": [
            {
                "title": "æŸç¯€ç›®",
                "episode": "EP1",
                "rss_id": "test_1",
                "confidence": 0.45,  # ä½æ–¼ 0.7
                "updated_at": "2024-01-01",
                "reason": "ç›¸é—œæ€§è¼ƒä½"
            }
        ],
        "status": "no_result",
        "high_confidence_count": 0
    }
    
    print(f"\nâš ï¸ ä½ä¿¡å¿ƒåº¦æƒ…æ³ï¼š")
    print(f"  é«˜ä¿¡å¿ƒåº¦çµæœæ•¸é‡ï¼š{low_confidence_results['high_confidence_count']}")
    print(f"  è§¸ç™¼æ¢ä»¶ï¼šé«˜ä¿¡å¿ƒåº¦çµæœ < 1")
    print(f"  å»ºè­°å‹•ä½œï¼šåŸ·è¡Œ Web Search")
    
    # Web Search æç¤ºè©
    web_search_prompt = get_prompt_template("web_search")
    formatted_web_search = format_prompt(
        web_search_prompt,
        user_question="æˆ‘æƒ³å­¸ç¿’æŠ•è³‡ç†è²¡ï¼Œæœ‰ä»€éº¼æ¨è–¦çš„ Podcast å—ï¼Ÿ",
        category="å•†æ¥­",
        fallback_reason="æœ¬åœ°æª¢ç´¢çµæœä¿¡å¿ƒåº¦ä¸è¶³"
    )
    print(f"\nğŸŒ Web Search æç¤ºè©é•·åº¦ï¼š{len(formatted_web_search)} å­—å…ƒ")


def demonstrate_cross_category_handling():
    """å±•ç¤ºè·¨é¡åˆ¥è™•ç†"""
    print("\n" + "=" * 60)
    print("ğŸ”„ è·¨é¡åˆ¥è™•ç†å±•ç¤º")
    print("=" * 60)
    
    # æ¨¡æ“¬è·¨é¡åˆ¥å•é¡Œ
    cross_category_question = "æˆ‘æƒ³å­¸ç¿’è·æ¶¯ç™¼å±•å’ŒæŠ•è³‡ç†è²¡"
    print(f"\nğŸ‘¤ è·¨é¡åˆ¥å•é¡Œï¼š{cross_category_question}")
    
    # æ¨¡æ“¬åˆ†é¡çµæœ
    cross_category_result = {
        "categories": [
            {
                "category": "å•†æ¥­",
                "confidence": 0.75,
                "keywords": ["æŠ•è³‡", "ç†è²¡"],
                "reasoning": "æåˆ°æŠ•è³‡ç†è²¡"
            },
            {
                "category": "æ•™è‚²",
                "confidence": 0.8,
                "keywords": ["å­¸ç¿’", "è·æ¶¯ç™¼å±•"],
                "reasoning": "æåˆ°å­¸ç¿’å’Œè·æ¶¯ç™¼å±•"
            }
        ],
        "primary_category": "æ•™è‚²",
        "is_multi_category": True,
        "cross_category_keywords": ["å­¸ç¿’", "ç™¼å±•"]
    }
    
    print(f"\nğŸ“Š åˆ†é¡çµæœï¼š")
    for cat in cross_category_result["categories"]:
        print(f"  {cat['category']}: ä¿¡å¿ƒåº¦ {cat['confidence']:.2f}")
    
    print(f"\nğŸ¯ è™•ç†ç­–ç•¥ï¼š")
    print(f"  1. åˆ†åˆ¥æª¢ç´¢å„é¡åˆ¥å…§å®¹")
    print(f"  2. æŒ‰ä¿¡å¿ƒåº¦æ’åºï¼ˆæ•™è‚² > å•†æ¥­ï¼‰")
    print(f"  3. å¯èƒ½æ··åˆæ¨è–¦å…©å€‹é¡åˆ¥")
    print(f"  4. ç¢ºä¿æ¨è–¦å¤šæ¨£æ€§")


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ Podwise RAG å•ç­”æ©Ÿå™¨äººæç¤ºè©ä½¿ç”¨ç¯„ä¾‹")
    print("æ•´åˆ text2vec-base-chinese èªæ„æª¢ç´¢ã€TAG_info.csv æ¨™ç±¤æ¯”å°å’Œ Langfuse ç›£æ§")
    
    try:
        # å±•ç¤º Langfuse ç›£æ§åŠŸèƒ½
        demonstrate_langfuse_monitoring()
        
        # å±•ç¤ºèªæ„æª¢ç´¢åŠŸèƒ½
        demonstrate_semantic_retrieval()
        
        # å±•ç¤ºæç¤ºè©ä½¿ç”¨
        demonstrate_prompt_usage()
        
        # å±•ç¤º Web Search å‚™æ´
        demonstrate_web_search_fallback()
        
        # å±•ç¤ºè·¨é¡åˆ¥è™•ç†
        demonstrate_cross_category_handling()
        
        print("\n" + "=" * 60)
        print("âœ… ç¯„ä¾‹å±•ç¤ºå®Œæˆ")
        print("=" * 60)
        
        print(f"\nğŸ“ ä½¿ç”¨èªªæ˜ï¼š")
        print(f"1. èªæ„æª¢ç´¢ï¼šä½¿ç”¨ text2vec-base-chinese æ¨¡å‹ + TAG_info.csv æ¨™ç±¤åŒ¹é…")
        print(f"2. æ··åˆåˆ†æ•¸ï¼šèªæ„æ¬Šé‡ 70% + æ¨™ç±¤æ¬Šé‡ 30%")
        print(f"3. ä¿¡å¿ƒåº¦æ§åˆ¶ï¼šåªæœ‰ >= 0.7 çš„çµæœæ‰è¢«æ¨è–¦")
        print(f"4. è·¨é¡åˆ¥è™•ç†ï¼šæŒ‰ä¿¡å¿ƒåº¦æ’åºï¼Œæ”¯æ´æ··åˆæ¨è–¦")
        print(f"5. Web Search å‚™æ´ï¼šä¿¡å¿ƒåº¦ä¸è¶³æ™‚è‡ªå‹•è§¸ç™¼")
        print(f"6. Langfuse ç›£æ§ï¼šè¿½è¹¤ LLM æ€è€ƒéç¨‹å’Œæ•ˆèƒ½æŒ‡æ¨™")
        
        print(f"\nğŸ”§ ç’°å¢ƒè¨­å®šï¼š")
        print(f"1. è¨­å®š Langfuse ç’°å¢ƒè®Šæ•¸ä»¥å•Ÿç”¨ç›£æ§")
        print(f"2. ç¢ºä¿ TAG_info.csv æª”æ¡ˆå­˜åœ¨")
        print(f"3. ä¸‹è¼‰ text2vec-base-chinese æ¨¡å‹")
        
    except Exception as e:
        print(f"âŒ åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 