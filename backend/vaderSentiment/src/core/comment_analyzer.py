#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è©•è«–åˆ†æå™¨æ ¸å¿ƒé¡åˆ¥

æä¾›è©•è«–æ•¸æ“šåˆ†æåŠŸèƒ½
åŒ…å«è©•è«–æƒ…æ„Ÿåˆ†æã€é—œéµè©æå–ã€æ¨è–¦ç†ç”±ç”Ÿæˆç­‰

ä½œè€…: Podwise Team
ç‰ˆæœ¬: 2.0.0
"""

import json
import logging
import re
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
from collections import Counter

from .sentiment_analyzer import SentimentAnalyzer, SentimentResult
from ..utils.data_processor import DataProcessor

logger = logging.getLogger(__name__)


@dataclass
class CommentAnalysis:
    """è©•è«–åˆ†æçµæœæ•¸æ“šé¡åˆ¥"""
    comment: str
    sentiment_result: SentimentResult
    keywords: List[str]
    recommendation_reason: str
    confidence: float


@dataclass
class PodcastRecommendation:
    """Podcast æ¨è–¦çµæœæ•¸æ“šé¡åˆ¥"""
    title: str
    positive_comments: List[CommentAnalysis]
    negative_comments: List[CommentAnalysis]
    overall_sentiment: float
    top_keywords: List[Tuple[str, int]]
    recommendation_summary: str
    source: str


class CommentAnalyzer:
    """
    è©•è«–åˆ†æå™¨
    
    æä¾›è©•è«–æ•¸æ“šçš„æ·±åº¦åˆ†æåŠŸèƒ½
    """
    
    def __init__(self, comment_data_dir: str = "comment_data"):
        """
        åˆå§‹åŒ–è©•è«–åˆ†æå™¨
        
        Args:
            comment_data_dir: è©•è«–æ•¸æ“šç›®éŒ„è·¯å¾‘
        """
        self.comment_data_dir = Path(comment_data_dir)
        self.sentiment_analyzer = SentimentAnalyzer()
        self.data_processor = DataProcessor()
        
        # æ¨è–¦é—œéµè©
        self.recommendation_keywords = {
            'æ¨è–¦', 'å–œæ­¡', 'å¾ˆæ£’', 'å„ªç§€', 'å¯¦ç”¨', 'æœ‰å¹«åŠ©', 'æœ‰å•Ÿç™¼', 'æœ‰æ”¶ç©«',
            'ç²¾å½©', 'æœ‰è¶£', 'å°ˆæ¥­', 'ç”¨å¿ƒ', 'èªçœŸ', 'è² è²¬', 'ç†±æƒ…', 'å‹å–„',
            'æº–ç¢º', 'æ¸…æ™°', 'æ˜“æ‡‚', 'æ·±å…¥', 'å…¨é¢', 'è©³ç´°', 'å®Œæ•´', 'è±å¯Œ',
            'æœ‰åƒ¹å€¼', 'æœ‰æ„ç¾©', 'æ”¯æŒ', 'é¼“å‹µ', 'è‚¯å®š', 'èªåŒ', 'ç†è§£', 'å…±é³´',
            'æ„Ÿè¬', 'è¬è¬', 'æ„›', 'å­¸ç¿’', 'çŸ¥è­˜', 'æ™ºæ…§', 'ç¶“é©—', 'åˆ†äº«',
            'æˆé•·', 'é€²æ­¥', 'æå‡', 'æ”¹å–„', 'è§£æ±º', 'ç­”æ¡ˆ', 'æ–¹æ³•', 'æŠ€å·§',
            'ç­–ç•¥', 'è§€é»', 'è¦‹è§£', 'åˆ†æ', 'ç ”ç©¶', 'æˆåŠŸ', 'æˆå°±', 'çªç ´',
            'å‰µæ–°', 'å‰µæ„', 'æƒ³æ³•', 'æ¦‚å¿µ', 'ç†è«–', 'å¯¦è¸'
        }
        
        self._setup_logging()
        
    def _setup_logging(self) -> None:
        """è¨­å®šæ—¥èªŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
    def load_comment_data(self, podcast_title: str) -> List[str]:
        """
        è¼‰å…¥æŒ‡å®š podcast çš„è©•è«–æ•¸æ“š
        
        Args:
            podcast_title: podcast æ¨™é¡Œ
            
        Returns:
            List[str]: è©•è«–åˆ—è¡¨
        """
        comments = []
        
        if not self.comment_data_dir.exists():
            logger.error(f"è©•è«–æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {self.comment_data_dir}")
            return comments
            
        # æœå°‹ç›¸é—œçš„è©•è«–æª”æ¡ˆ
        json_files = list(self.comment_data_dir.glob("*.json"))
        
        for file_path in json_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # æª¢æŸ¥æ˜¯å¦åŒ…å« podcast æ¨™é¡Œç›¸é—œå…§å®¹
                if self._is_related_to_podcast(data, podcast_title):
                    comment_text = data.get('content', '')
                    if comment_text and comment_text.strip():
                        comments.append(comment_text)
                        
            except Exception as e:
                logger.warning(f"è¼‰å…¥è©•è«–æª”æ¡ˆå¤±æ•— {file_path}: {e}")
                
        logger.info(f"ç‚º {podcast_title} è¼‰å…¥ {len(comments)} æ¢è©•è«–")
        return comments
        
    def _is_related_to_podcast(self, data: Dict[str, Any], podcast_title: str) -> bool:
        """æª¢æŸ¥æ•¸æ“šæ˜¯å¦èˆ‡æŒ‡å®š podcast ç›¸é—œ"""
        # ç°¡å–®çš„é—œéµè©åŒ¹é…
        title_keywords = set(podcast_title.lower().split())
        
        # æª¢æŸ¥æª”æ¡ˆå
        filename = data.get('filename', '')
        if any(keyword in filename.lower() for keyword in title_keywords):
            return True
            
        # æª¢æŸ¥å…§å®¹
        content = data.get('content', '')
        if any(keyword in content.lower() for keyword in title_keywords):
            return True
            
        return False
        
    def analyze_comment(self, comment: str) -> CommentAnalysis:
        """
        åˆ†æå–®æ¢è©•è«–
        
        Args:
            comment: è©•è«–å…§å®¹
            
        Returns:
            CommentAnalysis: è©•è«–åˆ†æçµæœ
        """
        # æƒ…æ„Ÿåˆ†æ
        sentiment_result = self.sentiment_analyzer.analyze_text(comment)
        
        # æå–é—œéµè©
        keywords = self._extract_keywords(comment)
        
        # ç”Ÿæˆæ¨è–¦ç†ç”±
        recommendation_reason = self._generate_recommendation_reason(
            comment, sentiment_result, keywords
        )
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦
        confidence = self._calculate_confidence(sentiment_result, keywords)
        
        return CommentAnalysis(
            comment=comment,
            sentiment_result=sentiment_result,
            keywords=keywords,
            recommendation_reason=recommendation_reason,
            confidence=confidence
        )
        
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–é—œéµè©"""
        words = self.data_processor.extract_words(text)
        
        # éæ¿¾æ¨è–¦é—œéµè©
        keywords = [word for word in words if word in self.recommendation_keywords]
        
        return keywords
        
    def _generate_recommendation_reason(self, comment: str, 
                                       sentiment_result: SentimentResult,
                                       keywords: List[str]) -> str:
        """ç”Ÿæˆæ¨è–¦ç†ç”±"""
        if sentiment_result.sentiment_label == 'positive':
            if keywords:
                return f"æ­£é¢è©•åƒ¹ï¼ŒåŒ…å«é—œéµè©: {', '.join(keywords[:3])}"
            else:
                return "æ­£é¢è©•åƒ¹ï¼Œå…§å®¹ç©æ¥µ"
        elif sentiment_result.sentiment_label == 'negative':
            return "è² é¢è©•åƒ¹ï¼Œä¸æ¨è–¦"
        else:
            return "ä¸­æ€§è©•åƒ¹ï¼Œéœ€è¦æ›´å¤šè³‡è¨Š"
            
    def _calculate_confidence(self, sentiment_result: SentimentResult, 
                             keywords: List[str]) -> float:
        """è¨ˆç®—ä¿¡å¿ƒåº¦"""
        # åŸºæ–¼æƒ…æ„Ÿåˆ†æä¿¡å¿ƒåº¦å’Œé—œéµè©æ•¸é‡
        sentiment_confidence = sentiment_result.confidence
        keyword_confidence = min(len(keywords) / 5.0, 1.0)  # æœ€å¤š 5 å€‹é—œéµè©
        
        return (sentiment_confidence + keyword_confidence) / 2
        
    def analyze_podcast_comments(self, podcast_title: str) -> PodcastRecommendation:
        """
        åˆ†æ podcast çš„æ‰€æœ‰è©•è«–
        
        Args:
            podcast_title: podcast æ¨™é¡Œ
            
        Returns:
            PodcastRecommendation: podcast æ¨è–¦çµæœ
        """
        # è¼‰å…¥è©•è«–
        comments = self.load_comment_data(podcast_title)
        
        if not comments:
            logger.warning(f"æ²’æœ‰æ‰¾åˆ° {podcast_title} çš„è©•è«–æ•¸æ“š")
            return self._create_empty_recommendation(podcast_title)
            
        # åˆ†ææ¯æ¢è©•è«–
        comment_analyses = []
        for comment in comments:
            try:
                analysis = self.analyze_comment(comment)
                comment_analyses.append(analysis)
            except Exception as e:
                logger.warning(f"åˆ†æè©•è«–å¤±æ•—: {e}")
                
        # åˆ†é¡è©•è«–
        positive_comments = [
            ca for ca in comment_analyses 
            if ca.sentiment_result.sentiment_label == 'positive'
        ]
        negative_comments = [
            ca for ca in comment_analyses 
            if ca.sentiment_result.sentiment_label == 'negative'
        ]
        
        # è¨ˆç®—æ•´é«”æƒ…æ„Ÿ
        if comment_analyses:
            overall_sentiment = sum(
                ca.sentiment_result.compound_score for ca in comment_analyses
            ) / len(comment_analyses)
        else:
            overall_sentiment = 0.0
            
        # æå–é ‚ç´šé—œéµè©
        all_keywords = []
        for ca in comment_analyses:
            all_keywords.extend(ca.keywords)
            
        keyword_counter = Counter(all_keywords)
        top_keywords = keyword_counter.most_common(10)
        
        # ç”Ÿæˆæ¨è–¦æ‘˜è¦
        recommendation_summary = self._generate_recommendation_summary(
            positive_comments, negative_comments, overall_sentiment, top_keywords
        )
        
        return PodcastRecommendation(
            title=podcast_title,
            positive_comments=positive_comments,
            negative_comments=negative_comments,
            overall_sentiment=overall_sentiment,
            top_keywords=top_keywords,
            recommendation_summary=recommendation_summary,
            source="comment_data"
        )
        
    def _generate_recommendation_summary(self, positive_comments: List[CommentAnalysis],
                                        negative_comments: List[CommentAnalysis],
                                        overall_sentiment: float,
                                        top_keywords: List[Tuple[str, int]]) -> str:
        """ç”Ÿæˆæ¨è–¦æ‘˜è¦"""
        summary_parts = []
        
        # æƒ…æ„Ÿå‚¾å‘
        if overall_sentiment > 0.1:
            summary_parts.append("æ•´é«”æƒ…æ„Ÿå‚¾å‘æ­£é¢")
        elif overall_sentiment < -0.1:
            summary_parts.append("æ•´é«”æƒ…æ„Ÿå‚¾å‘è² é¢")
        else:
            summary_parts.append("æ•´é«”æƒ…æ„Ÿå‚¾å‘ä¸­æ€§")
            
        # è©•è«–æ•¸é‡
        total_comments = len(positive_comments) + len(negative_comments)
        summary_parts.append(f"å…±åˆ†æ {total_comments} æ¢è©•è«–")
        
        # æ­£é¢è©•è«–æ¯”ä¾‹
        if total_comments > 0:
            positive_ratio = len(positive_comments) / total_comments
            summary_parts.append(f"æ­£é¢è©•è«–ä½” {positive_ratio:.1%}")
            
        # é—œéµè©
        if top_keywords:
            top_keywords_str = ", ".join([f"{word}({count})" for word, count in top_keywords[:5]])
            summary_parts.append(f"ä¸»è¦é—œéµè©: {top_keywords_str}")
            
        return "ï¼›".join(summary_parts)
        
    def _create_empty_recommendation(self, podcast_title: str) -> PodcastRecommendation:
        """å‰µå»ºç©ºçš„æ¨è–¦çµæœ"""
        return PodcastRecommendation(
            title=podcast_title,
            positive_comments=[],
            negative_comments=[],
            overall_sentiment=0.0,
            top_keywords=[],
            recommendation_summary="æ²’æœ‰æ‰¾åˆ°ç›¸é—œè©•è«–æ•¸æ“š",
            source="comment_data"
        )
        
    def generate_recommendation_report(self, recommendations: List[PodcastRecommendation],
                                      output_path: str = "podcast_recommendations.txt") -> bool:
        """
        ç”Ÿæˆæ¨è–¦å ±å‘Š
        
        Args:
            recommendations: æ¨è–¦çµæœåˆ—è¡¨
            output_path: è¼¸å‡ºè·¯å¾‘
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            report_content = self._create_recommendation_report_content(recommendations)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
                
            logger.info(f"æ¨è–¦å ±å‘Šå·²ç”Ÿæˆ: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¨è–¦å ±å‘Šå¤±æ•—: {e}")
            return False
            
    def _create_recommendation_report_content(self, 
                                             recommendations: List[PodcastRecommendation]) -> str:
        """å‰µå»ºæ¨è–¦å ±å‘Šå…§å®¹"""
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ğŸ§ PODCAST æ¨è–¦åˆ†æå ±å‘Š")
        report_lines.append("=" * 80)
        
        for i, rec in enumerate(recommendations, 1):
            report_lines.append(f"\n{i}. {rec.title}")
            report_lines.append("-" * 60)
            report_lines.append(f"ğŸ“Š æ•´é«”æƒ…æ„Ÿåˆ†æ•¸: {rec.overall_sentiment:.3f}")
            report_lines.append(f"ğŸ‘ æ­£é¢è©•è«–: {len(rec.positive_comments)} æ¢")
            report_lines.append(f"ğŸ‘ è² é¢è©•è«–: {len(rec.negative_comments)} æ¢")
            
            if rec.top_keywords:
                report_lines.append(f"ğŸ”‘ ä¸»è¦é—œéµè©: {', '.join([f'{word}({count})' for word, count in rec.top_keywords[:5]])}")
                
            report_lines.append(f"ğŸ’¡ æ¨è–¦æ‘˜è¦: {rec.recommendation_summary}")
            
            # é¡¯ç¤ºéƒ¨åˆ†æ­£é¢è©•è«–
            if rec.positive_comments:
                report_lines.append("\n   ğŸ“ æ­£é¢è©•è«–ç¯„ä¾‹:")
                for j, comment_analysis in enumerate(rec.positive_comments[:3]):
                    comment_preview = comment_analysis.comment[:100] + "..." if len(comment_analysis.comment) > 100 else comment_analysis.comment
                    report_lines.append(f"      {j+1}. {comment_preview}")
                    
        report_lines.append("\n" + "=" * 80)
        
        return "\n".join(report_lines) 