#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Podwise æ¸¬è©¦è³‡æ–™åŒ¯å…¥ç¨‹å¼
å°‡ testdata ç›®éŒ„ä¸‹çš„ CSV æª”æ¡ˆè³‡æ–™åŒ¯å…¥åˆ° PostgreSQL è³‡æ–™åº«
"""

import os
import sys
import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime
import logging
from typing import Dict, List, Optional, Tuple
import argparse

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_import.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class DatabaseImporter:
    """è³‡æ–™åº«åŒ¯å…¥å™¨é¡åˆ¥"""
    
    def __init__(self, db_config: Dict[str, str]):
        """
        åˆå§‹åŒ–è³‡æ–™åº«åŒ¯å…¥å™¨
        
        Args:
            db_config: è³‡æ–™åº«é€£ç·šé…ç½®
        """
        self.db_config = db_config
        self.connection = None
        self.cursor = None
        
    def connect(self) -> bool:
        """
        é€£æ¥åˆ°è³‡æ–™åº«
        
        Returns:
            bool: é€£ç·šæ˜¯å¦æˆåŠŸ
        """
        try:
            self.connection = psycopg2.connect(**self.db_config)
            self.cursor = self.connection.cursor(cursor_factory=RealDictCursor)
            logger.info("âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
            return False
    
    def disconnect(self):
        """é—œé–‰è³‡æ–™åº«é€£ç·š"""
        if self.cursor:
            self.cursor.close()
        if self.connection:
            self.connection.close()
        logger.info("ğŸ”Œ è³‡æ–™åº«é€£ç·šå·²é—œé–‰")
    
    def execute_query(self, query: str, params: Optional[Tuple] = None) -> bool:
        """
        åŸ·è¡Œ SQL æŸ¥è©¢
        
        Args:
            query: SQL æŸ¥è©¢èªå¥
            params: æŸ¥è©¢åƒæ•¸
            
        Returns:
            bool: åŸ·è¡Œæ˜¯å¦æˆåŠŸ
        """
        try:
            self.cursor.execute(query, params)
            return True
        except Exception as e:
            logger.error(f"âŒ SQL åŸ·è¡Œå¤±æ•—: {e}")
            logger.error(f"æŸ¥è©¢: {query}")
            if params:
                logger.error(f"åƒæ•¸: {params}")
            return False
    
    def commit(self):
        """æäº¤äº¤æ˜“"""
        if self.connection:
            self.connection.commit()
            logger.info("ğŸ’¾ äº¤æ˜“å·²æäº¤")
    
    def rollback(self):
        """å›æ»¾äº¤æ˜“"""
        if self.connection:
            self.connection.rollback()
            logger.warning("ğŸ”„ äº¤æ˜“å·²å›æ»¾")
    
    def get_or_create_user(self, user_code: str) -> Optional[int]:
        """
        å–å¾—æˆ–å‰µå»ºä½¿ç”¨è€…
        
        Args:
            user_code: ä½¿ç”¨è€…ä»£ç¢¼
            
        Returns:
            Optional[int]: ä½¿ç”¨è€… ID
        """
        # æ¨™æº–åŒ–ä½¿ç”¨è€…ä»£ç¢¼æ ¼å¼ (ç§»é™¤åº•ç·š)
        normalized_user_code = user_code.replace('_', '')
        
        # æª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦å­˜åœ¨
        query = "SELECT user_id FROM users WHERE user_code = %s"
        if self.execute_query(query, (normalized_user_code,)):
            result = self.cursor.fetchone()
            if result:
                return result['user_id']
        
        # å‰µå»ºæ–°ä½¿ç”¨è€…
        insert_query = """
        INSERT INTO users (email, username, given_name, family_name, is_active, locale)
        VALUES (%s, %s, 'Guest', 'User', true, 'zh-TW')
        RETURNING user_id
        """
        if self.execute_query(insert_query, (f"{normalized_user_code}@podwise.test", normalized_user_code)):
            result = self.cursor.fetchone()
            if result:
                logger.info(f"ğŸ‘¤ å‰µå»ºæ–°ä½¿ç”¨è€…: {normalized_user_code} (ID: {result['user_id']})")
                return result['user_id']
        
        return None
    
    def get_or_create_episode(self, episode_title: str) -> Optional[int]:
        """
        å–å¾—æˆ–å‰µå»ºç¯€ç›®é›†æ•¸
        
        Args:
            episode_title: ç¯€ç›®é›†æ•¸æ¨™é¡Œ
            
        Returns:
            Optional[int]: ç¯€ç›®é›†æ•¸ ID
        """
        # è™•ç†è‚¡ç™Œç¯€ç›®çš„æ ¼å¼è½‰æ›
        normalized_title = self._normalize_episode_title(episode_title)
        
        # æª¢æŸ¥ç¯€ç›®é›†æ•¸æ˜¯å¦å­˜åœ¨
        query = "SELECT episode_id FROM episodes WHERE episode_title = %s"
        if self.execute_query(query, (normalized_title,)):
            result = self.cursor.fetchone()
            if result:
                return result['episode_id']
        
        # å‰µå»ºæ–°ç¯€ç›®é›†æ•¸ï¼ˆéœ€è¦å…ˆæœ‰ podcastï¼‰
        # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œä½¿ç”¨é è¨­ podcast_id = 1
        insert_query = """
        INSERT INTO episodes (podcast_id, episode_title, published_date, created_at, updated_at)
        VALUES (1, %s, CURRENT_DATE, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        RETURNING episode_id
        """
        if self.execute_query(insert_query, (normalized_title,)):
            result = self.cursor.fetchone()
            if result:
                logger.info(f"ğŸ“º å‰µå»ºæ–°ç¯€ç›®é›†æ•¸: {normalized_title[:50]}... (ID: {result['episode_id']})")
                return result['episode_id']
        
        return None
    
    def _normalize_episode_title(self, episode_title: str) -> str:
        """
        æ¨™æº–åŒ–ç¯€ç›®é›†æ•¸æ¨™é¡Œæ ¼å¼
        
        Args:
            episode_title: åŸå§‹ç¯€ç›®é›†æ•¸æ¨™é¡Œ
            
        Returns:
            str: æ¨™æº–åŒ–å¾Œçš„æ¨™é¡Œ
        """
        # è™•ç†è‚¡ç™Œç¯€ç›®çš„æ ¼å¼è½‰æ›
        if episode_title.startswith('Spotify_RSS_1500839292_EP') and episode_title.endswith('_è‚¡ç™Œ.mp3'):
            # å¾ Spotify_RSS_1500839292_EP569_è‚¡ç™Œ.mp3 è½‰æ›ç‚º EP569_è‚¡ç™Œ
            episode_number = episode_title.replace('Spotify_RSS_1500839292_EP', '').replace('_è‚¡ç™Œ.mp3', '')
            return f'EP{episode_number}_è‚¡ç™Œ'
        
        # è™•ç†å…¶ä»–å¯èƒ½çš„æ ¼å¼è½‰æ›
        if episode_title.startswith('RSS_1500839292_EP') and episode_title.endswith('_è‚¡ç™Œ.mp3'):
            # å¾ RSS_1500839292_EP5702_è‚¡ç™Œ.mp3 è½‰æ›ç‚º EP5702_è‚¡ç™Œ
            episode_number = episode_title.replace('RSS_1500839292_EP', '').replace('_è‚¡ç™Œ.mp3', '')
            return f'EP{episode_number}_è‚¡ç™Œ'
        
        # è™•ç†å…¶ä»–ç¯€ç›®çš„æ ¼å¼è½‰æ›
        if episode_title.startswith('Spotify_RSS_'):
            # ç§»é™¤ Spotify_RSS_ å‰ç¶´å’Œ .mp3 å¾Œç¶´
            normalized = episode_title.replace('Spotify_RSS_', '')
            if normalized.endswith('.mp3'):
                normalized = normalized[:-4]
            return normalized
        
        # ç§»é™¤ .mp3 å‰¯æª”å
        if episode_title.endswith('.mp3'):
            episode_title = episode_title[:-4]
        
        return episode_title
    
    def import_user_feedback(self, csv_path: str) -> bool:
        """
        åŒ¯å…¥ä½¿ç”¨è€…å›é¥‹è³‡æ–™
        
        Args:
            csv_path: CSV æª”æ¡ˆè·¯å¾‘
            
        Returns:
            bool: åŒ¯å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"ğŸ“Š é–‹å§‹åŒ¯å…¥ä½¿ç”¨è€…å›é¥‹è³‡æ–™: {csv_path}")
            
            # è®€å– CSV æª”æ¡ˆ
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            logger.info(f"ğŸ“ˆ è®€å–åˆ° {len(df)} ç­†è³‡æ–™")
            
            success_count = 0
            error_count = 0
            
            for index, row in df.iterrows():
                try:
                    # å–å¾—æˆ–å‰µå»ºä½¿ç”¨è€…
                    user_id = self.get_or_create_user(row['User_id'])
                    if not user_id:
                        error_count += 1
                        continue
                    
                    # å–å¾—æˆ–å‰µå»ºç¯€ç›®é›†æ•¸
                    episode_id = self.get_or_create_episode(row['Episode_id'])
                    if not episode_id:
                        error_count += 1
                        continue
                    
                    # è™•ç†æ—¥æœŸæ ¼å¼
                    preview_played_at = None
                    created_at = None
                    
                    if pd.notna(row['preview_played_at']):
                        try:
                            preview_played_at = pd.to_datetime(row['preview_played_at']).strftime('%Y-%m-%d %H:%M:%S')
                        except:
                            preview_played_at = None
                    
                    if pd.notna(row['created_at']):
                        try:
                            created_at = pd.to_datetime(row['created_at']).strftime('%Y-%m-%d %H:%M:%S')
                        except:
                            created_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    else:
                        created_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    
                    # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒè¨˜éŒ„
                    check_query = """
                    SELECT 1 FROM user_feedback 
                    WHERE user_id = %s AND episode_id = %s
                    """
                    if self.execute_query(check_query, (user_id, episode_id)):
                        if self.cursor.fetchone():
                            # æ›´æ–°ç¾æœ‰è¨˜éŒ„
                            update_query = """
                            UPDATE user_feedback 
                            SET rating = %s, bookmark = false, preview_played = %s,
                                preview_listen_time = NULL, preview_played_at = %s,
                                like_count = %s, dislike_count = 0, preview_play_count = %s,
                                updated_at = %s
                            WHERE user_id = %s AND episode_id = %s
                            """
                            preview_played = preview_played_at is not None
                            params = (
                                None, preview_played, preview_played_at,
                                row['like_count'], row['preview_play_count'],
                                created_at, user_id, episode_id
                            )
                        else:
                            # æ’å…¥æ–°è¨˜éŒ„
                            insert_query = """
                            INSERT INTO user_feedback 
                            (user_id, episode_id, rating, bookmark, preview_played,
                             preview_listen_time, preview_played_at, like_count,
                             dislike_count, preview_play_count, created_at, updated_at)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                            """
                            preview_played = preview_played_at is not None
                            params = (
                                user_id, episode_id, None, False, preview_played,
                                None, preview_played_at, row['like_count'],
                                0, row['preview_play_count'], created_at, created_at
                            )
                        
                        if self.execute_query(insert_query if 'INSERT' in locals() else update_query, params):
                            success_count += 1
                        else:
                            error_count += 1
                    else:
                        error_count += 1
                    
                    # æ¯ 100 ç­†æäº¤ä¸€æ¬¡
                    if (index + 1) % 100 == 0:
                        self.commit()
                        logger.info(f"ğŸ“Š å·²è™•ç† {index + 1}/{len(df)} ç­†è³‡æ–™")
                
                except Exception as e:
                    logger.error(f"âŒ è™•ç†ç¬¬ {index + 1} ç­†è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    error_count += 1
            
            # æœ€çµ‚æäº¤
            self.commit()
            
            logger.info(f"âœ… ä½¿ç”¨è€…å›é¥‹è³‡æ–™åŒ¯å…¥å®Œæˆ")
            logger.info(f"ğŸ“Š æˆåŠŸ: {success_count} ç­†, å¤±æ•—: {error_count} ç­†")
            
            return error_count == 0
            
        except Exception as e:
            logger.error(f"âŒ åŒ¯å…¥ä½¿ç”¨è€…å›é¥‹è³‡æ–™å¤±æ•—: {e}")
            self.rollback()
            return False
    
    def import_episode_stats(self, likes_csv: str, plays_csv: str) -> bool:
        """
        åŒ¯å…¥ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™
        
        Args:
            likes_csv: æŒ‰è®šçµ±è¨ˆ CSV æª”æ¡ˆè·¯å¾‘
            plays_csv: æ’­æ”¾çµ±è¨ˆ CSV æª”æ¡ˆè·¯å¾‘
            
        Returns:
            bool: åŒ¯å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("ğŸ“Š é–‹å§‹åŒ¯å…¥ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™")
            
            # è®€å–çµ±è¨ˆè³‡æ–™
            likes_df = pd.read_csv(likes_csv, encoding='utf-8-sig')
            plays_df = pd.read_csv(plays_csv, encoding='utf-8-sig')
            
            logger.info(f"ğŸ“ˆ è®€å–åˆ° {len(likes_df)} ç­†æŒ‰è®šçµ±è¨ˆ, {len(plays_df)} ç­†æ’­æ”¾çµ±è¨ˆ")
            
            success_count = 0
            error_count = 0
            
            # åˆä½µçµ±è¨ˆè³‡æ–™
            stats_df = pd.merge(likes_df, plays_df, on='Episode_id', how='outer')
            
            for index, row in stats_df.iterrows():
                try:
                    # å–å¾—æˆ–å‰µå»ºç¯€ç›®é›†æ•¸
                    episode_id = self.get_or_create_episode(row['Episode_id'])
                    if not episode_id:
                        error_count += 1
                        continue
                    
                    # æ›´æ–°ç¯€ç›®é›†æ•¸çš„çµ±è¨ˆè³‡è¨Š
                    update_query = """
                    UPDATE episodes 
                    SET apple_episodes_ranking = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE episode_id = %s
                    """
                    
                    # é€™è£¡å¯ä»¥æ ¹æ“šéœ€è¦è¨ˆç®—æ’åæˆ–ä½¿ç”¨å…¶ä»–é‚è¼¯
                    ranking = None
                    
                    if self.execute_query(update_query, (ranking, episode_id)):
                        success_count += 1
                    else:
                        error_count += 1
                    
                except Exception as e:
                    logger.error(f"âŒ è™•ç†çµ±è¨ˆè³‡æ–™ç¬¬ {index + 1} ç­†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    error_count += 1
            
            self.commit()
            
            logger.info(f"âœ… ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™åŒ¯å…¥å®Œæˆ")
            logger.info(f"ğŸ“Š æˆåŠŸ: {success_count} ç­†, å¤±æ•—: {error_count} ç­†")
            
            return error_count == 0
            
        except Exception as e:
            logger.error(f"âŒ åŒ¯å…¥ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™å¤±æ•—: {e}")
            self.rollback()
            return False
    
    def import_user_episode_counts(self, csv_path: str) -> bool:
        """
        åŒ¯å…¥ä½¿ç”¨è€…ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™
        
        Args:
            csv_path: CSV æª”æ¡ˆè·¯å¾‘
            
        Returns:
            bool: åŒ¯å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"ğŸ“Š é–‹å§‹åŒ¯å…¥ä½¿ç”¨è€…ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™: {csv_path}")
            
            # è®€å– CSV æª”æ¡ˆ
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            logger.info(f"ğŸ“ˆ è®€å–åˆ° {len(df)} ç­†è³‡æ–™")
            
            success_count = 0
            error_count = 0
            
            for index, row in df.iterrows():
                try:
                    # å–å¾—æˆ–å‰µå»ºä½¿ç”¨è€…
                    user_id = self.get_or_create_user(row['User_id'])
                    if not user_id:
                        error_count += 1
                        continue
                    
                    # æ›´æ–°ä½¿ç”¨è€…è¡Œç‚ºçµ±è¨ˆ
                    # é€™è£¡å¯ä»¥æ ¹æ“šéœ€è¦æ’å…¥åˆ° user_behavior_stats è¡¨
                    # æˆ–è€…æ›´æ–° users è¡¨çš„ç›¸é—œæ¬„ä½
                    
                    success_count += 1
                    
                except Exception as e:
                    logger.error(f"âŒ è™•ç†ä½¿ç”¨è€…çµ±è¨ˆç¬¬ {index + 1} ç­†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    error_count += 1
            
            self.commit()
            
            logger.info(f"âœ… ä½¿ç”¨è€…ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™åŒ¯å…¥å®Œæˆ")
            logger.info(f"ğŸ“Š æˆåŠŸ: {success_count} ç­†, å¤±æ•—: {error_count} ç­†")
            
            return error_count == 0
            
        except Exception as e:
            logger.error(f"âŒ åŒ¯å…¥ä½¿ç”¨è€…ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™å¤±æ•—: {e}")
            self.rollback()
            return False


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description='Podwise æ¸¬è©¦è³‡æ–™åŒ¯å…¥ç¨‹å¼')
    parser.add_argument('--host', default='localhost', help='è³‡æ–™åº«ä¸»æ©Ÿ')
    parser.add_argument('--port', default='5432', help='è³‡æ–™åº«åŸ è™Ÿ')
    parser.add_argument('--database', default='podcast', help='è³‡æ–™åº«åç¨±')
    parser.add_argument('--username', default='bdse37', help='è³‡æ–™åº«ä½¿ç”¨è€…åç¨±')
    parser.add_argument('--password', default='111111', help='è³‡æ–™åº«å¯†ç¢¼')
    parser.add_argument('--data-dir', default='.', help='æ¸¬è©¦è³‡æ–™ç›®éŒ„è·¯å¾‘')
    parser.add_argument('--skip-user-feedback', action='store_true', help='è·³éä½¿ç”¨è€…å›é¥‹è³‡æ–™åŒ¯å…¥')
    parser.add_argument('--skip-episode-stats', action='store_true', help='è·³éç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™åŒ¯å…¥')
    parser.add_argument('--skip-user-counts', action='store_true', help='è·³éä½¿ç”¨è€…çµ±è¨ˆè³‡æ–™åŒ¯å…¥')
    
    args = parser.parse_args()
    
    # è³‡æ–™åº«é€£ç·šé…ç½®
    db_config = {
        'host': args.host,
        'port': args.port,
        'database': args.database,
        'user': args.username,
        'password': args.password
    }
    
    # å»ºç«‹åŒ¯å…¥å™¨
    importer = DatabaseImporter(db_config)
    
    try:
        # é€£æ¥åˆ°è³‡æ–™åº«
        if not importer.connect():
            logger.error("âŒ ç„¡æ³•é€£æ¥åˆ°è³‡æ–™åº«ï¼Œç¨‹å¼çµæŸ")
            return 1
        
        # è¨­å®šæª”æ¡ˆè·¯å¾‘
        data_dir = args.data_dir
        user_feedback_csv = os.path.join(data_dir, 'user_feedback.csv')
        episode_likes_csv = os.path.join(data_dir, 'episode_likes.csv')
        episode_plays_csv = os.path.join(data_dir, 'episode_plays.csv')
        user_episode_counts_csv = os.path.join(data_dir, 'user_episode_counts.csv')
        
        success = True
        
        # åŒ¯å…¥ä½¿ç”¨è€…å›é¥‹è³‡æ–™
        if not args.skip_user_feedback and os.path.exists(user_feedback_csv):
            if not importer.import_user_feedback(user_feedback_csv):
                success = False
        else:
            logger.info("â­ï¸ è·³éä½¿ç”¨è€…å›é¥‹è³‡æ–™åŒ¯å…¥")
        
        # åŒ¯å…¥ç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™
        if not args.skip_episode_stats and os.path.exists(episode_likes_csv) and os.path.exists(episode_plays_csv):
            if not importer.import_episode_stats(episode_likes_csv, episode_plays_csv):
                success = False
        else:
            logger.info("â­ï¸ è·³éç¯€ç›®é›†æ•¸çµ±è¨ˆè³‡æ–™åŒ¯å…¥")
        
        # åŒ¯å…¥ä½¿ç”¨è€…çµ±è¨ˆè³‡æ–™
        if not args.skip_user_counts and os.path.exists(user_episode_counts_csv):
            if not importer.import_user_episode_counts(user_episode_counts_csv):
                success = False
        else:
            logger.info("â­ï¸ è·³éä½¿ç”¨è€…çµ±è¨ˆè³‡æ–™åŒ¯å…¥")
        
        if success:
            logger.info("ğŸ‰ æ‰€æœ‰è³‡æ–™åŒ¯å…¥å®Œæˆï¼")
            return 0
        else:
            logger.error("âŒ éƒ¨åˆ†è³‡æ–™åŒ¯å…¥å¤±æ•—")
            return 1
            
    except KeyboardInterrupt:
        logger.info("âš ï¸ ä½¿ç”¨è€…ä¸­æ–·ç¨‹å¼")
        importer.rollback()
        return 1
    except Exception as e:
        logger.error(f"âŒ ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        importer.rollback()
        return 1
    finally:
        importer.disconnect()


if __name__ == "__main__":
    sys.exit(main()) 