#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Data Cleaning æ¨¡çµ„ä¸»ç¨‹å¼å…¥å£é»

æä¾›çµ±ä¸€çš„å‘½ä»¤åˆ—ä»‹é¢ï¼Œæ–¹ä¾¿èª¿ç”¨æ‰€æœ‰æ¸…ç†åŠŸèƒ½ã€‚

Author: Podri Team
License: MIT
"""

import argparse
import sys
import logging
from pathlib import Path
from typing import Dict, Any

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

def list_cleaners():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¸…ç†å™¨"""
    try:
        from data_cleaning import (
            BaseCleaner, MongoCleaner, StockCancerCleaner, 
            LongTextCleaner, EpisodeCleaner, PodcastCleaner
        )
        
        cleaners = {
            "BaseCleaner": "åŸºåº•æ¸…ç†å™¨ï¼ˆæŠ½è±¡é¡åˆ¥ï¼‰",
            "MongoCleaner": "MongoDB æ–‡æª”æ¸…ç†å™¨",
            "StockCancerCleaner": "è‚¡ç™Œç¯€ç›®å°ˆç”¨æ¸…ç†å™¨",
            "LongTextCleaner": "é•·æ–‡æœ¬æ¸…ç†å™¨",
            "EpisodeCleaner": "Episode è³‡æ–™æ¸…ç†å™¨",
            "PodcastCleaner": "Podcast è³‡æ–™æ¸…ç†å™¨"
        }
        
        print("å¯ç”¨çš„æ¸…ç†å™¨ï¼š")
        print("=" * 50)
        for name, description in cleaners.items():
            print(f"â€¢ {name}: {description}")
        print("=" * 50)
        
    except ImportError as e:
        logger.error(f"ç„¡æ³•è¼‰å…¥æ¸…ç†å™¨: {e}")
        return False
    
    return True

def test_cleaners():
    """æ¸¬è©¦æ‰€æœ‰æ¸…ç†å™¨"""
    try:
        from data_cleaning import MongoCleaner, StockCancerCleaner, LongTextCleaner
        
        print("æ¸¬è©¦æ¸…ç†å™¨åŠŸèƒ½...")
        print("=" * 50)
        
        # æ¸¬è©¦ LongTextCleaner
        print("1. æ¸¬è©¦ LongTextCleaner")
        longtext_cleaner = LongTextCleaner()
        test_text = "Hello ğŸ˜Š World :) é€™æ˜¯ä¸€å€‹æ¸¬è©¦æ–‡æœ¬ ğŸš€"
        cleaned_text = longtext_cleaner.clean(test_text)
        print(f"   åŸå§‹: {test_text}")
        print(f"   æ¸…ç†å¾Œ: {cleaned_text}")
        print()
        
        # æ¸¬è©¦ StockCancerCleaner
        print("2. æ¸¬è©¦ StockCancerCleaner")
        stock_cleaner = StockCancerCleaner()
        test_data = {
            "episode_title": "EP572 | ğŸŒ 2025 éä¸€åŠäº†== æœ¬é›†ç¯€ç›®ç”±ã€NordVPNã€‘è´ŠåŠ©",
            "description": "æ™¦æ¾€é‡‘èæŠ•è³‡çŸ¥è­˜ç›´ç™½è¬›ï¼Œé‡è¦æµ·å…§å¤–æ™‚äº‹è¼•é¬†è«‡..."
        }
        cleaned_data = stock_cleaner.clean(test_data)
        print(f"   åŸå§‹æ¨™é¡Œ: {test_data['episode_title']}")
        print(f"   æ¸…ç†å¾Œæ¨™é¡Œ: {cleaned_data['episode_title']}")
        print()
        
        # æ¸¬è©¦ MongoCleaner
        print("3. æ¸¬è©¦ MongoCleaner")
        mongo_cleaner = MongoCleaner()
        test_doc = {
            "text": "é€™æ˜¯ä¸€å€‹ MongoDB æ–‡æª” ğŸ˜Š åŒ…å«è¡¨æƒ…ç¬¦è™Ÿ :)",
            "title": "æ¸¬è©¦æ¨™é¡Œ ğŸš€",
            "description": "æ¸¬è©¦æè¿° :D"
        }
        cleaned_doc = mongo_cleaner.clean(test_doc)
        print(f"   åŸå§‹æ–‡æª”: {test_doc}")
        print(f"   æ¸…ç†å¾Œæ–‡æª”: {cleaned_doc}")
        print()
        
        print("æ‰€æœ‰æ¸…ç†å™¨æ¸¬è©¦å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"æ¸¬è©¦æ¸…ç†å™¨å¤±æ•—: {e}")
        return False

def clean_data(input_file: str, output_file: str):
    """æ¸…ç†è³‡æ–™æª”æ¡ˆ"""
    try:
        from data_cleaning.services import CleanerOrchestrator
        
        print(f"é–‹å§‹æ¸…ç†æª”æ¡ˆ: {input_file}")
        
        # åˆå§‹åŒ–å”èª¿å™¨
        orchestrator = CleanerOrchestrator()
        
        # æ¸…ç†æª”æ¡ˆ
        output_path = orchestrator.clean_file(input_file)
        
        print(f"æ¸…ç†å®Œæˆï¼è¼¸å‡ºæª”æ¡ˆ: {output_path}")
        return True
        
    except Exception as e:
        logger.error(f"æ¸…ç†è³‡æ–™å¤±æ•—: {e}")
        return False

def process_stock_cancer(input_file: str, import_postgresql: bool = False):
    """è™•ç†è‚¡ç™Œè³‡æ–™"""
    try:
        from data_cleaning.core import StockCancerCleaner
        from data_cleaning.utils import DataExtractor
        from data_cleaning.config import Config
        
        print(f"é–‹å§‹è™•ç†è‚¡ç™Œè³‡æ–™: {input_file}")
        
        # åˆå§‹åŒ–
        config = Config()
        extractor = DataExtractor(config)
        cleaner = StockCancerCleaner()
        
        # è®€å–è³‡æ–™
        with open(input_file, 'r', encoding='utf-8') as f:
            import json
            data = json.load(f)
        
        # æ¸…ç†è³‡æ–™
        if isinstance(data, list):
            cleaned_data = cleaner.batch_clean_documents(data)
        else:
            cleaned_data = cleaner.clean(data)
        
        # å„²å­˜çµæœ
        output_file = input_file.replace('.json', '_cleaned.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        
        print(f"è‚¡ç™Œè³‡æ–™è™•ç†å®Œæˆï¼è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        
        # åŒ¯å…¥ PostgreSQL
        if import_postgresql:
            print("é–‹å§‹åŒ¯å…¥ PostgreSQL...")
            from data_cleaning.utils import DBUtils
            
            db_utils = DBUtils(config.get_db_config())
            db_utils.connect()
            
            success_count = 0
            if isinstance(cleaned_data, list):
                for doc in cleaned_data:
                    if doc.get('cleaning_status') != 'error':
                        if db_utils.insert_episode(doc):
                            success_count += 1
            else:
                if cleaned_data.get('cleaning_status') != 'error':
                    if db_utils.insert_episode(cleaned_data):
                        success_count += 1
            
            db_utils.disconnect()
            print(f"PostgreSQL åŒ¯å…¥å®Œæˆï¼æˆåŠŸæ’å…¥ {success_count} ç­†è³‡æ–™")
        
        return True
        
    except Exception as e:
        logger.error(f"è™•ç†è‚¡ç™Œè³‡æ–™å¤±æ•—: {e}")
        return False

def import_postgresql(input_file: str):
    """åŒ¯å…¥è³‡æ–™åˆ° PostgreSQL"""
    try:
        from data_cleaning.utils import DBUtils, DataExtractor
        from data_cleaning.config import Config
        
        print(f"é–‹å§‹åŒ¯å…¥ PostgreSQL: {input_file}")
        
        # åˆå§‹åŒ–
        config = Config()
        db_utils = DBUtils(config.get_db_config())
        extractor = DataExtractor(config)
        
        # è®€å–è³‡æ–™
        with open(input_file, 'r', encoding='utf-8') as f:
            import json
            data = json.load(f)
        
        # é€£æ¥è³‡æ–™åº«
        db_utils.connect()
        
        # æ’å…¥è³‡æ–™
        success_count = 0
        if isinstance(data, list):
            for doc in data:
                if doc.get('cleaning_status') != 'error':
                    if db_utils.insert_episode(doc):
                        success_count += 1
        else:
            if data.get('cleaning_status') != 'error':
                if db_utils.insert_episode(data):
                    success_count += 1
        
        # é—œé–‰é€£æ¥
        db_utils.disconnect()
        
        print(f"PostgreSQL åŒ¯å…¥å®Œæˆï¼æˆåŠŸæ’å…¥ {success_count} ç­†è³‡æ–™")
        return True
        
    except Exception as e:
        logger.error(f"åŒ¯å…¥ PostgreSQL å¤±æ•—: {e}")
        return False

def run_service_test(test_type: str, sample_size: int = 100):
    """åŸ·è¡Œæœå‹™æ¸¬è©¦"""
    try:
        from data_cleaning.services import CleanupService
        from data_cleaning.config import Config
        
        print(f"é–‹å§‹åŸ·è¡Œ {test_type} æ¸¬è©¦...")
        
        # åˆå§‹åŒ–æœå‹™
        config = Config()
        service = CleanupService(config)
        
        # åŸ·è¡Œæ¸¬è©¦
        if test_type == "local":
            result = service.run_local_test(sample_size)
        elif test_type == "database":
            result = service.run_database_test(sample_size)
        elif test_type == "full":
            result = service.run_full_cleanup_test(sample_size)
        else:
            print(f"æœªçŸ¥çš„æ¸¬è©¦é¡å‹: {test_type}")
            return False
        
        # é¡¯ç¤ºçµæœ
        if result.get('success'):
            print("æ¸¬è©¦æˆåŠŸï¼")
            print(f"çµæœ: {result}")
        else:
            print("æ¸¬è©¦å¤±æ•—ï¼")
            print(f"éŒ¯èª¤: {result.get('error')}")
        
        return result.get('success', False)
        
    except Exception as e:
        logger.error(f"åŸ·è¡Œæœå‹™æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»ç¨‹å¼å…¥å£é»"""
    parser = argparse.ArgumentParser(
        description="Data Cleaning æ¨¡çµ„å‘½ä»¤åˆ—å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # åˆ—å‡ºæ‰€æœ‰æ¸…ç†å™¨
  python main.py --list-cleaners
  
  # æ¸¬è©¦æ¸…ç†å™¨
  python main.py --test-cleaners
  
  # æ¸…ç†è³‡æ–™æª”æ¡ˆ
  python main.py --clean --input data.json --output cleaned_data.json
  
  # è™•ç†è‚¡ç™Œè³‡æ–™
  python main.py --process-stock-cancer --input stock_cancer.json
  
  # è™•ç†è‚¡ç™Œè³‡æ–™ä¸¦åŒ¯å…¥ PostgreSQL
  python main.py --process-stock-cancer --input stock_cancer.json --import-postgresql
  
  # åŒ¯å…¥ PostgreSQL
  python main.py --import-postgresql --input cleaned_data.json
  
  # åŸ·è¡Œæœå‹™æ¸¬è©¦
  python main.py --service-test local --sample-size 50
  python main.py --service-test database --sample-size 50
  python main.py --service-test full --sample-size 50
        """
    )
    
    # åŸºæœ¬é¸é …
    parser.add_argument('--list-cleaners', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¸…ç†å™¨')
    parser.add_argument('--test-cleaners', action='store_true',
                       help='æ¸¬è©¦æ‰€æœ‰æ¸…ç†å™¨åŠŸèƒ½')
    
    # æ¸…ç†é¸é …
    parser.add_argument('--clean', action='store_true',
                       help='æ¸…ç†è³‡æ–™æª”æ¡ˆ')
    parser.add_argument('--input', type=str,
                       help='è¼¸å…¥æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--output', type=str,
                       help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    
    # è‚¡ç™Œè™•ç†é¸é …
    parser.add_argument('--process-stock-cancer', action='store_true',
                       help='è™•ç†è‚¡ç™Œè³‡æ–™')
    parser.add_argument('--import-postgresql', action='store_true',
                       help='åŒ¯å…¥è³‡æ–™åˆ° PostgreSQL')
    
    # æœå‹™æ¸¬è©¦é¸é …
    parser.add_argument('--service-test', type=str, choices=['local', 'database', 'full'],
                       help='åŸ·è¡Œæœå‹™æ¸¬è©¦ (local/database/full)')
    parser.add_argument('--sample-size', type=int, default=100,
                       help='æ¸¬è©¦æ¨£æœ¬å¤§å° (é è¨­: 100)')
    
    args = parser.parse_args()
    
    # åŸ·è¡Œå°æ‡‰åŠŸèƒ½
    if args.list_cleaners:
        return list_cleaners()
    
    elif args.test_cleaners:
        return test_cleaners()
    
    elif args.clean:
        if not args.input:
            print("éŒ¯èª¤: æ¸…ç†è³‡æ–™éœ€è¦æŒ‡å®š --input åƒæ•¸")
            return False
        return clean_data(args.input, args.output or f"cleaned_{args.input}")
    
    elif args.process_stock_cancer:
        if not args.input:
            print("éŒ¯èª¤: è™•ç†è‚¡ç™Œè³‡æ–™éœ€è¦æŒ‡å®š --input åƒæ•¸")
            return False
        return process_stock_cancer(args.input, args.import_postgresql)
    
    elif args.import_postgresql:
        if not args.input:
            print("éŒ¯èª¤: åŒ¯å…¥ PostgreSQL éœ€è¦æŒ‡å®š --input åƒæ•¸")
            return False
        return import_postgresql(args.input)
    
    elif args.service_test:
        return run_service_test(args.service_test, args.sample_size)
    
    else:
        parser.print_help()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 