#!/usr/bin/env python3
"""
é©—è­‰ä¸Šå‚³çµæœè…³æœ¬
ç¢ºèªè³‡æ–™æ˜¯å¦æ­£ç¢ºæ’å…¥ä¸”æ²’æœ‰é‡è¤‡
"""

import os
import sys
import logging
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime
from typing import List, Dict, Any, Optional, Set
from pathlib import Path
import traceback

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class UploadResultVerifier:
    """ä¸Šå‚³çµæœé©—è­‰é¡åˆ¥"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥"""
        self.config = config
        self.conn = None
        self._connect()
    
    def _connect(self):
        """å»ºç«‹è³‡æ–™åº«é€£æ¥"""
        try:
            if self.conn:
                self.conn.close()
            
            self.conn = psycopg2.connect(
                host=self.config['host'],
                port=self.config['port'],
                database=self.config['database'],
                user=self.config['user'],
                password=self.config['password']
            )
            self.conn.autocommit = False
            logger.info("PostgreSQL é€£æ¥æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
            raise
    
    def get_podcasts_summary(self) -> Dict[str, Any]:
        """ç²å– Podcasts è¡¨æ ¼æ‘˜è¦"""
        try:
            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # ç¸½æ•¸
                cursor.execute("SELECT COUNT(*) as total FROM podcasts")
                total = cursor.fetchone()['total']
                
                # æœ€è¿‘æ–°å¢çš„
                cursor.execute("""
                    SELECT COUNT(*) as recent_count 
                    FROM podcasts 
                    WHERE created_at >= CURRENT_DATE - INTERVAL '1 day'
                """)
                recent_count = cursor.fetchone()['recent_count']
                
                # åˆ†é¡çµ±è¨ˆ
                cursor.execute("""
                    SELECT category, COUNT(*) as count 
                    FROM podcasts 
                    WHERE category IS NOT NULL 
                    GROUP BY category 
                    ORDER BY count DESC
                """)
                categories = cursor.fetchall()
                
                # èªè¨€çµ±è¨ˆ
                cursor.execute("""
                    SELECT languages, COUNT(*) as count 
                    FROM podcasts 
                    WHERE languages IS NOT NULL 
                    GROUP BY languages 
                    ORDER BY count DESC
                """)
                languages = cursor.fetchall()
                
                return {
                    'total': total,
                    'recent_count': recent_count,
                    'categories': categories,
                    'languages': languages
                }
                
        except Exception as e:
            logger.error(f"ç²å– Podcasts æ‘˜è¦å¤±æ•—: {e}")
            return {}
    
    def get_episodes_summary(self) -> Dict[str, Any]:
        """ç²å– Episodes è¡¨æ ¼æ‘˜è¦"""
        try:
            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # ç¸½æ•¸
                cursor.execute("SELECT COUNT(*) as total FROM episodes")
                total = cursor.fetchone()['total']
                
                # æœ€è¿‘æ–°å¢çš„
                cursor.execute("""
                    SELECT COUNT(*) as recent_count 
                    FROM episodes 
                    WHERE created_at >= CURRENT_DATE - INTERVAL '1 day'
                """)
                recent_count = cursor.fetchone()['recent_count']
                
                # æŒ‰ podcast_id çµ±è¨ˆ
                cursor.execute("""
                    SELECT podcast_id, COUNT(*) as episode_count 
                    FROM episodes 
                    GROUP BY podcast_id 
                    ORDER BY episode_count DESC 
                    LIMIT 10
                """)
                podcast_stats = cursor.fetchall()
                
                # æª¢æŸ¥é‡è¤‡
                cursor.execute("""
                    SELECT podcast_id, episode_title, COUNT(*) as duplicate_count
                    FROM episodes 
                    GROUP BY podcast_id, episode_title 
                    HAVING COUNT(*) > 1
                    ORDER BY duplicate_count DESC
                """)
                duplicates = cursor.fetchall()
                
                # èªè¨€çµ±è¨ˆ
                cursor.execute("""
                    SELECT languages, COUNT(*) as count 
                    FROM episodes 
                    WHERE languages IS NOT NULL 
                    GROUP BY languages 
                    ORDER BY count DESC
                """)
                languages = cursor.fetchall()
                
                return {
                    'total': total,
                    'recent_count': recent_count,
                    'podcast_stats': podcast_stats,
                    'duplicates': duplicates,
                    'languages': languages
                }
                
        except Exception as e:
            logger.error(f"ç²å– Episodes æ‘˜è¦å¤±æ•—: {e}")
            return {}
    
    def check_data_integrity(self) -> Dict[str, Any]:
        """æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§"""
        try:
            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # æª¢æŸ¥å¤–éµå®Œæ•´æ€§
                cursor.execute("""
                    SELECT COUNT(*) as orphan_count
                    FROM episodes e
                    LEFT JOIN podcasts p ON e.podcast_id = p.podcast_id
                    WHERE p.podcast_id IS NULL
                """)
                orphan_episodes = cursor.fetchone()['orphan_count']
                
                # æª¢æŸ¥ç©ºæ¨™é¡Œ
                cursor.execute("""
                    SELECT COUNT(*) as empty_title_count
                    FROM episodes 
                    WHERE episode_title IS NULL OR episode_title = ''
                """)
                empty_titles = cursor.fetchone()['empty_title_count']
                
                # æª¢æŸ¥ç©º podcast åç¨±
                cursor.execute("""
                    SELECT COUNT(*) as empty_name_count
                    FROM podcasts 
                    WHERE name IS NULL OR name = ''
                """)
                empty_names = cursor.fetchone()['empty_name_count']
                
                return {
                    'orphan_episodes': orphan_episodes,
                    'empty_titles': empty_titles,
                    'empty_names': empty_names
                }
                
        except Exception as e:
            logger.error(f"æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§å¤±æ•—: {e}")
            return {}
    
    def get_sample_data(self, table_name: str, limit: int = 5) -> List[Dict[str, Any]]:
        """ç²å–æ¨£æœ¬è³‡æ–™"""
        try:
            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:
                cursor.execute(f"SELECT * FROM {table_name} ORDER BY created_at DESC LIMIT {limit}")
                return cursor.fetchall()
                
        except Exception as e:
            logger.error(f"ç²å– {table_name} æ¨£æœ¬è³‡æ–™å¤±æ•—: {e}")
            return []
    
    def verify_batch_input_mapping(self, batch_input_folder: str) -> Dict[str, Any]:
        """é©—è­‰ batch_input è³‡æ–™å¤¾çš„æ˜ å°„"""
        try:
            json_files = [f for f in os.listdir(batch_input_folder) if f.endswith('.json')]
            
            podcast_files = [f for f in json_files if f.startswith('podcast_')]
            rss_files = [f for f in json_files if f.startswith('RSS_') or f.startswith('Spotify_RSS_')]
            
            # æå– podcast_id
            podcast_ids_from_files = set()
            for filename in podcast_files:
                if filename.startswith('podcast_'):
                    try:
                        # ç§»é™¤ .json å‰¯æª”åå¾Œå†åˆ†å‰²
                        name_without_ext = filename.replace('.json', '')
                        podcast_id = int(name_without_ext.split('_')[1])
                        podcast_ids_from_files.add(podcast_id)
                    except (IndexError, ValueError) as e:
                        logger.warning(f"ç„¡æ³•è§£æ podcast æª”æ¡ˆåç¨±: {filename}, éŒ¯èª¤: {e}")
                        continue
            
            for filename in rss_files:
                try:
                    # ç§»é™¤ .json å‰¯æª”åå¾Œå†åˆ†å‰²
                    name_without_ext = filename.replace('.json', '')
                    if filename.startswith('RSS_'):
                        podcast_id = int(name_without_ext.split('_')[1])
                        podcast_ids_from_files.add(podcast_id)
                    elif filename.startswith('Spotify_RSS_'):
                        podcast_id = int(name_without_ext.split('_')[2])
                        podcast_ids_from_files.add(podcast_id)
                except (IndexError, ValueError) as e:
                    logger.warning(f"ç„¡æ³•è§£æ RSS æª”æ¡ˆåç¨±: {filename}, éŒ¯èª¤: {e}")
                    continue
            
            # æª¢æŸ¥è³‡æ–™åº«ä¸­çš„ podcast_id
            with self.conn.cursor() as cursor:
                cursor.execute("SELECT podcast_id FROM podcasts")
                podcast_ids_in_db = {row[0] for row in cursor.fetchall()}
            
            # æª¢æŸ¥æ˜ å°„
            missing_in_db = podcast_ids_from_files - podcast_ids_in_db
            extra_in_db = podcast_ids_in_db - podcast_ids_from_files
            
            return {
                'total_files': len(json_files),
                'podcast_files': len(podcast_files),
                'rss_files': len(rss_files),
                'podcast_ids_from_files': len(podcast_ids_from_files),
                'podcast_ids_in_db': len(podcast_ids_in_db),
                'missing_in_db': list(missing_in_db),
                'extra_in_db': list(extra_in_db),
                'mapping_complete': len(missing_in_db) == 0
            }
            
        except Exception as e:
            logger.error(f"é©—è­‰ batch_input æ˜ å°„å¤±æ•—: {e}")
            return {}
    
    def generate_verification_report(self, batch_input_folder: str) -> str:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        logger.info("é–‹å§‹ç”Ÿæˆé©—è­‰å ±å‘Š...")
        
        # ç²å–å„é …çµ±è¨ˆ
        podcasts_summary = self.get_podcasts_summary()
        episodes_summary = self.get_episodes_summary()
        data_integrity = self.check_data_integrity()
        mapping_verification = self.verify_batch_input_mapping(batch_input_folder)
        
        # ç”Ÿæˆå ±å‘Š
        report = []
        report.append("=" * 80)
        report.append("è³‡æ–™ä¸Šå‚³çµæœé©—è­‰å ±å‘Š")
        report.append("=" * 80)
        report.append(f"é©—è­‰æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Podcasts çµ±è¨ˆ
        report.append(f"\nğŸ“Š Podcasts çµ±è¨ˆ:")
        report.append(f"   - ç¸½æ•¸: {podcasts_summary.get('total', 0):,}")
        report.append(f"   - ä»Šæ—¥æ–°å¢: {podcasts_summary.get('recent_count', 0):,}")
        
        if podcasts_summary.get('categories'):
            report.append(f"   - åˆ†é¡çµ±è¨ˆ:")
            for cat in podcasts_summary['categories'][:5]:  # åªé¡¯ç¤ºå‰5å€‹
                report.append(f"     â€¢ {cat['category']}: {cat['count']}")
        
        if podcasts_summary.get('languages'):
            report.append(f"   - èªè¨€çµ±è¨ˆ:")
            for lang in podcasts_summary['languages'][:3]:  # åªé¡¯ç¤ºå‰3å€‹
                report.append(f"     â€¢ {lang['languages']}: {lang['count']}")
        
        # Episodes çµ±è¨ˆ
        report.append(f"\nğŸ“» Episodes çµ±è¨ˆ:")
        report.append(f"   - ç¸½æ•¸: {episodes_summary.get('total', 0):,}")
        report.append(f"   - ä»Šæ—¥æ–°å¢: {episodes_summary.get('recent_count', 0):,}")
        
        if episodes_summary.get('podcast_stats'):
            report.append(f"   - å‰5å€‹ Podcast çš„ Episode æ•¸é‡:")
            for stat in episodes_summary['podcast_stats'][:5]:
                report.append(f"     â€¢ Podcast {stat['podcast_id']}: {stat['episode_count']} episodes")
        
        if episodes_summary.get('languages'):
            report.append(f"   - èªè¨€çµ±è¨ˆ:")
            for lang in episodes_summary['languages'][:3]:
                report.append(f"     â€¢ {lang['languages']}: {lang['count']}")
        
        # è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥
        report.append(f"\nğŸ” è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥:")
        report.append(f"   - å­¤ç«‹ Episodes: {data_integrity.get('orphan_episodes', 0)}")
        report.append(f"   - ç©ºæ¨™é¡Œ Episodes: {data_integrity.get('empty_titles', 0)}")
        report.append(f"   - ç©ºåç¨± Podcasts: {data_integrity.get('empty_names', 0)}")
        
        # é‡è¤‡æª¢æŸ¥
        if episodes_summary.get('duplicates'):
            report.append(f"   - é‡è¤‡ Episodes: {len(episodes_summary['duplicates'])} çµ„")
            for dup in episodes_summary['duplicates'][:3]:  # åªé¡¯ç¤ºå‰3å€‹
                report.append(f"     â€¢ Podcast {dup['podcast_id']} - {dup['episode_title']}: {dup['duplicate_count']} æ¬¡")
        else:
            report.append(f"   - é‡è¤‡ Episodes: âœ… ç„¡é‡è¤‡")
        
        # æ˜ å°„é©—è­‰
        report.append(f"\nğŸ“ Batch Input æ˜ å°„é©—è­‰:")
        report.append(f"   - ç¸½æª”æ¡ˆæ•¸: {mapping_verification.get('total_files', 0)}")
        report.append(f"   - Podcast æª”æ¡ˆ: {mapping_verification.get('podcast_files', 0)}")
        report.append(f"   - RSS æª”æ¡ˆ: {mapping_verification.get('rss_files', 0)}")
        report.append(f"   - æª”æ¡ˆä¸­çš„ Podcast ID: {mapping_verification.get('podcast_ids_from_files', 0)}")
        report.append(f"   - è³‡æ–™åº«ä¸­çš„ Podcast ID: {mapping_verification.get('podcast_ids_in_db', 0)}")
        
        if mapping_verification.get('missing_in_db'):
            report.append(f"   - ç¼ºå°‘åœ¨è³‡æ–™åº«: {mapping_verification['missing_in_db']}")
        
        if mapping_verification.get('extra_in_db'):
            report.append(f"   - è³‡æ–™åº«ä¸­å¤šé¤˜: {mapping_verification['extra_in_db']}")
        
        if mapping_verification.get('mapping_complete'):
            report.append(f"   - æ˜ å°„ç‹€æ…‹: âœ… å®Œæ•´")
        else:
            report.append(f"   - æ˜ å°„ç‹€æ…‹: âš ï¸ ä¸å®Œæ•´")
        
        # ç¸½çµ
        report.append(f"\n{'='*80}")
        report.append("ç¸½çµ")
        report.append(f"{'='*80}")
        
        total_issues = (
            data_integrity.get('orphan_episodes', 0) +
            data_integrity.get('empty_titles', 0) +
            data_integrity.get('empty_names', 0) +
            len(episodes_summary.get('duplicates', []))
        )
        
        if total_issues == 0 and mapping_verification.get('mapping_complete'):
            report.append("âœ… è³‡æ–™ä¸Šå‚³é©—è­‰æˆåŠŸï¼æ‰€æœ‰è³‡æ–™æ­£ç¢ºæ’å…¥ä¸”ç„¡é‡è¤‡")
        else:
            report.append(f"âš ï¸ ç™¼ç¾ {total_issues} å€‹å•é¡Œï¼Œè«‹æª¢æŸ¥ä¸Šè¿°è©³ç´°è³‡è¨Š")
        
        report.append(f"\n{'='*80}")
        return "\n".join(report)
    
    def close(self):
        """é—œé–‰è³‡æ–™åº«é€£æ¥"""
        if self.conn:
            self.conn.close()
            logger.info("è³‡æ–™åº«é€£æ¥å·²é—œé–‰")

def main():
    """ä¸»ç¨‹å¼"""
    logger.info("=== é©—è­‰ä¸Šå‚³çµæœ ===")
    
    # è³‡æ–™åº«é…ç½®
    config = {
        'host': os.getenv('POSTGRES_HOST', 'postgres.podwise.svc.cluster.local'),
        'port': int(os.getenv('POSTGRES_PORT', 5432)),
        'database': os.getenv('POSTGRES_DB', 'podcast'),
        'user': os.getenv('POSTGRES_USER', 'bdse37'),
        'password': os.getenv('POSTGRES_PASSWORD', '111111')
    }
    
    # batch_input è³‡æ–™å¤¾è·¯å¾‘
    batch_input_folder = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        'batch_input'
    )
    
    try:
        # å»ºç«‹é©—è­‰å™¨
        verifier = UploadResultVerifier(config)
        
        # ç”Ÿæˆé©—è­‰å ±å‘Š
        report = verifier.generate_verification_report(batch_input_folder)
        print(report)
        
        # å„²å­˜å ±å‘Š
        report_file = os.path.join(os.path.dirname(batch_input_folder), 'upload_verification_report.txt')
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"é©—è­‰å ±å‘Šå·²å„²å­˜åˆ°: {report_file}")
        
        # é—œé–‰é€£æ¥
        verifier.close()
        
    except Exception as e:
        logger.error(f"é©—è­‰å¤±æ•—: {e}")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 