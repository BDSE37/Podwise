#!/usr/bin/env python3
"""
ç°¡åŒ–çš„æ‰¹æ¬¡è™•ç†æ¸¬è©¦è…³æœ¬
é©—è­‰ OOP æ¶æ§‹å’Œå¾ªç’°è™•ç†åŠŸèƒ½
"""

import sys
import logging
from pathlib import Path

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_batch_processor_initialization():
    """æ¸¬è©¦æ‰¹æ¬¡è™•ç†å™¨åˆå§‹åŒ–"""
    print("ğŸ§ª æ¸¬è©¦æ‰¹æ¬¡è™•ç†å™¨åˆå§‹åŒ–...")
    
    try:
        from batch_process_podcasts import BatchProcessor
        
        # æ¸¬è©¦é…ç½®
        mongo_config = {
            "host": "192.168.32.86",
            "port": 30017,
            "username": "bdse37",
            "password": "111111",
            "database": "podcast"
        }
        
        postgres_config = {
            "host": "192.168.32.56",
            "port": 32432,
            "database": "podcast",
            "user": "bdse37",
            "password": "111111"
        }
        
        milvus_config = {
            "host": "192.168.32.86",
            "port": "19530",
            "collection_name": "podcast_chunks",
            "dim": 1024,
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 1024}
        }
        
        # å‰µå»ºæ‰¹æ¬¡è™•ç†å™¨
        processor = BatchProcessor(
            mongo_config=mongo_config,
            postgres_config=postgres_config,
            milvus_config=milvus_config,
            collections_per_cycle=5
        )
        
        # æ¸¬è©¦åˆå§‹åŒ–
        if processor.initialize():
            print("  âœ… æ‰¹æ¬¡è™•ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # ç²å– collections
            collections = processor.orchestrator.mongo_processor.get_collection_names()
            print(f"  ğŸ“‹ æ‰¾åˆ° {len(collections)} å€‹ collections")
            
            if collections:
                print(f"  ğŸ“‹ å‰ 5 å€‹ collections: {collections[:5]}")
                
                # æ¸¬è©¦å¾ªç’°è¨ˆç®—
                current_cycle = processor.progress_manager.get_current_cycle()
                start_index = current_cycle * processor.collections_per_cycle
                end_index = min(start_index + processor.collections_per_cycle, len(collections))
                current_collections = collections[start_index:end_index]
                
                print(f"  ğŸ”„ ç•¶å‰å¾ªç’° {current_cycle + 1} å°‡è™•ç†: {current_collections}")
                
                return True
            else:
                print("  âš ï¸  æ²’æœ‰æ‰¾åˆ° collections")
                return False
        else:
            print("  âŒ æ‰¹æ¬¡è™•ç†å™¨åˆå§‹åŒ–å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"  âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_metadata_validation():
    """æ¸¬è©¦ metadata é©—è­‰"""
    print("ğŸ§ª æ¸¬è©¦ metadata é©—è­‰...")
    
    try:
        from batch_process_podcasts import MetadataValidator
        
        validator = MetadataValidator()
        
        # å‰µå»ºæ¸¬è©¦ metadata
        class TestMetadata:
            def __init__(self):
                self.episode_id = 123
                self.podcast_id = 456
                self.episode_title = "æ¸¬è©¦ç¯€ç›®"
                self.podcast_name = "æ¸¬è©¦æ’­å®¢"
                self.author = "æ¸¬è©¦ä½œè€…"
                self.category = "ç§‘æŠ€"
        
        # æ¸¬è©¦å®Œæ•´ metadata
        complete_metadata = TestMetadata()
        is_complete = validator.is_metadata_complete(complete_metadata)
        print(f"  âœ… å®Œæ•´ metadata é©—è­‰: {is_complete}")
        
        # æ¸¬è©¦ä¸å®Œæ•´ metadata
        incomplete_metadata = TestMetadata()
        incomplete_metadata.episode_id = 0  # è¨­ç‚º 0
        is_incomplete = validator.is_metadata_complete(incomplete_metadata)
        print(f"  âœ… ä¸å®Œæ•´ metadata é©—è­‰: {is_incomplete}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_progress_management():
    """æ¸¬è©¦é€²åº¦ç®¡ç†"""
    print("ğŸ§ª æ¸¬è©¦é€²åº¦ç®¡ç†...")
    
    try:
        from batch_process_podcasts import FileProgressManager
        
        # å‰µå»ºæ¸¬è©¦é€²åº¦ç®¡ç†å™¨
        progress_manager = FileProgressManager("test_progress.json")
        
        # æ¸¬è©¦é€²åº¦æ“ä½œ
        progress_manager.save_progress(
            last_processed_collection="test_collection",
            total_processed_chunks=100
        )
        
        current_cycle = progress_manager.get_current_cycle()
        print(f"  âœ… ç•¶å‰å¾ªç’°: {current_cycle}")
        
        # å¢åŠ å¾ªç’°
        progress_manager.increment_cycle()
        new_cycle = progress_manager.get_current_cycle()
        print(f"  âœ… æ–°å¾ªç’°: {new_cycle}")
        
        # æ¨™è¨˜ collection å®Œæˆ
        progress_manager.mark_collection_completed("test_collection")
        
        # æª¢æŸ¥æ˜¯å¦æ‡‰è©²è·³é
        should_skip = progress_manager.should_skip_collection("test_collection")
        print(f"  âœ… æ‡‰è©²è·³é test_collection: {should_skip}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_tag_processing():
    """æ¸¬è©¦æ¨™ç±¤è™•ç†"""
    print("ğŸ§ª æ¸¬è©¦æ¨™ç±¤è™•ç†...")
    
    try:
        from vector_pipeline.pipeline_orchestrator import TagProcessorManager
        
        # å‰µå»ºæ¨™ç±¤è™•ç†å™¨
        tag_manager = TagProcessorManager("TAG_info.csv")
        
        # æ¸¬è©¦ä¸åŒé¡å‹çš„æ–‡æœ¬
        test_cases = [
            "é€™æ˜¯ä¸€å€‹é—œæ–¼ AI å’Œäººå·¥æ™ºæ…§çš„ç§‘æŠ€ç¯€ç›®",
            "å•†æ¥­ç®¡ç†å’Œä¼æ¥­é ˜å°çš„è©±é¡Œè¨è«–",
            "æ•™è‚²å­¸ç¿’å’ŒçŸ¥è­˜åˆ†äº«çš„å…§å®¹",
            "å‰µæ¥­æ–°å‰µå’Œå•†æ¥­æ¨¡å¼çš„æ¢è¨",
            "é€™æ˜¯ä¸€å€‹å¾ˆçŸ­çš„æ–‡æœ¬"
        ]
        
        for i, text in enumerate(test_cases, 1):
            tags = tag_manager.extract_tags(text)
            print(f"  ğŸ“ æ¸¬è©¦ {i}: {tags}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ç°¡åŒ–æ‰¹æ¬¡è™•ç†æ¸¬è©¦")
    print("=" * 80)
    
    test_results = []
    
    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    test_results.append(("æ‰¹æ¬¡è™•ç†å™¨åˆå§‹åŒ–", test_batch_processor_initialization()))
    test_results.append(("Metadata é©—è­‰", test_metadata_validation()))
    test_results.append(("é€²åº¦ç®¡ç†", test_progress_management()))
    test_results.append(("æ¨™ç±¤è™•ç†", test_tag_processing()))
    
    # è¼¸å‡ºæ¸¬è©¦çµæœ
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 80)
    
    for test_name, result in test_results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{test_name}: {status}")
    
    # è¨ˆç®—æˆåŠŸç‡
    passed_tests = sum(1 for _, result in test_results if result)
    total_tests = len(test_results)
    success_rate = (passed_tests / total_tests) * 100
    
    print(f"\nğŸ¯ æ¸¬è©¦æˆåŠŸç‡: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
    
    if success_rate == 100:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼æ‰¹æ¬¡è™•ç†åŠŸèƒ½æ­£å¸¸")
        print("\nğŸ’¡ å¯ä»¥é–‹å§‹åŸ·è¡Œæ‰¹æ¬¡è™•ç†:")
        print("   python batch_process_podcasts.py")
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦é€²ä¸€æ­¥æª¢æŸ¥")
    
    print("\n" + "=" * 80)
    print("ğŸ æ¸¬è©¦å®Œæˆ")


if __name__ == "__main__":
    main() 