"""
é€šç”¨ YouTube æ¸…ç†å™¨
å°ˆé–€è™•ç†ä»»ä½• YouTube é »é“çš„è³‡æ–™

æ¸…ç†é‚è¼¯ï¼š
- æ¨™é¡Œï¼šç§»é™¤è¡¨æƒ…ç¬¦è™Ÿã€ç‰¹æ®Šç¬¦è™Ÿã€YouTube ç‰¹æœ‰æ¨™è¨˜
- ä½œè€…ï¼šæ¸…ç†é »é“åç¨±ï¼Œç§»é™¤å®˜æ–¹æ¨™è¨˜
- è§€çœ‹æ¬¡æ•¸ã€æŒ‰è®šæ•¸ã€è©•è«–æ•¸ï¼šæ¨™æº–åŒ–æ•¸å­—æ ¼å¼
- è©•è«–ï¼šæ¸…ç†è©•è«–å…§å®¹
- æª”æ¡ˆåç¨±ï¼šä½¿ç”¨èˆ‡å…§æ–‡ç›¸åŒçš„æ¸…ç†é‚è¼¯
- é‡å° YouTube è³‡æ–™æ ¼å¼é€²è¡Œå„ªåŒ–
- æ”¯æ´è‡ªå®šç¾©æ¬„ä½æ¸…ç†é…ç½®
"""

import re
import sys
import logging
import os
import json
from pathlib import Path
from typing import Dict, Any, List, Optional, Set
from datetime import datetime

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ä»¥æ”¯æ´çµ•å°å°å…¥
sys.path.append(str(Path(__file__).parent.parent.parent))

try:
    from data_cleaning.core.base_cleaner import BaseCleaner
    from data_cleaning.core.longtext_cleaner import LongTextCleaner
except ImportError:
    # Fallback: ç›¸å°å°å…¥
    from core.base_cleaner import BaseCleaner
    from core.longtext_cleaner import LongTextCleaner


class YouTubeCleaner(BaseCleaner):
    """é€šç”¨ YouTube æ¸…ç†å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ– YouTube æ¸…ç†å™¨
        
        Args:
            config: æ¸…ç†é…ç½®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹é¸é …ï¼š
                - fields_to_clean: éœ€è¦æ¸…ç†çš„æ¬„ä½åˆ—è¡¨
                - title_clean_rules: æ¨™é¡Œæ¸…ç†è¦å‰‡
                - author_clean_rules: ä½œè€…æ¸…ç†è¦å‰‡
                - number_clean_rules: æ•¸å­—æ¬„ä½æ¸…ç†è¦å‰‡
                - comment_clean_rules: è©•è«–æ¸…ç†è¦å‰‡
                - filename_clean_rules: æª”æ¡ˆåç¨±æ¸…ç†è¦å‰‡
        """
        self.longtext_cleaner = LongTextCleaner()
        self.logger = logging.getLogger(__name__)
        
        # é è¨­é…ç½®
        self.default_config = {
            "fields_to_clean": {
                "title": {
                    "enabled": True,
                    "clean_type": "title",
                    "description": "æ¸…ç†æ¨™é¡Œï¼Œç§»é™¤è¡¨æƒ…ç¬¦è™Ÿå’Œç‰¹æ®Šæ¨™è¨˜"
                },
                "author": {
                    "enabled": True,
                    "clean_type": "author",
                    "description": "æ¸…ç†ä½œè€…æ¬„ä½ï¼Œç§»é™¤å®˜æ–¹æ¨™è¨˜"
                },
                "view_count": {
                    "enabled": True,
                    "clean_type": "number",
                    "description": "æ¸…ç†è§€çœ‹æ¬¡æ•¸ï¼Œæ¨™æº–åŒ–ç‚ºæ•¸å­—"
                },
                "like_count": {
                    "enabled": True,
                    "clean_type": "number",
                    "description": "æ¸…ç†æŒ‰è®šæ•¸ï¼Œæ¨™æº–åŒ–ç‚ºæ•¸å­—"
                },
                "comment_count": {
                    "enabled": True,
                    "clean_type": "number",
                    "description": "æ¸…ç†è©•è«–æ•¸ï¼Œæ¨™æº–åŒ–ç‚ºæ•´æ•¸"
                },
                "comments": {
                    "enabled": True,
                    "clean_type": "list",
                    "description": "æ¸…ç†è©•è«–åˆ—è¡¨"
                },
                "description": {
                    "enabled": False,
                    "clean_type": "text",
                    "description": "æ¸…ç†æè¿°æ¬„ä½"
                },
                "content": {
                    "enabled": False,
                    "clean_type": "text",
                    "description": "æ¸…ç†å…§å®¹æ¬„ä½"
                },
                "summary": {
                    "enabled": False,
                    "clean_type": "text",
                    "description": "æ¸…ç†æ‘˜è¦æ¬„ä½"
                },
                "filename": {
                    "enabled": False,
                    "clean_type": "filename",
                    "description": "æ¸…ç†æª”æ¡ˆåç¨±ï¼Œä½¿ç”¨èˆ‡å…§æ–‡ç›¸åŒçš„æ¸…ç†é‚è¼¯"
                }
            },
            "title_clean_rules": {
                "remove_emoji": True,
                "remove_special_symbols": True,
                "remove_youtube_patterns": True,
                "normalize_format": True
            },
            "author_clean_rules": {
                "remove_official_tags": True,
                "remove_special_symbols": True
            },
            "number_clean_rules": {
                "remove_prefixes": ["è§€çœ‹æ¬¡æ•¸ï¼š", "è®šæ•¸ï¼š", "ç•™è¨€æ•¸ï¼š"],
                "remove_suffixes": ["æ¬¡", "å€‹", "è¬", "åƒ"],
                "extract_numbers_only": True
            },
            "comment_clean_rules": {
                "remove_emoji": True,
                "remove_special_symbols": True,
                "normalize_text": True
            },
            "filename_clean_rules": {
                "remove_emoji": True,
                "remove_special_symbols": True,
                "remove_youtube_patterns": True,
                "remove_invalid_chars": True,
                "normalize_format": True,
                "max_length": 100,
                "replace_spaces": True,
                "allowed_extensions": [".json", ".txt", ".csv"]
            }
        }
        
        # åˆä½µè‡ªå®šç¾©é…ç½®
        self.config = self._merge_config(self.default_config, config or {})
        
    def _merge_config(self, default: Dict[str, Any], custom: Dict[str, Any]) -> Dict[str, Any]:
        """åˆä½µé è¨­é…ç½®å’Œè‡ªå®šç¾©é…ç½®"""
        merged = default.copy()
        
        # åˆä½µæ¬„ä½é…ç½®
        if "fields_to_clean" in custom:
            for field, field_config in custom["fields_to_clean"].items():
                if field in merged["fields_to_clean"]:
                    merged["fields_to_clean"][field].update(field_config)
                else:
                    merged["fields_to_clean"][field] = field_config
        
        # åˆä½µæ¸…ç†è¦å‰‡
        for rule_type in ["title_clean_rules", "author_clean_rules", "number_clean_rules", "comment_clean_rules", "filename_clean_rules"]:
            if rule_type in custom:
                merged[rule_type].update(custom[rule_type])
        
        return merged
        
    def clean(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ¸…ç† YouTube è³‡æ–™
        Args:
            data: åŒ…å«å„ç¨®æ¬„ä½çš„å­—å…¸
        Returns:
            æ¸…ç†å¾Œçš„è³‡æ–™å­—å…¸
        """
        cleaned_data = data.copy()
        
        # æ ¹æ“šé…ç½®æ¸…ç†å„å€‹æ¬„ä½
        for field_name, field_config in self.config["fields_to_clean"].items():
            if not field_config.get("enabled", True):
                continue
                
            if field_name in cleaned_data:
                clean_type = field_config.get("clean_type", "text")
                
                if clean_type == "title":
                    cleaned_data[field_name] = self._clean_youtube_title(cleaned_data[field_name])
                elif clean_type == "author":
                    cleaned_data[field_name] = self._clean_author(cleaned_data[field_name])
                elif clean_type == "number":
                    cleaned_data[field_name] = self._clean_number_field(cleaned_data[field_name])
                elif clean_type == "list":
                    cleaned_data[field_name] = self._clean_list_field(cleaned_data[field_name])
                elif clean_type == "filename":
                    cleaned_data[field_name] = self._clean_filename(cleaned_data[field_name])
                elif clean_type == "text":
                    cleaned_data[field_name] = self.longtext_cleaner.clean(cleaned_data[field_name])
        
        return cleaned_data
    
    def _clean_filename(self, filename: str) -> str:
        """
        æ¸…ç†æª”æ¡ˆåç¨±ï¼Œä½¿ç”¨èˆ‡å…§æ–‡ç›¸åŒçš„æ¸…ç†é‚è¼¯
        Args:
            filename: åŸå§‹æª”æ¡ˆåç¨±
        Returns:
            æ¸…ç†å¾Œçš„æª”æ¡ˆåç¨±
        """
        if not filename:
            return ""
        
        rules = self.config["filename_clean_rules"]
        
        # åˆ†é›¢æª”æ¡ˆåç¨±å’Œå‰¯æª”å
        name, ext = os.path.splitext(filename)
        
        # ä½¿ç”¨èˆ‡æ¨™é¡Œç›¸åŒçš„æ¸…ç†é‚è¼¯
        # 1. ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿ
        if rules.get("remove_emoji"):
            name = self._remove_emoji_and_symbols(name)
        
        # 2. ç§»é™¤ç‰¹æ®Šç¬¦è™Ÿ
        if rules.get("remove_special_symbols"):
            # åªä¿ç•™å­—æ¯ã€æ•¸å­—ã€ä¸­æ–‡å’ŒåŸºæœ¬ç¬¦è™Ÿ
            allowed_chars = set(' -_.()[]{}')
            name = ''.join(c for c in name if c.isalnum() or '\u4e00' <= c <= '\u9fff' or c in allowed_chars)
        
        # 3. ç§»é™¤ YouTube ç‰¹æœ‰æ¨¡å¼ï¼ˆèˆ‡æ¨™é¡Œæ¸…ç†ç›¸åŒï¼‰
        if rules.get("remove_youtube_patterns"):
            name = self._remove_youtube_title_patterns(name)
        
        # 4. ç§»é™¤æª”æ¡ˆç³»çµ±ä¸å…è¨±çš„å­—å…ƒ
        if rules.get("remove_invalid_chars"):
            invalid_chars = '<>:"/\\|?*'
            for char in invalid_chars:
                name = name.replace(char, '')
        
        # 5. æ¨™æº–åŒ–æ ¼å¼ï¼ˆèˆ‡æ¨™é¡Œæ¸…ç†ç›¸åŒï¼‰
        if rules.get("normalize_format"):
            name = self._normalize_youtube_title(name)
        
        # 6. æ›¿æ›ç©ºç™½
        if rules.get("replace_spaces"):
            name = name.replace(' ', '_')
        
        # 7. é™åˆ¶é•·åº¦
        max_length = rules.get("max_length", 100)
        if len(name) > max_length:
            name = name[:max_length]
        
        # 8. ç¢ºä¿æª”æ¡ˆåç¨±ä¸ç‚ºç©º
        if not name:
            name = "cleaned_file"
        
        # 9. æª¢æŸ¥å‰¯æª”åæ˜¯å¦å…è¨±
        allowed_extensions = rules.get("allowed_extensions", [".json", ".txt", ".csv"])
        if ext.lower() not in [ext.lower() for ext in allowed_extensions]:
            ext = ".json"  # é è¨­ä½¿ç”¨ .json
        
        return name + ext
    
    def clean_file(self, file_path: str, output_path: Optional[str] = None) -> str:
        """
        æ¸…ç†æª”æ¡ˆå…§å®¹å’Œæª”æ¡ˆåç¨±
        Args:
            file_path: è¼¸å…¥æª”æ¡ˆè·¯å¾‘
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
        Returns:
            æ¸…ç†å¾Œçš„æª”æ¡ˆè·¯å¾‘
        """
        try:
            # è®€å–åŸå§‹æª”æ¡ˆ
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ¸…ç†è³‡æ–™
            cleaned_data = self.clean(data)
            
            # è™•ç†æª”æ¡ˆåç¨±
            original_path = Path(file_path)
            original_name = original_path.name
            
            # å¦‚æœå•Ÿç”¨äº†æª”æ¡ˆåç¨±æ¸…ç†
            if self.config["fields_to_clean"].get("filename", {}).get("enabled", False):
                cleaned_name = self._clean_filename(original_name)
            else:
                cleaned_name = original_name
            
            # æ±ºå®šè¼¸å‡ºè·¯å¾‘
            if output_path:
                output_file = Path(output_path)
            else:
                output_file = original_path.parent / cleaned_name
            
            # å¯«å…¥æ¸…ç†å¾Œçš„æª”æ¡ˆ
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"æª”æ¡ˆæ¸…ç†å®Œæˆ: {file_path} -> {output_file}")
            return str(output_file)
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†æª”æ¡ˆå¤±æ•— {file_path}: {e}")
            raise
    
    def batch_clean_files(self, file_paths: List[str], output_dir: Optional[str] = None) -> List[str]:
        """
        æ‰¹æ¬¡æ¸…ç†å¤šå€‹æª”æ¡ˆ
        Args:
            file_paths: æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
            output_dir: è¼¸å‡ºç›®éŒ„ï¼ˆå¯é¸ï¼‰
        Returns:
            æ¸…ç†å¾Œçš„æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        """
        cleaned_files = []
        
        for i, file_path in enumerate(file_paths):
            try:
                if output_dir:
                    # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆåç¨±
                    original_name = Path(file_path).name
                    if self.config["fields_to_clean"].get("filename", {}).get("enabled", False):
                        cleaned_name = self._clean_filename(original_name)
                    else:
                        cleaned_name = original_name
                    
                    output_path = Path(output_dir) / cleaned_name
                else:
                    output_path = None
                
                cleaned_file = self.clean_file(file_path, str(output_path) if output_path else None)
                cleaned_files.append(cleaned_file)
                
                if (i + 1) % 10 == 0:
                    self.logger.info(f"å·²æ¸…ç† {i + 1}/{len(file_paths)} å€‹æª”æ¡ˆ")
                    
            except Exception as e:
                self.logger.error(f"æ¸…ç†æª”æ¡ˆå¤±æ•— {file_path}: {e}")
                cleaned_files.append(file_path)  # ä¿ç•™åŸå§‹æª”æ¡ˆè·¯å¾‘
        
        return cleaned_files
    
    def _clean_number_field(self, value: Any) -> str:
        """æ¸…ç†æ•¸å­—æ¬„ä½"""
        if not value:
            return "0"
        
        value_str = str(value)
        rules = self.config["number_clean_rules"]
        
        # ç§»é™¤å‰ç¶´
        if rules.get("remove_prefixes"):
            for prefix in rules["remove_prefixes"]:
                value_str = value_str.replace(prefix, "")
        
        # ç§»é™¤å¾Œç¶´
        if rules.get("remove_suffixes"):
            for suffix in rules["remove_suffixes"]:
                value_str = value_str.replace(suffix, "")
        
        # åªä¿ç•™æ•¸å­—
        if rules.get("extract_numbers_only"):
            value_str = re.sub(r'[^\d]', '', value_str)
        
        return value_str if value_str else "0"
    
    def _clean_list_field(self, value: Any) -> List[str]:
        """æ¸…ç†åˆ—è¡¨æ¬„ä½ï¼ˆå¦‚è©•è«–ï¼‰"""
        if not isinstance(value, list):
            return []
        
        rules = self.config["comment_clean_rules"]
        cleaned_list = []
        
        for item in value:
            if isinstance(item, str):
                cleaned_item = item
                
                # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿ
                if rules.get("remove_emoji"):
                    cleaned_item = self._remove_emoji_and_symbols(cleaned_item)
                
                # ç§»é™¤ç‰¹æ®Šç¬¦è™Ÿ
                if rules.get("remove_special_symbols"):
                    allowed_chars = set(' .,!?()[]{}:;\'"#@&+=%$*-_/')
                    cleaned_item = ''.join(c for c in cleaned_item if c.isalnum() or '\u4e00' <= c <= '\u9fff' or c in allowed_chars)
                
                # æ¨™æº–åŒ–æ–‡æœ¬
                if rules.get("normalize_text"):
                    cleaned_item = re.sub(r'\s+', ' ', cleaned_item).strip()
                
                cleaned_list.append(cleaned_item)
            else:
                cleaned_list.append(str(item))
        
        return cleaned_list
    
    def _is_youtube_data(self, data: Dict[str, Any]) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚º YouTube è³‡æ–™"""
        # æª¢æŸ¥æ˜¯å¦æœ‰ YouTube ç‰¹æœ‰çš„æ¬„ä½çµæ§‹
        youtube_fields = ['view_count', 'like_count', 'comment_count', 'comments']
        if all(field in data for field in youtube_fields):
            return True
        
        # æª¢æŸ¥ URL æ˜¯å¦åŒ…å« YouTube ç›¸é—œé—œéµå­—
        url = data.get('url', '').lower()
        if 'youtube.com' in url or 'youtu.be' in url:
            return True
        
        # æª¢æŸ¥æ¨™é¡Œæ˜¯å¦åŒ…å« YouTube ç‰¹æœ‰æ¨™è¨˜
        title = data.get('title', '').lower()
        youtube_keywords = ['è§€çœ‹æ¬¡æ•¸', 'è¨‚é–±', 'æŒ‰è®š', 'åˆ†äº«', 'ç•™è¨€', 'youtube', 'yt']
        if any(keyword in title for keyword in youtube_keywords):
            return True
        
        return False
    
    def _clean_youtube_title(self, title: str) -> str:
        """
        æ¸…ç† YouTube æ¨™é¡Œ
        Args:
            title: åŸå§‹æ¨™é¡Œ
        Returns:
            æ¸…ç†å¾Œçš„æ¨™é¡Œ
        """
        if not title:
            return ""
        
        rules = self.config["title_clean_rules"]
        
        # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿå’Œç‰¹æ®Šç¬¦è™Ÿ
        if rules.get("remove_emoji"):
            title = self._remove_emoji_and_symbols(title)
        
        # ç§»é™¤ YouTube ç‰¹æœ‰çš„æ¨™é¡Œæ¨¡å¼
        if rules.get("remove_youtube_patterns"):
            title = self._remove_youtube_title_patterns(title)
        
        # æ¨™æº–åŒ–æ¨™é¡Œæ ¼å¼
        if rules.get("normalize_format"):
            title = self._normalize_youtube_title(title)
        
        return title
    
    def _remove_emoji_and_symbols(self, text: str) -> str:
        """ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿå’Œç‰¹æ®Šç¬¦è™Ÿ"""
        # ç§»é™¤ Unicode è¡¨æƒ…ç¬¦è™Ÿ
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map symbols
            "\U0001F1E0-\U0001F1FF"  # flags (iOS)
            "\U0001F900-\U0001F9FF"  # supplemental symbols
            "\U0001FA70-\U0001FAFF"  # symbols and pictographs extended-A
            "]+", flags=re.UNICODE)
        text = emoji_pattern.sub('', text)
        
        # ç§»é™¤ç‰¹æ®Šç¬¦è™Ÿï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•¸å­—å’ŒåŸºæœ¬æ¨™é»ï¼ŒåŒ…æ‹¬ URL ç›¸é—œå­—å…ƒï¼‰
        allowed_chars = set(' .,!?()[]{}:;\'"#@&+=%$*-_/')
        text = ''.join(c for c in text if c.isalnum() or '\u4e00' <= c <= '\u9fff' or c in allowed_chars)
        
        return text
    
    def _remove_youtube_title_patterns(self, title: str) -> str:
        """ç§»é™¤ YouTube ç‰¹æœ‰çš„æ¨™é¡Œæ¨¡å¼"""
        # YouTube é »é“ç‰¹æœ‰çš„æ¨™é¡Œæ¨¡å¼
        patterns = [
            # è¡¨æƒ…ç¬¦è™Ÿå’Œç‰¹æ®Šç¬¦è™Ÿ
            r'ğŸš©', r'ğŸ¯', r'ğŸ’¡', r'ğŸ”¥', r'â­', r'ğŸŒŸ', r'âœ¨', r'ğŸ’', r'ğŸ†', r'ğŸ‰',
            r'ğŸ“š', r'ğŸ“–', r'ğŸ“', r'ğŸ“‹', r'ğŸ“Œ', r'ğŸ“', r'ğŸª', r'ğŸ­', r'ğŸ¨', r'ğŸ¬',
            r'ğŸ¤', r'ğŸ§', r'ğŸµ', r'ğŸ¶', r'ğŸ¹', r'ğŸ¸', r'ğŸº', r'ğŸ»', r'ğŸ¥', r'ğŸ·',
            r'ğŸ ', r'ğŸ¡', r'ğŸ¢', r'ğŸ£', r'ğŸ¤', r'ğŸ¥', r'ğŸ¦', r'ğŸ¨', r'ğŸ©', r'ğŸª',
            r'ğŸ«', r'ğŸ¬', r'ğŸ­', r'ğŸ¯', r'ğŸ°', r'ğŸ’’', r'ğŸ—¼', r'ğŸ—½', r'â›ª', r'ğŸ•Œ',
            r'ğŸ›•', r'â›©ï¸', r'ğŸ•', r'â›ª', r'ğŸ›', r'ğŸ“¿', r'ğŸ’', r'ğŸ”®', r'ğŸ”¯', r'ğŸ•‰ï¸',
            
            # YouTube ç‰¹æœ‰æ¨™è¨˜
            r'ã€.*?ã€‘',  # ã€å³æ·¡å¦‚ï¼¸æ—é¦™è˜­ã€‘
            r'\[.*?\]',  # [å³æ·¡å¦‚ï¼¸æ—é¦™è˜­]
            r'ï¼ˆ.*?ï¼‰',  # ï¼ˆå³æ·¡å¦‚ï¼¸æ—é¦™è˜­ï¼‰
            r'\(.*?\)',  # (å³æ·¡å¦‚ï¼¸æ—é¦™è˜­)
            
            # åˆ†éš”ç¬¦è™Ÿ
            r'ï¼¸', r'X', r'x',  # äº¤å‰ç¬¦è™Ÿ
            r'ï½œ', r'|',  # åˆ†éš”ç·š
            r'â€¢', r'Â·', r'Â·',  # é»è™Ÿ
            r'â†’', r'â†', r'â†‘', r'â†“',  # ç®­é ­
            r'â‡’', r'â‡', r'â‡‘', r'â‡“',  # é›™ç®­é ­
            
            # æ•¸å­—å’Œå–®ä½
            r'\d+æ¬¡',  # è§€çœ‹æ¬¡æ•¸
            r'\d+å€‹',  # å€‹æ•¸
            r'\d+å€‹è®š',  # è®šæ•¸
            r'\d+å€‹ç•™è¨€',  # ç•™è¨€æ•¸
            
            # æ™‚é–“æ¨™è¨˜
            r'\d{4}[-/]\d{1,2}[-/]\d{1,2}',
            r'\d{1,2}[-/]\d{1,2}[-/]\d{4}',
            r'\d{1,2}æœˆ\d{1,2}æ—¥',
            r'\d{1,2}:\d{2}',
            
            # å…¶ä»–æ¨™è¨˜
            r'å®˜æ–¹', r'å”¯ä¸€', r'é »é“', r'Official',
            r'è¨‚é–±', r'æŒ‰è®š', r'åˆ†äº«', r'ç•™è¨€',
            r'è§€çœ‹æ¬¡æ•¸', r'è®šæ•¸', r'ç•™è¨€æ•¸',
            r'æ–°å½±ç‰‡', r'æœ€æ–°', r'ç†±é–€', r'æ¨è–¦',
        ]
        
        for pattern in patterns:
            title = re.sub(pattern, '', title, flags=re.IGNORECASE)
        
        return title
    
    def _normalize_youtube_title(self, title: str) -> str:
        """æ¨™æº–åŒ– YouTube æ¨™é¡Œæ ¼å¼"""
        # ç§»é™¤å¤šé¤˜ç©ºç™½
        title = re.sub(r'\s+', ' ', title)
        
        # ç§»é™¤é–‹é ­çš„æ¨™é»ç¬¦è™Ÿ
        title = re.sub(r'^[^\w\u4e00-\u9fff]+', '', title)
        
        # ç§»é™¤çµå°¾çš„æ¨™é»ç¬¦è™Ÿ
        title = re.sub(r'[^\w\u4e00-\u9fff]+$', '', title)
        
        return title.strip()
    
    def _clean_author(self, author: str) -> str:
        """æ¸…ç†ä½œè€…æ¬„ä½"""
        if not author:
            return ""
        
        rules = self.config["author_clean_rules"]
        
        # ç§»é™¤ç‰¹æ®Šç¬¦è™Ÿå’Œæ¨™è¨˜
        if rules.get("remove_special_symbols"):
            author = self._remove_emoji_and_symbols(author)
        
        # ç§»é™¤å¤šé¤˜çš„æ¨™è¨˜
        if rules.get("remove_official_tags"):
            patterns = [
                r'ï¼ˆOfficialå®˜æ–¹å”¯ä¸€é »é“ï¼‰',
                r'\(Officialå®˜æ–¹å”¯ä¸€é »é“\)',
                r'ã€Officialå®˜æ–¹å”¯ä¸€é »é“ã€‘',
                r'\[Officialå®˜æ–¹å”¯ä¸€é »é“\]',
                r'Officialå®˜æ–¹å”¯ä¸€é »é“',
                r'å®˜æ–¹å”¯ä¸€é »é“',
                r'å®˜æ–¹é »é“',
                r'å”¯ä¸€é »é“',
                r'ï¼ˆOfficialï¼‰',
                r'\(Official\)',
                r'ã€Officialã€‘',
                r'\[Official\]',
                r'Official',
            ]
            
            for pattern in patterns:
                author = re.sub(pattern, '', author, flags=re.IGNORECASE)
        
        return author.strip()
    
    def get_config(self) -> Dict[str, Any]:
        """å–å¾—ç•¶å‰é…ç½®"""
        return self.config.copy()
    
    def update_config(self, new_config: Dict[str, Any]):
        """æ›´æ–°é…ç½®"""
        self.config = self._merge_config(self.config, new_config)
    
    def add_custom_field(self, field_name: str, field_config: Dict[str, Any]):
        """æ·»åŠ è‡ªå®šç¾©æ¬„ä½"""
        self.config["fields_to_clean"][field_name] = field_config
    
    def remove_field(self, field_name: str):
        """ç§»é™¤æ¬„ä½"""
        if field_name in self.config["fields_to_clean"]:
            del self.config["fields_to_clean"][field_name]
    
    def batch_clean_documents(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ‰¹æ¬¡æ¸…ç† YouTube æ–‡æª”
        
        Args:
            documents: æ–‡æª”åˆ—è¡¨
            
        Returns:
            æ¸…ç†å¾Œçš„æ–‡æª”åˆ—è¡¨
        """
        cleaned_docs = []
        
        for i, doc in enumerate(documents):
            try:
                cleaned_doc = self.clean(doc)
                cleaned_docs.append(cleaned_doc)
                
                if (i + 1) % 100 == 0:
                    self.logger.info(f"å·²æ¸…ç† {i + 1}/{len(documents)} å€‹ YouTube æ–‡æª”")
                    
            except Exception as e:
                self.logger.error(f"æ¸…ç†ç¬¬ {i + 1} å€‹ YouTube æ–‡æª”å¤±æ•—: {e}")
                # ä¿ç•™åŸå§‹æ–‡æª”ï¼Œä¸æ·»åŠ æ¸…ç†ç‹€æ…‹è³‡è¨Š
                cleaned_docs.append(doc)
        
        return cleaned_docs
    
    def clean_youtube_collection(self, collection_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ¸…ç† YouTube collection è³‡æ–™"""
        try:
            self.logger.info("é–‹å§‹æ¸…ç† YouTube collection è³‡æ–™")
            
            # æ‰¹æ¬¡æ¸…ç†
            cleaned_docs = self.batch_clean_documents(collection_data)
            
            # åªè¿”å›æ¸…ç†å¾Œçš„æ–‡æª”åˆ—è¡¨
            result = {
                "cleaned_documents": cleaned_docs
            }
            
            self.logger.info(f"YouTube collection æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {len(cleaned_docs)} å€‹æ–‡æª”")
            return result
            
        except Exception as e:
            self.logger.error(f"æ¸…ç† YouTube collection å¤±æ•—: {e}")
            return {
                "status": "failed",
                "error": str(e)
            } 