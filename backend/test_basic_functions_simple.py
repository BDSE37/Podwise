#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆåŸºæœ¬åŠŸèƒ½æ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ–‡æœ¬æ¸…ç†å’Œæ¨™ç±¤æå–åŠŸèƒ½ï¼ˆä¸ä¾è³´ emoji å¥—ä»¶ï¼‰
"""

import re
from typing import List, Dict, Any
import pandas as pd
from pathlib import Path


class TextCleaner:
    """æ–‡æœ¬æ¸…ç†å™¨"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤è¡¨æƒ…ç¬¦è™Ÿå’Œç‰¹æ®Šå­—å…ƒ
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†å¾Œçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿï¼ˆä½¿ç”¨ Unicode ç¯„åœï¼‰
        text = re.sub(r'[\U0001F600-\U0001F64F]', '', text)  # è¡¨æƒ…ç¬¦è™Ÿ
        text = re.sub(r'[\U0001F300-\U0001F5FF]', '', text)  # é›œé …ç¬¦è™Ÿ
        text = re.sub(r'[\U0001F680-\U0001F6FF]', '', text)  # äº¤é€šé‹è¼¸
        text = re.sub(r'[\U0001F1E0-\U0001F1FF]', '', text)  # åœ‹æ——
        text = re.sub(r'[\U00002600-\U000027BF]', '', text)  # é›œé …ç¬¦è™Ÿ
        text = re.sub(r'[\U0001F900-\U0001F9FF]', '', text)  # è£œå……ç¬¦è™Ÿ
        
        # ç§»é™¤é¡æ–‡å­—
        text = re.sub(r'[^\u4e00-\u9fff\u3400-\u4dbf\w\s.,!?;:()\[\]{}"\'-]', '', text)
        
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤é–‹é ­å’Œçµå°¾çš„ç©ºç™½
        text = text.strip()
        
        return text
    
    @staticmethod
    def clean_title(title: str) -> str:
        """
        æ¸…ç†æ¨™é¡Œï¼Œç§»é™¤è¡¨æƒ…ç¬¦è™Ÿå’Œç‰¹æ®Šå­—å…ƒ
        
        Args:
            title: åŸå§‹æ¨™é¡Œ
            
        Returns:
            æ¸…ç†å¾Œçš„æ¨™é¡Œ
        """
        if not title:
            return ""
        
        # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿ
        title = re.sub(r'[\U0001F600-\U0001F64F]', '', title)
        title = re.sub(r'[\U0001F300-\U0001F5FF]', '', title)
        title = re.sub(r'[\U0001F680-\U0001F6FF]', '', title)
        title = re.sub(r'[\U0001F1E0-\U0001F1FF]', '', title)
        title = re.sub(r'[\U00002600-\U000027BF]', '', title)
        title = re.sub(r'[\U0001F900-\U0001F9FF]', '', title)
        
        # ç§»é™¤ç‰¹æ®Šå­—å…ƒï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•¸å­—å’ŒåŸºæœ¬æ¨™é»
        title = re.sub(r'[^\u4e00-\u9fff\u3400-\u4dbf\w\s.,!?;:()\[\]{}"\'-]', '', title)
        
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½
        title = re.sub(r'\s+', ' ', title)
        
        # ç§»é™¤é–‹é ­å’Œçµå°¾çš„ç©ºç™½
        title = title.strip()
        
        return title


class SimpleTagProcessor:
    """ç°¡å–®æ¨™ç±¤è™•ç†å™¨"""
    
    def __init__(self, tag_csv_path: str = "TAG_info.csv"):
        self.tag_csv_path = Path(tag_csv_path)
        self.tag_mappings: Dict[str, str] = {}
        self.keyword_to_tags: Dict[str, List[str]] = {}
        self._load_tags()
    
    def _load_tags(self):
        """è¼‰å…¥æ¨™ç±¤è³‡æ–™"""
        try:
            if not self.tag_csv_path.exists():
                print(f"æ¨™ç±¤æª”æ¡ˆä¸å­˜åœ¨: {self.tag_csv_path}")
                self._create_default_tags()
                return
            
            # è®€å– CSV æª”æ¡ˆ
            df = pd.read_csv(self.tag_csv_path)
            print(f"æˆåŠŸè¼‰å…¥æ¨™ç±¤æª”æ¡ˆ: {self.tag_csv_path}")
            print(f"æ¨™ç±¤æª”æ¡ˆæ¬„ä½: {list(df.columns)}")
            
            # è™•ç†æ¯å€‹é¡åˆ¥
            for _, row in df.iterrows():
                main_category = row.get("ä¸»è¦é¡åˆ¥", "")
                sub_category = row.get("å­é¡åˆ¥", "")
                tags_str = row.get("æ¨™ç±¤", "")
                weight = row.get("æ¬Šé‡", 1.0)
                
                if tags_str and isinstance(tags_str, str):
                    # åˆ†å‰²æ¨™ç±¤
                    tags = [tag.strip() for tag in tags_str.split(",") if tag.strip()]
                    
                    # å»ºç«‹é—œéµå­—æ˜ å°„
                    for tag in tags:
                        self.tag_mappings[tag] = main_category
                        self.keyword_to_tags[tag.lower()] = tags
                        
                        # ä¹Ÿå°‡ä¸»è¦é¡åˆ¥å’Œå­é¡åˆ¥åŠ å…¥æ˜ å°„
                        if main_category:
                            self.keyword_to_tags[main_category.lower()] = tags
                        if sub_category:
                            self.keyword_to_tags[sub_category.lower()] = tags
            
            print(f"è¼‰å…¥çš„æ¨™ç±¤æ˜ å°„: {self.tag_mappings}")
            
        except Exception as e:
            print(f"è¼‰å…¥æ¨™ç±¤æª”æ¡ˆå¤±æ•—: {e}")
            self._create_default_tags()
    
    def _create_default_tags(self):
        """å»ºç«‹é è¨­æ¨™ç±¤"""
        default_tags = {
            "ç§‘æŠ€": ["AI", "äººå·¥æ™ºæ…§", "ç§‘æŠ€", "æŠ€è¡“"],
            "å•†æ¥­": ["å•†æ¥­", "ä¼æ¥­", "æŠ•è³‡", "ç†è²¡"],
            "æ•™è‚²": ["æ•™è‚²", "å­¸ç¿’", "çŸ¥è­˜"],
            "å¥åº·": ["å¥åº·", "é‹å‹•", "é£²é£Ÿ"],
            "å¨›æ¨‚": ["å¨›æ¨‚", "éŸ³æ¨‚", "é›»å½±"]
        }
        
        for category, tags in default_tags.items():
            for tag in tags:
                self.tag_mappings[tag] = category
                self.keyword_to_tags[tag.lower()] = tags
    
    def extract_tags(self, chunk_text: str) -> List[str]:
        """
        æå–æ¨™ç±¤
        
        Args:
            chunk_text: æ–‡æœ¬å¡Š
            
        Returns:
            æ¨™ç±¤åˆ—è¡¨
        """
        try:
            tags = []
            chunk_lower = chunk_text.lower()
            
            # ç¬¬ä¸€éšæ®µï¼šåŸºæ–¼ TAG_info.csv çš„æ¨™ç±¤åŒ¹é…
            for keyword, tag_list in self.keyword_to_tags.items():
                if keyword in chunk_lower:
                    tags.extend(tag_list)
            
            # ç¬¬äºŒéšæ®µï¼šå¦‚æœæ²’æœ‰æ¨™ç±¤ï¼Œä½¿ç”¨æ™ºèƒ½æ¨™ç±¤ç³»çµ±
            if not tags:
                tags = self._intelligent_tag_extraction(chunk_text)
            
            # ç¬¬ä¸‰éšæ®µï¼šæœ€çµ‚å‚™æ´
            if not tags:
                tags = self._fallback_tag_extraction(chunk_text)
            
            # é©—è­‰å’Œæ¸…ç†æ¨™ç±¤
            tags = self._validate_and_clean_tags(tags, chunk_text)
            
            return tags[:3]  # é™åˆ¶æœ€å¤š 3 å€‹æ¨™ç±¤
            
        except Exception as e:
            print(f"æå–æ¨™ç±¤å¤±æ•—: {e}")
            return self._fallback_tag_extraction(chunk_text)
    
    def _intelligent_tag_extraction(self, chunk_text: str) -> List[str]:
        """æ™ºèƒ½æ¨™ç±¤æå–"""
        tags = []
        chunk_lower = chunk_text.lower()
        
        # é—œéµå­—åŒ¹é…
        keyword_mapping = {
            'ai': ['AI', 'äººå·¥æ™ºæ…§'],
            'ç§‘æŠ€': ['ç§‘æŠ€', 'æŠ€è¡“'],
            'å•†æ¥­': ['å•†æ¥­', 'ä¼æ¥­'],
            'æ•™è‚²': ['æ•™è‚²', 'å­¸ç¿’'],
            'å‰µæ¥­': ['å‰µæ¥­', 'æ–°å‰µ'],
            'ç®¡ç†': ['ç®¡ç†', 'é ˜å°'],
            'æŠ•è³‡': ['æŠ•è³‡', 'ç†è²¡'],
            'å¥åº·': ['å¥åº·', 'é‹å‹•'],
            'å¨›æ¨‚': ['å¨›æ¨‚', 'éŸ³æ¨‚'],
            'æ”¿æ²»': ['æ”¿æ²»', 'æ”¿ç­–']
        }
        
        for keyword, tag_list in keyword_mapping.items():
            if keyword in chunk_lower:
                tags.extend(tag_list)
        
        return list(set(tags))  # å»é‡
    
    def _fallback_tag_extraction(self, chunk_text: str) -> List[str]:
        """å‚™æ´æ¨™ç±¤æå–"""
        # åŸºæ–¼æ–‡æœ¬é•·åº¦å’Œå…§å®¹çš„åŸºæœ¬æ¨™ç±¤
        if len(chunk_text) > 500:
            return ['é•·æ–‡æœ¬', 'è©³ç´°å…§å®¹']
        elif len(chunk_text) > 200:
            return ['ä¸­ç­‰æ–‡æœ¬', 'ä¸€èˆ¬å…§å®¹']
        else:
            return ['çŸ­æ–‡æœ¬', 'ç°¡è¦å…§å®¹']
    
    def _validate_and_clean_tags(self, tags: List[str], chunk_text: str) -> List[str]:
        """é©—è­‰å’Œæ¸…ç†æ¨™ç±¤"""
        valid_tags = []
        
        for tag in tags:
            if tag and len(tag.strip()) > 0:
                # æ¸…ç†æ¨™ç±¤
                clean_tag = re.sub(r'[^\u4e00-\u9fff\u3400-\u4dbf\w\s]', '', tag.strip())
                if clean_tag and len(clean_tag) <= 20:  # é™åˆ¶æ¨™ç±¤é•·åº¦
                    valid_tags.append(clean_tag)
        
        return valid_tags


def test_text_cleaner():
    """æ¸¬è©¦æ–‡æœ¬æ¸…ç†å™¨"""
    print("=== æ¸¬è©¦æ–‡æœ¬æ¸…ç†å™¨ ===")
    
    cleaner = TextCleaner()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        "é€™æ˜¯ä¸€å€‹æ¸¬è©¦æ–‡æœ¬ ğŸ˜Š åŒ…å«è¡¨æƒ…ç¬¦è™Ÿ",
        "Hello World! ğŸŒ æ··åˆä¸­è‹±æ–‡",
        "è‚¡ç™Œ EP123 ğŸ“ˆ æŠ•è³‡ç†è²¡ ğŸ’°",
        "ç§‘æŠ€æ–°è ğŸ”¥ AI äººå·¥æ™ºæ…§ ğŸ¤–",
        "æ­£å¸¸æ–‡æœ¬ï¼Œæ²’æœ‰ç‰¹æ®Šå­—å…ƒ",
        "åŒ…å«é¡æ–‡å­— (ï½¡â—•â€¿â—•ï½¡) çš„æ–‡æœ¬",
        "å¤šå€‹è¡¨æƒ…ç¬¦è™Ÿ ğŸ‰ğŸŠğŸˆ æ¸¬è©¦",
        ""
    ]
    
    for i, text in enumerate(test_cases):
        cleaned = cleaner.clean_text(text)
        print(f"åŸå§‹: {text}")
        print(f"æ¸…ç†å¾Œ: {cleaned}")
        print(f"é•·åº¦è®ŠåŒ–: {len(text)} -> {len(cleaned)}")
        print("-" * 50)
    
    # æ¸¬è©¦æ¨™é¡Œæ¸…ç†
    print("\n=== æ¸¬è©¦æ¨™é¡Œæ¸…ç† ===")
    title_test_cases = [
        "EP001_è‚¡ç™Œ ğŸ“ˆ æŠ•è³‡ç†è²¡",
        "ç§‘æŠ€æ–°è ğŸ”¥ AI äººå·¥æ™ºæ…§",
        "æ­£å¸¸æ¨™é¡Œï¼Œæ²’æœ‰ç‰¹æ®Šå­—å…ƒ",
        "åŒ…å«è¡¨æƒ…ç¬¦è™Ÿçš„æ¨™é¡Œ ğŸ‰"
    ]
    
    for title in title_test_cases:
        cleaned_title = cleaner.clean_title(title)
        print(f"åŸå§‹æ¨™é¡Œ: {title}")
        print(f"æ¸…ç†å¾Œæ¨™é¡Œ: {cleaned_title}")
        print("-" * 30)


def test_tag_processor():
    """æ¸¬è©¦æ¨™ç±¤è™•ç†å™¨"""
    print("\n=== æ¸¬è©¦æ¨™ç±¤è™•ç†å™¨ ===")
    
    processor = SimpleTagProcessor("TAG_info.csv")
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        "äººå·¥æ™ºæ…§æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œæ©Ÿå™¨å­¸ç¿’å’Œæ·±åº¦å­¸ç¿’æˆç‚ºç†±é–€è©±é¡Œã€‚",
        "æŠ•è³‡ç†è²¡æ˜¯ç¾ä»£äººå¿…é ˆå­¸ç¿’çš„æŠ€èƒ½ï¼Œè‚¡ç¥¨å’ŒåŸºé‡‘æŠ•è³‡éœ€è¦è¬¹æ…ã€‚",
        "å‰µæ¥­éœ€è¦å‰µæ–°æ€ç¶­å’ŒåŸ·è¡ŒåŠ›ï¼Œæ–°å‰µå…¬å¸é¢è‡¨è¨±å¤šæŒ‘æˆ°ã€‚",
        "å¥åº·ç”Ÿæ´»åŒ…æ‹¬é‹å‹•å’Œé£²é£Ÿï¼Œå°èº«é«”å¥åº·è‡³é—œé‡è¦ã€‚",
        "é€™æ˜¯ä¸€æ®µæ™®é€šçš„æ–‡æœ¬ï¼Œæ²’æœ‰æ˜é¡¯çš„é—œéµå­—ã€‚",
        "ç§‘æŠ€æ–°èå ±å°æœ€æ–°çš„æŠ€è¡“ç™¼å±•ï¼ŒåŒ…æ‹¬AIã€å€å¡Šéˆç­‰é ˜åŸŸã€‚",
        "æ•™è‚²å­¸ç¿’æ˜¯çµ‚èº«éç¨‹ï¼ŒçŸ¥è­˜å’ŒæŠ€èƒ½çš„æå‡å°å€‹äººç™¼å±•å¾ˆé‡è¦ã€‚",
        "å¨›æ¨‚éŸ³æ¨‚è®“äººæ”¾é¬†å¿ƒæƒ…ï¼Œé›»å½±å’ŒéŠæˆ²ä¹Ÿæ˜¯é‡è¦çš„ä¼‘é–’æ´»å‹•ã€‚"
    ]
    
    for i, text in enumerate(test_cases):
        print(f"\næ¸¬è©¦æ¡ˆä¾‹ {i+1}: {text[:50]}...")
        tags = processor.extract_tags(text)
        print(f"æå–çš„æ¨™ç±¤: {tags}")


def test_text_chunking():
    """æ¸¬è©¦æ–‡æœ¬åˆ‡åˆ†"""
    print("\n=== æ¸¬è©¦æ–‡æœ¬åˆ‡åˆ† ===")
    
    def split_text_into_chunks(text: str, max_chunk_size: int = 500) -> List[str]:
        """å°‡æ–‡æœ¬åˆ‡åˆ†ç‚º chunks"""
        if not text:
            return []
        
        # æŒ‰å¥å­åˆ‡åˆ†
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # å¦‚æœç•¶å‰ chunk åŠ ä¸Šæ–°å¥å­è¶…éæœ€å¤§é•·åº¦ï¼Œä¿å­˜ç•¶å‰ chunk
            if len(current_chunk) + len(sentence) > max_chunk_size:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence
            else:
                current_chunk += sentence + "ã€‚"
        
        # æ·»åŠ æœ€å¾Œä¸€å€‹ chunk
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    # æ¸¬è©¦æ–‡æœ¬
    test_text = """
    é€™æ˜¯ç¬¬ä¸€æ®µæ–‡æœ¬ã€‚å®ƒåŒ…å«äº†ä¸€äº›åŸºæœ¬çš„å…§å®¹ã€‚æˆ‘å€‘éœ€è¦æ¸¬è©¦æ–‡æœ¬åˆ‡åˆ†åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
    
    é€™æ˜¯ç¬¬äºŒæ®µæ–‡æœ¬ã€‚å®ƒè¨è«–äº†äººå·¥æ™ºæ…§å’Œæ©Ÿå™¨å­¸ç¿’çš„ç›¸é—œè©±é¡Œã€‚AIæŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ã€‚
    
    é€™æ˜¯ç¬¬ä¸‰æ®µæ–‡æœ¬ã€‚å®ƒè«‡è«–äº†æŠ•è³‡ç†è²¡çš„é‡è¦æ€§ã€‚è‚¡ç¥¨å¸‚å ´å……æ»¿äº†æ©Ÿæœƒå’Œé¢¨éšªã€‚
    
    é€™æ˜¯ç¬¬å››æ®µæ–‡æœ¬ã€‚å®ƒä»‹ç´¹äº†å‰µæ¥­çš„åŸºæœ¬æ¦‚å¿µã€‚æ–°å‰µå…¬å¸éœ€è¦å‰µæ–°æ€ç¶­å’ŒåŸ·è¡ŒåŠ›ã€‚
    
    é€™æ˜¯ç¬¬äº”æ®µæ–‡æœ¬ã€‚å®ƒè¨è«–äº†å¥åº·ç”Ÿæ´»çš„é‡è¦æ€§ã€‚é‹å‹•å’Œé£²é£Ÿå°èº«é«”å¥åº·è‡³é—œé‡è¦ã€‚
    """
    
    chunks = split_text_into_chunks(test_text)
    
    print(f"åŸå§‹æ–‡æœ¬é•·åº¦: {len(test_text)}")
    print(f"åˆ‡åˆ†å¾Œ chunks æ•¸é‡: {len(chunks)}")
    
    for i, chunk in enumerate(chunks):
        print(f"\nChunk {i+1} (é•·åº¦: {len(chunk)}):")
        print(f"å…§å®¹: {chunk[:100]}{'...' if len(chunk) > 100 else ''}")


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("é–‹å§‹åŸ·è¡Œç°¡åŒ–ç‰ˆåŸºæœ¬åŠŸèƒ½æ¸¬è©¦")
    print("=" * 60)
    
    # åŸ·è¡Œå„ç¨®æ¸¬è©¦
    test_text_cleaner()
    test_tag_processor()
    test_text_chunking()
    
    print("\n" + "=" * 60)
    print("æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")


if __name__ == "__main__":
    main() 