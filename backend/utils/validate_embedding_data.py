#!/usr/bin/env python3
"""
é©—è­‰ embedding è³‡æ–™å®Œæ•´æ€§è…³æœ¬
ç¢ºä¿æ‰€æœ‰å¿…è¦æ¬„ä½éƒ½æ­£ç¢ºå¾ž PostgreSQL è£œè¶³
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any
import psycopg2
from datetime import datetime

class EmbeddingDataValidator:
    """Embedding è³‡æ–™é©—è­‰å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é©—è­‰å™¨"""
        self.pg_config = {
            'host': os.getenv('POSTGRES_HOST', '10.233.50.117'),
            'port': os.getenv('POSTGRES_PORT', '5432'),
            'database': os.getenv('POSTGRES_DB', 'podcast'),
            'user': os.getenv('POSTGRES_USER', 'bdse37'),
            'password': os.getenv('POSTGRES_PASSWORD', '111111')
        }
        
        # å¿…è¦æ¬„ä½å®šç¾©
        self.required_fields = {
            'chunk_id': {'type': 'str', 'max_length': 64, 'required': True},
            'chunk_index': {'type': 'int', 'required': True},
            'episode_id': {'type': 'int', 'required': True},
            'podcast_id': {'type': 'int', 'required': True},
            'podcast_name': {'type': 'str', 'max_length': 255, 'required': True},
            'author': {'type': 'str', 'max_length': 255, 'required': True},
            'category': {'type': 'str', 'max_length': 64, 'required': True},
            'episode_title': {'type': 'str', 'max_length': 255, 'required': True},
            'duration': {'type': 'str', 'max_length': 255, 'required': True},
            'published_date': {'type': 'str', 'max_length': 64, 'required': True},
            'apple_rating': {'type': 'int', 'required': True},
            'chunk_text': {'type': 'str', 'max_length': 1024, 'required': True},
            'embedding': {'type': 'list', 'required': True},
            'language': {'type': 'str', 'max_length': 16, 'required': True},
            'created_at': {'type': 'str', 'required': True},
            'source_model': {'type': 'str', 'max_length': 64, 'required': True},
            'tags': {'type': 'str', 'max_length': 1024, 'required': True}
        }
    
    def validate_single_chunk(self, chunk: Dict) -> Dict[str, Any]:
        """é©—è­‰å–®å€‹ chunk çš„è³‡æ–™å®Œæ•´æ€§"""
        validation_result = {
            'valid': True,
            'missing_fields': [],
            'invalid_fields': [],
            'warnings': []
        }
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        for field_name, field_config in self.required_fields.items():
            if field_name not in chunk:
                validation_result['missing_fields'].append(field_name)
                validation_result['valid'] = False
                continue
            
            value = chunk[field_name]
            
            # æª¢æŸ¥æ¬„ä½é¡žåž‹
            if field_config['type'] == 'int':
                if not isinstance(value, int):
                    validation_result['invalid_fields'].append(f"{field_name}: æ‡‰ç‚º intï¼Œå¯¦éš›ç‚º {type(value)}")
                    validation_result['valid'] = False
            elif field_config['type'] == 'str':
                if not isinstance(value, str):
                    validation_result['invalid_fields'].append(f"{field_name}: æ‡‰ç‚º strï¼Œå¯¦éš›ç‚º {type(value)}")
                    validation_result['valid'] = False
                elif 'max_length' in field_config and len(value) > field_config['max_length']:
                    validation_result['warnings'].append(f"{field_name}: é•·åº¦ {len(value)} è¶…éŽé™åˆ¶ {field_config['max_length']}")
            elif field_config['type'] == 'list':
                if not isinstance(value, list):
                    validation_result['invalid_fields'].append(f"{field_name}: æ‡‰ç‚º listï¼Œå¯¦éš›ç‚º {type(value)}")
                    validation_result['valid'] = False
                elif field_name == 'embedding' and len(value) != 1024:
                    validation_result['warnings'].append(f"{field_name}: embedding ç¶­åº¦ {len(value)} ä¸æ˜¯ 1024")
        
        # æª¢æŸ¥ PostgreSQL è³‡æ–™å®Œæ•´æ€§
        if chunk.get('episode_id', 0) > 0:
            # æœ‰ episode_idï¼Œæª¢æŸ¥æ˜¯å¦ç‚ºé è¨­å€¼
            if chunk.get('podcast_name') == 'æœªçŸ¥æ’­å®¢':
                validation_result['warnings'].append("æœ‰ episode_id ä½† podcast_name ç‚ºé è¨­å€¼")
            if chunk.get('author') == 'æœªçŸ¥ä½œè€…':
                validation_result['warnings'].append("æœ‰ episode_id ä½† author ç‚ºé è¨­å€¼")
            if chunk.get('duration') == 'æœªçŸ¥æ™‚é•·':
                validation_result['warnings'].append("æœ‰ episode_id ä½† duration ç‚ºé è¨­å€¼")
        else:
            # æ²’æœ‰ episode_idï¼Œæª¢æŸ¥æ˜¯å¦ç‚ºé è¨­å€¼
            if chunk.get('podcast_name') == 'æœªçŸ¥æ’­å®¢':
                validation_result['warnings'].append("æ²’æœ‰ episode_id ä¸” podcast_name ç‚ºé è¨­å€¼")
            if chunk.get('author') == 'æœªçŸ¥ä½œè€…':
                validation_result['warnings'].append("æ²’æœ‰ episode_id ä¸” author ç‚ºé è¨­å€¼")
            if chunk.get('duration') == 'æœªçŸ¥æ™‚é•·':
                validation_result['warnings'].append("æ²’æœ‰ episode_id ä¸” duration ç‚ºé è¨­å€¼")
        
        return validation_result
    
    def validate_file(self, file_path: Path) -> Dict[str, Any]:
        """é©—è­‰å–®å€‹æª”æ¡ˆ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            chunks = data.get('chunks', [])
            if not chunks:
                return {
                    'file': str(file_path),
                    'valid': False,
                    'error': 'æ²’æœ‰ chunks è³‡æ–™'
                }
            
            validation_results = []
            for i, chunk in enumerate(chunks):
                chunk_validation = self.validate_single_chunk(chunk)
                chunk_validation['chunk_index'] = i
                validation_results.append(chunk_validation)
            
            # çµ±è¨ˆçµæžœ
            valid_chunks = sum(1 for r in validation_results if r['valid'])
            total_chunks = len(validation_results)
            
            return {
                'file': str(file_path),
                'valid': valid_chunks == total_chunks,
                'total_chunks': total_chunks,
                'valid_chunks': valid_chunks,
                'invalid_chunks': total_chunks - valid_chunks,
                'chunk_validations': validation_results
            }
            
        except Exception as e:
            return {
                'file': str(file_path),
                'valid': False,
                'error': str(e)
            }
    
    def validate_all_files(self) -> Dict[str, Any]:
        """é©—è­‰æ‰€æœ‰æª”æ¡ˆ"""
        stage4_path = Path("backend/vector_pipeline/data/stage4_embedding_prep")
        
        if not stage4_path.exists():
            return {
                'valid': False,
                'error': f'ç›®éŒ„ä¸å­˜åœ¨: {stage4_path}'
            }
        
        all_files = list(stage4_path.rglob("*.json"))
        if not all_files:
            return {
                'valid': False,
                'error': 'æ²’æœ‰æ‰¾åˆ°ä»»ä½•æª”æ¡ˆ'
            }
        
        print(f"ðŸ” é–‹å§‹é©—è­‰ {len(all_files)} å€‹æª”æ¡ˆ...")
        
        validation_results = []
        for i, file_path in enumerate(all_files):
            print(f"é©—è­‰é€²åº¦: {i+1}/{len(all_files)} - {file_path.name}")
            result = self.validate_file(file_path)
            validation_results.append(result)
        
        # çµ±è¨ˆç¸½çµæžœ
        valid_files = sum(1 for r in validation_results if r['valid'])
        total_files = len(validation_results)
        total_chunks = sum(r.get('total_chunks', 0) for r in validation_results)
        valid_chunks = sum(r.get('valid_chunks', 0) for r in validation_results)
        
        return {
            'timestamp': datetime.now().isoformat(),
            'total_files': total_files,
            'valid_files': valid_files,
            'invalid_files': total_files - valid_files,
            'total_chunks': total_chunks,
            'valid_chunks': valid_chunks,
            'invalid_chunks': total_chunks - valid_chunks,
            'validation_results': validation_results,
            'summary': {
                'file_success_rate': valid_files / total_files * 100 if total_files > 0 else 0,
                'chunk_success_rate': valid_chunks / total_chunks * 100 if total_chunks > 0 else 0
            }
        }
    
    def print_validation_report(self, report: Dict[str, Any]):
        """åˆ—å°é©—è­‰å ±å‘Š"""
        print("\n" + "="*80)
        print("ðŸ“Š Embedding è³‡æ–™å®Œæ•´æ€§é©—è­‰å ±å‘Š")
        print("="*80)
        
        if 'error' in report:
            print(f"âŒ é©—è­‰å¤±æ•—: {report['error']}")
            return
        
        print(f"ðŸ“ æª”æ¡ˆçµ±è¨ˆ:")
        print(f"   ç¸½æª”æ¡ˆæ•¸: {report['total_files']}")
        print(f"   æœ‰æ•ˆæª”æ¡ˆ: {report['valid_files']}")
        print(f"   ç„¡æ•ˆæª”æ¡ˆ: {report['invalid_files']}")
        print(f"   æª”æ¡ˆæˆåŠŸçŽ‡: {report['summary']['file_success_rate']:.1f}%")
        
        print(f"\nðŸ§© Chunk çµ±è¨ˆ:")
        print(f"   ç¸½ Chunk æ•¸: {report['total_chunks']}")
        print(f"   æœ‰æ•ˆ Chunk: {report['valid_chunks']}")
        print(f"   ç„¡æ•ˆ Chunk: {report['invalid_chunks']}")
        print(f"   Chunk æˆåŠŸçŽ‡: {report['summary']['chunk_success_rate']:.1f}%")
        
        # é¡¯ç¤ºå•é¡Œæª”æ¡ˆ
        invalid_files = [r for r in report['validation_results'] if not r['valid']]
        if invalid_files:
            print(f"\nâŒ å•é¡Œæª”æ¡ˆæ¸…å–®:")
            for file_result in invalid_files[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                print(f"   {file_result['file']}: {file_result.get('error', 'è³‡æ–™ä¸å®Œæ•´')}")
            if len(invalid_files) > 10:
                print(f"   ... é‚„æœ‰ {len(invalid_files) - 10} å€‹å•é¡Œæª”æ¡ˆ")
        
        # é¡¯ç¤ºè­¦å‘Š
        warnings = []
        for file_result in report['validation_results']:
            for chunk_validation in file_result.get('chunk_validations', []):
                warnings.extend(chunk_validation.get('warnings', []))
        
        if warnings:
            print(f"\nâš ï¸ è­¦å‘Šæ¸…å–® (å‰10å€‹):")
            for warning in warnings[:10]:
                print(f"   {warning}")
            if len(warnings) > 10:
                print(f"   ... é‚„æœ‰ {len(warnings) - 10} å€‹è­¦å‘Š")
        
        print("\n" + "="*80)

def main():
    """ä¸»å‡½æ•¸"""
    validator = EmbeddingDataValidator()
    report = validator.validate_all_files()
    validator.print_validation_report(report)

if __name__ == "__main__":
    main() 