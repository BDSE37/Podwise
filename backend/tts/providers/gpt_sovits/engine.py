"""SoVITSInferenceEngine
=======================
å°‡å®˜æ–¹ `inference_webui.py` ç²¾ç°¡ç‚º**é›¢ç·šæ¨è«–å¼•æ“**ã€‚
åƒ…ä¿ç•™ï¼š
  â€¢ æ¨¡å‹åˆå§‹åŒ– (`_load_models`)  
  â€¢ èªéŸ³åˆæˆ (`synthesize`)
ä¾› Provider / CLI / å…¶ä»–æœå‹™å‘¼å«ã€‚

ä¾è³´ï¼š
```bash
pip install torch soundfile librosa transformers peft GPT-SoVITS
```
"""
from __future__ import annotations

import json
import os
from pathlib import Path
from typing import Tuple

import numpy as np
import soundfile as sf
import torch
import os
import sys
import pathlib

# æ‰¾åˆ° engine.py æ‰€åœ¨çš„çœŸæ­£è·¯å¾‘ï¼ˆä¾‹å¦‚ backend/tts/providers/gpt_sovitsï¼‰
CURRENT_FILE = pathlib.Path(__file__).resolve()

# å¾€ä¸Šæ‰¾ç›´åˆ°é‡åˆ° models/gpt_sovits ç‚ºæ­¢
def find_gpt_sovits_dir(start: pathlib.Path) -> pathlib.Path:
    for parent in start.parents:
        gpt_dir = parent / "models" / "gpt_sovits"
        if gpt_dir.exists():
            return gpt_dir
    raise FileNotFoundError("âŒ æ‰¾ä¸åˆ° models/gpt_sovits è³‡æ–™å¤¾")

GPT_SOVITS_DIR = find_gpt_sovits_dir(CURRENT_FILE)
sys.path.insert(0, str(GPT_SOVITS_DIR))

# é©—è­‰æ˜¯å¦æˆåŠŸ
print("âœ… GPT_SOVITS_DIR =", GPT_SOVITS_DIR)
print("ğŸ“ å…§å®¹ï¼š", os.listdir(GPT_SOVITS_DIR))

# åŒ¯å…¥
from inference_webui import get_tts_wav



# === CLI ç”¨æ³• ===
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_dir", required=True)
    parser.add_argument("--text", required=True)
    parser.add_argument("--out", required=True)
    args = parser.parse_args()

    wav_data = get_tts_wav(args.text)  # â—ï¸é€™è£¡å¦‚æœé‚„éœ€è¦ config è«‹è£œåƒæ•¸
    with open(args.out, "wb") as f:
        f.write(wav_data)

    print("âœ… éŸ³æª”è¼¸å‡ºå®Œæˆ:", args.out)

# wav_bytes = get_tts_wav(text="Podri TTS æ¸¬è©¦", ...å…¶ä»–åƒæ•¸...)


__all__ = ["SoVITSInferenceEngine"]


class SoVITSInferenceEngine:
    """å°è£ GPTâ€‘SoVITS æ¨è«–æµç¨‹ã€‚"""

    def __init__(self,
                 model_dir: Path | str,
                 device: str | None = None,
                 half: bool = True):
        self.model_dir = Path(model_dir)
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.half = half and self.device == "cuda"

        # --- æ¬Šé‡è·¯å¾‘ ---
        self.cfg_path = self.model_dir / "configs/config.json"
        self.ckpt_path = self.model_dir / "pretrained/model.pth"
        self.ref_wav = self.model_dir / "reference/ref.wav"
        self.ref_txt = self.model_dir / "reference/ref.txt"
        for p in (self.cfg_path, self.ckpt_path, self.ref_wav, self.ref_txt):
            if not p.exists():
                raise FileNotFoundError(f"ç¼ºå°‘æª”æ¡ˆ: {p}")

        # --- æ¨¡å‹åˆå§‹åŒ– ---
        self._load_models()

    # --------------------------------------------------
    def _load_models(self) -> None:
        """è¼‰å…¥ GPT èˆ‡ SoVITS æ¬Šé‡ã€‚"""
        # å¯¦éš› change_weights æœƒæŠŠæ¨¡å‹å­˜åˆ°å…¨åŸŸ
        change_gpt_weights(str(self.ckpt_path))
        # é è¨­èªè¨€é‡è¨­ç‚ºä¸­æ–‡
        for _ in change_sovits_weights(str(self.ckpt_path), "ä¸­æ–‡", "ä¸­æ–‡"):
            pass  # å…¶ç‚º generatorï¼›éœ€å®Œå…¨è¿­ä»£ä»¥å®Œæˆè¼‰å…¥

    # --------------------------------------------------
    def synthesize(self,
                   text: str,
                   text_lang: str = "ä¸­æ–‡",
                   top_p: float = 0.6,
                   temperature: float = 0.6) -> Tuple[int, bytes]:
        """é›¢ç·šèªéŸ³åˆæˆ

        Args:
            text: ç›®æ¨™å¥å­
            text_lang: èªç¨®ï¼ˆä¸­æ–‡/è‹±æ–‡/æ—¥æ–‡â€¦ï¼‰
            top_p, temperature: å–æ¨£åƒæ•¸
        Returns:
            (sr, wav_bytes)
        """
        # å‘¼å«å®˜æ–¹ get_tts_wav (yield generator) å–å¾—æœ€å¾Œçµæœ
        out_iter = get_tts_wav(
            str(self.ref_wav),                # åƒè€ƒéŸ³é »
            self.ref_txt.read_text(),         # åƒè€ƒæ–‡å­—
            text_lang,                        # åƒè€ƒèªè¨€
            text,
            text_lang,
            top_p=top_p,
            temperature=temperature,
        )
        sr, audio_np = list(out_iter)[-1]  # (sr, np.int16)
        wav_bytes = self._numpy_to_bytes(audio_np, sr)
        return sr, wav_bytes

    # --------------------------------------------------
    @staticmethod
    def _numpy_to_bytes(audio: np.ndarray, sr: int) -> bytes:
        """å°‡ numpy int16 è½‰ wav bytesã€‚"""
        import io
        buf = io.BytesIO()
        sf.write(buf, audio, sr, format="WAV", subtype="PCM_16")
        return buf.getvalue()

    # --------------------------------------------------
    # å¯å†æ“´å…… batch_synthesizeã€change_voice ç­‰æ–¹æ³•


# ---- CLI æ¸¬è©¦ ----
if __name__ == "__main__":
    import argparse

    ap = argparse.ArgumentParser(description="SoVITS å¼•æ“æ¸¬è©¦")
    ap.add_argument("--model_dir", default="backend/tts/models/gpt_sovits")
    ap.add_argument("--text", default="å“ˆå›‰ï¼ŒPodri OOP æ¸¬è©¦ï¼")
    ap.add_argument("--out", default="demo_engine.wav")
    args = ap.parse_args()

    eng = SoVITSInferenceEngine(Path(args.model_dir))
    sr, wav_b = eng.synthesize(args.text)
    Path(args.out).write_bytes(wav_b)
    print(f"âœ” å·²è¼¸å‡º {args.out} (sr={sr})")
