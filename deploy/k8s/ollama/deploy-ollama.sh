#!/bin/bash

# Ollama éƒ¨ç½²è…³æœ¬
# éƒ¨ç½² Ollama æœå‹™ä¸¦ä¸‹è¼‰æ‰€éœ€çš„ LLM æ¨¡å‹

set -e

echo "ğŸš€ é–‹å§‹éƒ¨ç½² Ollama æœå‹™..."

# éƒ¨ç½² Ollama åˆ° Kubernetes
echo "ğŸ“¦ éƒ¨ç½² Ollama åˆ° Kubernetes..."
kubectl apply -f deploy/k8s/ollama/ollama-deployment.yaml

# ç­‰å¾… Pod å•Ÿå‹•
echo "â³ ç­‰å¾… Ollama Pod å•Ÿå‹•..."
kubectl wait --for=condition=ready pod -l app=ollama-service -n podwise --timeout=300s

# ç²å– Pod åç¨±
OLLAMA_POD=$(kubectl get pods -n podwise -l app=ollama-service -o jsonpath='{.items[0].metadata.name}')
echo "ğŸ“‹ Ollama Pod: $OLLAMA_POD"

# ç­‰å¾…æœå‹™å®Œå…¨å•Ÿå‹•
echo "â³ ç­‰å¾… Ollama æœå‹™å®Œå…¨å•Ÿå‹•..."
sleep 60

# æª¢æŸ¥æœå‹™ç‹€æ…‹
echo "ğŸ” æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹..."
kubectl exec -n podwise $OLLAMA_POD -- curl -s http://localhost:11434/api/tags

echo "âœ… Ollama æœå‹™éƒ¨ç½²å®Œæˆï¼"

# ä¸‹è¼‰æ¨¡å‹
echo "ğŸ“¥ é–‹å§‹ä¸‹è¼‰ LLM æ¨¡å‹..."
kubectl cp deploy/k8s/ollama/download-models.sh podwise/$OLLAMA_POD:/tmp/download-models.sh
kubectl exec -n podwise $OLLAMA_POD -- chmod +x /tmp/download-models.sh
kubectl exec -n podwise $OLLAMA_POD -- /tmp/download-models.sh

echo "ğŸ‰ Ollama éƒ¨ç½²å’Œæ¨¡å‹ä¸‹è¼‰å®Œæˆï¼"
echo "ğŸ“Š æœå‹™ç«¯é»: http://worker1:31134"
echo "ğŸ“‹ å¯ç”¨æ¨¡å‹:"
kubectl exec -n podwise $OLLAMA_POD -- ollama list 