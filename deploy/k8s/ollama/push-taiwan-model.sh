#!/bin/bash

# æ¨é€å°ç£ç‰ˆæœ¬æ¨¡å‹åˆ° Kubernetes Ollama è…³æœ¬
# å°‡æœ¬åœ°çš„ Qwen2.5-Taiwan-7B-Instruct æ¨¡å‹æ¨é€åˆ° K8s Ollama æœå‹™

set -e

# é¡è‰²å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥èªŒå‡½æ•¸
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æª¢æŸ¥å‰ç½®æ¢ä»¶
check_prerequisites() {
    log_info "æª¢æŸ¥å‰ç½®æ¢ä»¶..."
    
    # æª¢æŸ¥ kubectl
    if ! command -v kubectl &> /dev/null; then
        log_error "kubectl æœªå®‰è£ï¼Œè«‹å…ˆå®‰è£ kubectl"
        exit 1
    fi
    
    # æª¢æŸ¥ Ollama Pod æ˜¯å¦å­˜åœ¨
    if ! kubectl get pods -n podwise -l app=ollama-service &> /dev/null; then
        log_error "Ollama Pod ä¸å­˜åœ¨ï¼Œè«‹å…ˆéƒ¨ç½² Ollama æœå‹™"
        exit 1
    fi
    
    # æª¢æŸ¥æœ¬åœ°æ¨¡å‹ç›®éŒ„
    MODEL_PATH="backend/llm/models/Qwen2.5-Taiwan-7B-Instruct"
    if [ ! -d "$MODEL_PATH" ]; then
        log_error "æœ¬åœ°æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨: $MODEL_PATH"
        exit 1
    fi
    
    log_success "å‰ç½®æ¢ä»¶æª¢æŸ¥é€šé"
}

# ç²å– Ollama Pod åç¨±
get_ollama_pod() {
    log_info "ç²å– Ollama Pod åç¨±..."
    
    OLLAMA_POD=$(kubectl get pods -n podwise -l app=ollama-service -o jsonpath='{.items[0].metadata.name}')
    
    if [ -z "$OLLAMA_POD" ]; then
        log_error "ç„¡æ³•ç²å– Ollama Pod åç¨±"
        exit 1
    fi
    
    log_success "Ollama Pod: $OLLAMA_POD"
    echo "$OLLAMA_POD"
}

# æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹
check_ollama_service() {
    log_info "æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹..."
    
    local pod_name=$1
    
    # ç­‰å¾…æœå‹™å•Ÿå‹•
    log_info "ç­‰å¾… Ollama æœå‹™å•Ÿå‹•..."
    sleep 30
    
    # æª¢æŸ¥æœå‹™ç‹€æ…‹
    if kubectl exec -n podwise $pod_name -- curl -s http://localhost:11434/api/tags > /dev/null; then
        log_success "Ollama æœå‹™æ­£å¸¸é‹è¡Œ"
    else
        log_error "Ollama æœå‹™æœªæ­£å¸¸é‹è¡Œ"
        exit 1
    fi
}

# å‰µå»º Modelfile
create_modelfile() {
    log_info "å‰µå»º Modelfile..."
    
    cat > Modelfile << 'EOF'
FROM ./Qwen2.5-Taiwan-7B-Instruct

TEMPLATE """{{ if .System }}<|im_start|>system
{{ .System }}<|im_end|>
{{ end }}{{ if .Prompt }}<|im_start|>user
{{ .Prompt }}<|im_end|>
{{ end }}<|im_start|>assistant
"""

PARAMETER stop "<|im_end|>"
PARAMETER stop "<|im_start|>"
PARAMETER stop "<|endoftext|>"

SYSTEM """ä½ æ˜¯ Qwen-Taiwan-7B, ä¾†è‡ªå°ç£ã€‚ä½ æ˜¯ä¸€ä½æ¨‚æ–¼å›ç­”å•é¡Œçš„åŠ©æ‰‹ã€‚"""
EOF
    
    log_success "Modelfile å‰µå»ºå®Œæˆ"
}

# æ¨é€æ¨¡å‹åˆ° Ollama
push_model_to_ollama() {
    log_info "æ¨é€æ¨¡å‹åˆ° Ollama..."
    
    local pod_name=$1
    
    # è¤‡è£½æ¨¡å‹æª”æ¡ˆåˆ° Pod
    log_info "è¤‡è£½æ¨¡å‹æª”æ¡ˆåˆ° Ollama Pod..."
    kubectl cp backend/llm/models/Qwen2.5-Taiwan-7B-Instruct podwise/$pod_name:/tmp/Qwen2.5-Taiwan-7B-Instruct
    
    # è¤‡è£½ Modelfile åˆ° Pod
    log_info "è¤‡è£½ Modelfile åˆ° Ollama Pod..."
    kubectl cp Modelfile podwise/$pod_name:/tmp/Modelfile
    
    # åœ¨ Pod ä¸­å‰µå»ºæ¨¡å‹
    log_info "åœ¨ Ollama Pod ä¸­å‰µå»ºæ¨¡å‹..."
    kubectl exec -n podwise $pod_name -- bash -c "
        cd /tmp && \
        ollama create qwen2.5-taiwan-7b-instruct -f Modelfile && \
        echo 'æ¨¡å‹å‰µå»ºå®Œæˆ'
    "
    
    log_success "æ¨¡å‹æ¨é€å®Œæˆ"
}

# é©—è­‰æ¨¡å‹
verify_model() {
    log_info "é©—è­‰æ¨¡å‹..."
    
    local pod_name=$1
    
    # æª¢æŸ¥æ¨¡å‹åˆ—è¡¨
    log_info "æª¢æŸ¥å¯ç”¨æ¨¡å‹..."
    kubectl exec -n podwise $pod_name -- ollama list
    
    # æ¸¬è©¦æ¨¡å‹
    log_info "æ¸¬è©¦æ¨¡å‹å›æ‡‰..."
    kubectl exec -n podwise $pod_name -- ollama run qwen2.5-taiwan-7b-instruct "ä½ å¥½ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼šä½ æ˜¯èª°ï¼Ÿ" --timeout 30
    
    log_success "æ¨¡å‹é©—è­‰å®Œæˆ"
}

# æ›´æ–°é…ç½®
update_config() {
    log_info "æ›´æ–°ç³»çµ±é…ç½®..."
    
    # æ›´æ–°ä¸‹è¼‰è…³æœ¬ï¼Œå°‡å°ç£ç‰ˆæœ¬è¨­ç‚ºç¬¬ä¸€å„ªå…ˆ
    log_info "æ›´æ–°æ¨¡å‹ä¸‹è¼‰è…³æœ¬..."
    
    cat > deploy/k8s/ollama/download-models.sh << 'EOF'
#!/bin/bash

# Qwen æ¨¡å‹ä¸‹è¼‰è…³æœ¬
# ç”¨æ–¼åœ¨ Ollama å®¹å™¨ä¸­ä¸‹è¼‰æ‰€éœ€çš„ LLM æ¨¡å‹

set -e

echo "ğŸš€ é–‹å§‹ä¸‹è¼‰ Qwen æ¨¡å‹..."

# ç­‰å¾… Ollama æœå‹™å•Ÿå‹•
echo "â³ ç­‰å¾… Ollama æœå‹™å•Ÿå‹•..."
sleep 30

# æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹
echo "ğŸ” æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹..."
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âŒ Ollama æœå‹™æœªå•Ÿå‹•ï¼Œè«‹æª¢æŸ¥æœå‹™ç‹€æ…‹"
    exit 1
fi

echo "âœ… Ollama æœå‹™æ­£å¸¸é‹è¡Œ"

# æª¢æŸ¥æ˜¯å¦å·²æœ‰æœ¬åœ°å°ç£ç‰ˆæœ¬æ¨¡å‹
echo "ğŸ” æª¢æŸ¥æœ¬åœ°å°ç£ç‰ˆæœ¬æ¨¡å‹..."
if ollama list | grep -q "qwen2.5-taiwan-7b-instruct"; then
    echo "âœ… æœ¬åœ°å°ç£ç‰ˆæœ¬æ¨¡å‹å·²å­˜åœ¨"
else
    echo "ğŸ“¥ ä¸‹è¼‰ Qwen2.5-Taiwan-7B-Instruct..."
    ollama pull weiren119/Qwen2.5-Taiwan-7B-Instruct
fi

# ä¸‹è¼‰ Qwen2.5-8B-Instruct (ç¬¬äºŒå„ªå…ˆ)
echo "ğŸ“¥ ä¸‹è¼‰ Qwen2.5-8B-Instruct..."
ollama pull Qwen/Qwen2.5-8B-Instruct

# ä¸‹è¼‰ Qwen3:8b (å‚™ç”¨)
echo "ğŸ“¥ ä¸‹è¼‰ Qwen3:8b..."
ollama pull qwen2.5:8b

# åˆ—å‡ºå·²ä¸‹è¼‰çš„æ¨¡å‹
echo "ğŸ“‹ å·²ä¸‹è¼‰çš„æ¨¡å‹åˆ—è¡¨ï¼š"
ollama list

echo "âœ… æ‰€æœ‰æ¨¡å‹ä¸‹è¼‰å®Œæˆï¼"
EOF
    
    log_success "é…ç½®æ›´æ–°å®Œæˆ"
}

# é¡¯ç¤ºæœå‹™è³‡è¨Š
show_service_info() {
    log_info "Podwise å°ç£ç‰ˆæœ¬æ¨¡å‹éƒ¨ç½²å®Œæˆï¼"
    echo ""
    echo "ğŸŒ Ollama æœå‹™ç«¯é»: http://worker1:31134"
    echo "ğŸ“š å°ç£ç‰ˆæœ¬æ¨¡å‹: qwen2.5-taiwan-7b-instruct"
    echo "ğŸ”§ æ¨¡å‹ç®¡ç†: kubectl exec -n podwise <pod-name> -- ollama list"
    echo "ğŸ§ª æ¨¡å‹æ¸¬è©¦: kubectl exec -n podwise <pod-name> -- ollama run qwen2.5-taiwan-7b-instruct 'ä½ å¥½'"
    echo ""
    log_success "éƒ¨ç½²å®Œæˆï¼"
}

# ä¸»å‡½æ•¸
main() {
    log_info "é–‹å§‹æ¨é€å°ç£ç‰ˆæœ¬æ¨¡å‹åˆ° Kubernetes Ollama..."
    
    # æª¢æŸ¥å‰ç½®æ¢ä»¶
    check_prerequisites
    
    # ç²å– Ollama Pod åç¨±
    OLLAMA_POD=$(get_ollama_pod)
    
    # æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹
    check_ollama_service $OLLAMA_POD
    
    # å‰µå»º Modelfile
    create_modelfile
    
    # æ¨é€æ¨¡å‹åˆ° Ollama
    push_model_to_ollama $OLLAMA_POD
    
    # é©—è­‰æ¨¡å‹
    verify_model $OLLAMA_POD
    
    # æ›´æ–°é…ç½®
    update_config
    
    # é¡¯ç¤ºæœå‹™è³‡è¨Š
    show_service_info
}

# åŸ·è¡Œä¸»å‡½æ•¸
main "$@" 