#!/bin/bash

# Podwise RAG Pipeline Worker2 éƒ¨ç½²è…³æœ¬
# ç”¨æ–¼åœ¨ worker2 ç¯€é»ä¸Šéƒ¨ç½² RAG pipelineï¼Œä¸¦å¼•ç”¨ K8s ä¸­çš„ LLM æœå‹™

set -e

# é¡è‰²å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# é…ç½®è®Šæ•¸
WORKER2_HOST="bdse37@worker2"
RAG_PIPELINE_DIR="/home/bdse37/rag_pipeline"
REGISTRY="192.168.32.38:5000"
IMAGE_NAME="podwise-rag-pipeline"
IMAGE_TAG="latest"
CONTAINER_NAME="rag-pipeline-worker2"

# æ—¥èªŒå‡½æ•¸
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æª¢æŸ¥ SSH é€£æ¥
check_ssh_connection() {
    log_info "æª¢æŸ¥ SSH é€£æ¥åˆ° worker2..."
    if ssh -o ConnectTimeout=10 -o BatchMode=yes $WORKER2_HOST "echo 'SSH é€£æ¥æˆåŠŸ'" 2>/dev/null; then
        log_success "SSH é€£æ¥æ­£å¸¸"
    else
        log_error "ç„¡æ³•é€£æ¥åˆ° worker2ï¼Œè«‹æª¢æŸ¥ SSH é…ç½®"
        exit 1
    fi
}

# æª¢æŸ¥ RAG pipeline ç›®éŒ„
check_rag_pipeline_dir() {
    log_info "æª¢æŸ¥ RAG pipeline ç›®éŒ„..."
    if ssh $WORKER2_HOST "[ -d $RAG_PIPELINE_DIR ]"; then
        log_success "RAG pipeline ç›®éŒ„å­˜åœ¨"
        ssh $WORKER2_HOST "ls -la $RAG_PIPELINE_DIR"
    else
        log_error "RAG pipeline ç›®éŒ„ä¸å­˜åœ¨: $RAG_PIPELINE_DIR"
        exit 1
    fi
}

# æª¢æŸ¥ K8s æœå‹™ç‹€æ…‹
check_k8s_services() {
    log_info "æª¢æŸ¥ K8s æœå‹™ç‹€æ…‹..."
    
    # æª¢æŸ¥ LLM æœå‹™
    if kubectl get svc -n podwise llm-service >/dev/null 2>&1; then
        log_success "LLM æœå‹™å­˜åœ¨"
        kubectl get svc -n podwise llm-service
    else
        log_error "LLM æœå‹™ä¸å­˜åœ¨"
        exit 1
    fi
    
    # æª¢æŸ¥ TTS æœå‹™
    if kubectl get svc -n podwise tts-service >/dev/null 2>&1; then
        log_success "TTS æœå‹™å­˜åœ¨"
        kubectl get svc -n podwise tts-service
    else
        log_warning "TTS æœå‹™ä¸å­˜åœ¨"
    fi
    
    # æª¢æŸ¥ STT æœå‹™
    if kubectl get svc -n podwise stt-service >/dev/null 2>&1; then
        log_success "STT æœå‹™å­˜åœ¨"
        kubectl get svc -n podwise stt-service
    else
        log_warning "STT æœå‹™ä¸å­˜åœ¨"
    fi
}

# å®‰è£ä¾è³´
install_dependencies() {
    log_info "åœ¨ worker2 ä¸Šå®‰è£ Python ä¾è³´..."
    
    # æª¢æŸ¥ä¸¦å®‰è£ pip
    ssh $WORKER2_HOST "if ! command -v pip3 &> /dev/null; then sudo apt update && sudo apt install -y python3-pip; fi"
    
    # å®‰è£ä¾è³´
    ssh $WORKER2_HOST "cd $RAG_PIPELINE_DIR && pip3 install --upgrade pip"
    ssh $WORKER2_HOST "cd $RAG_PIPELINE_DIR && pip3 install -r requirements.txt"
    
    # å®‰è£é¡å¤–çš„ä¾è³´
    ssh $WORKER2_HOST "cd $RAG_PIPELINE_DIR && pip3 install pydantic-settings"
    
    log_success "ä¾è³´å®‰è£å®Œæˆ"
}

# æ¸¬è©¦ K8s æœå‹™é€£ç·š
test_k8s_connections() {
    log_info "æ¸¬è©¦ K8s æœå‹™é€£ç·š..."
    
    # ç²å– worker1 IP
    WORKER1_IP=$(kubectl get nodes -o wide | grep worker1 | awk '{print $6}')
    if [ -z "$WORKER1_IP" ]; then
        WORKER1_IP="192.168.32.38"  # é è¨­ IP
    fi
    
    # æ¸¬è©¦ LLM æœå‹™
    log_info "æ¸¬è©¦ LLM æœå‹™é€£ç·š..."
    if ssh $WORKER2_HOST "curl -s http://$WORKER1_IP:30800/health" >/dev/null 2>&1; then
        log_success "LLM æœå‹™é€£ç·šæ­£å¸¸"
    else
        log_warning "LLM æœå‹™é€£ç·šå¤±æ•—ï¼Œä½†ç¹¼çºŒéƒ¨ç½²"
    fi
    
    # æ¸¬è©¦ TTS æœå‹™
    log_info "æ¸¬è©¦ TTS æœå‹™é€£ç·š..."
    if ssh $WORKER2_HOST "curl -s http://$WORKER1_IP:30801/health" >/dev/null 2>&1; then
        log_success "TTS æœå‹™é€£ç·šæ­£å¸¸"
    else
        log_warning "TTS æœå‹™é€£ç·šå¤±æ•—"
    fi
    
    # æ¸¬è©¦ STT æœå‹™
    log_info "æ¸¬è©¦ STT æœå‹™é€£ç·š..."
    if ssh $WORKER2_HOST "curl -s http://$WORKER1_IP:30802/health" >/dev/null 2>&1; then
        log_success "STT æœå‹™é€£ç·šæ­£å¸¸"
    else
        log_warning "STT æœå‹™é€£ç·šå¤±æ•—"
    fi
}

# è¨­ç½®ç’°å¢ƒè®Šæ•¸
setup_environment() {
    log_info "è¨­ç½®ç’°å¢ƒè®Šæ•¸..."
    
    # æª¢æŸ¥ OpenAI API Key
    if [ -n "$OPENAI_API_KEY" ]; then
        log_info "âœ… æª¢æ¸¬åˆ° OpenAI API Keyï¼Œå°‡å•Ÿç”¨å‚™æ´æ©Ÿåˆ¶"
        OPENAI_CONFIG="export OPENAI_API_KEY=\"$OPENAI_API_KEY\""
    else
        log_warning "âš ï¸  æœªè¨­ç½® OpenAI API Keyï¼Œå°‡åƒ…ä½¿ç”¨ Qwen æ¨¡å‹"
        OPENAI_CONFIG="# export OPENAI_API_KEY=\"\""
    fi
    
    # å‰µå»ºç’°å¢ƒè®Šæ•¸æª”æ¡ˆ
    cat > /tmp/rag_env.sh << EOF
#!/bin/bash
# K8s æœå‹™é…ç½®
export LLM_HOST="192.168.32.38"
export LLM_PORT="30800"
export TTS_HOST="192.168.32.38"
export TTS_PORT="30801"
export STT_HOST="192.168.32.38"
export STT_PORT="30802"

# Python é…ç½®
export PYTHONPATH="$RAG_PIPELINE_DIR"
export PYTHONUNBUFFERED="1"
export CUDA_VISIBLE_DEVICES="0"

# æ‡‰ç”¨é…ç½®
export APP_ENV="production"
export DEBUG="false"
export LOG_LEVEL="INFO"

# LLM é…ç½®
export OLLAMA_HOST="http://worker1:11434"
export OLLAMA_MODEL="qwen2.5:8b"

# OpenAI å‚™æ´é…ç½®
$OPENAI_CONFIG

# è³‡æ–™åº«é…ç½®
export MONGODB_URI="mongodb://worker3:27017/podwise"
export POSTGRES_HOST="worker3"
export POSTGRES_PORT="5432"

# å‘é‡æœå°‹é…ç½®
export MILVUS_HOST="worker3"
export MILVUS_PORT="19530"
EOF
    
    # è¤‡è£½åˆ° worker2
    scp /tmp/rag_env.sh $WORKER2_HOST:$RAG_PIPELINE_DIR/
    ssh $WORKER2_HOST "chmod +x $RAG_PIPELINE_DIR/rag_env.sh"
    
    log_success "ç’°å¢ƒè®Šæ•¸è¨­ç½®å®Œæˆ"
}

# æ¸¬è©¦ RAG pipeline
test_rag_pipeline() {
    log_info "æ¸¬è©¦ RAG pipeline..."
    
    # å‰µå»ºæ¸¬è©¦è…³æœ¬
    cat > /tmp/test_rag.py << 'EOF'
#!/usr/bin/env python3
"""
RAG Pipeline æ¸¬è©¦è…³æœ¬ - åŒ…å« LLM å‚™æ´æ©Ÿåˆ¶æ¸¬è©¦
"""

import sys
import os
sys.path.append('/home/bdse37/rag_pipeline')

try:
    from config.integrated_config import get_config
    from core.qwen3_llm_manager import get_qwen3_llm_manager
    
    print("=== RAG Pipeline æ¸¬è©¦ ===")
    
    # æ¸¬è©¦é…ç½®
    config = get_config()
    print("âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
    
    # æª¢æŸ¥å„ªå…ˆç´šé †åº
    priority_models = config.models.llm_priority or []
    print(f"ğŸ“‹ æ¨¡å‹å„ªå…ˆç´šé †åº: {priority_models}")
    
    # æª¢æŸ¥å°ç£æ¨¡å‹æ˜¯å¦ç‚ºç¬¬ä¸€å„ªå…ˆ
    taiwan_first = priority_models and priority_models[0] == "qwen2.5:taiwan"
    print(f"ğŸ‡¹ğŸ‡¼ å°ç£æ¨¡å‹ç¬¬ä¸€å„ªå…ˆ: {'âœ…' if taiwan_first else 'âŒ'}")
    
    # æ¸¬è©¦ LLM ç®¡ç†å™¨
    manager = get_qwen3_llm_manager()
    available_models = manager.get_available_models()
    print(f"ğŸ¤– å¯ç”¨æ¨¡å‹: {available_models}")
    
    # æª¢æŸ¥ OpenAI é…ç½®
    openai_configured = bool(config.api.openai_api_key)
    print(f"ğŸ”‘ OpenAI å‚™æ´é…ç½®: {'âœ… å·²é…ç½®' if openai_configured else 'âŒ æœªé…ç½®'}")
    
    # æ¸¬è©¦å¥åº·æª¢æŸ¥
    current_model = manager.current_model
    is_healthy = manager.test_model_health(current_model)
    print(f"ğŸ¥ ç•¶å‰æ¨¡å‹ {current_model} å¥åº·ç‹€æ…‹: {'âœ…' if is_healthy else 'âŒ'}")
    
    # æ¸¬è©¦å‚™æ´æ©Ÿåˆ¶
    best_model = manager.get_best_model()
    print(f"ğŸ¯ æœ€ä½³æ¨¡å‹: {best_model}")
    
    # æ¸¬è©¦ç°¡å–®æŸ¥è©¢
    if is_healthy:
        response = manager.call_with_fallback("è«‹ç”¨ç¹é«”ä¸­æ–‡ç°¡å–®ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±ã€‚")
        success = "éŒ¯èª¤" not in response and len(response) > 10
        print(f"ğŸ’¬ æ¸¬è©¦å›æ‡‰: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±æ•—'}")
        print(f"   å›æ‡‰å…§å®¹: {response[:100]}...")
    else
        print("âš ï¸  æ¨¡å‹ä¸å¥åº·ï¼Œè·³éæŸ¥è©¢æ¸¬è©¦")
    
    print("=== æ¸¬è©¦å®Œæˆ ===")
    
except Exception as e:
    print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
EOF
    
    # è¤‡è£½åˆ° worker2 ä¸¦åŸ·è¡Œ
    scp /tmp/test_rag.py $WORKER2_HOST:$RAG_PIPELINE_DIR/
    ssh $WORKER2_HOST "cd $RAG_PIPELINE_DIR && source rag_env.sh && python3 test_rag.py"
    
    if [ $? -eq 0 ]; then
        log_success "RAG pipeline æ¸¬è©¦é€šé"
    else
        log_error "RAG pipeline æ¸¬è©¦å¤±æ•—"
        exit 1
    fi
}

# å•Ÿå‹• RAG pipeline æœå‹™
start_rag_service() {
    log_info "å•Ÿå‹• RAG pipeline æœå‹™..."
    
    # å‰µå»ºå•Ÿå‹•è…³æœ¬
    cat > /tmp/start_rag_service.py << 'EOF'
#!/usr/bin/env python3
"""
RAG Pipeline æœå‹™å•Ÿå‹•è…³æœ¬ - CrewAI æ¶æ§‹
"""

import sys
import os
sys.path.append('/home/bdse37/rag_pipeline')

from app.main_crewai import app
import uvicorn

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8002,
        log_level="info",
        workers=1
    )
EOF
    
    # è¤‡è£½åˆ° worker2
    scp /tmp/start_rag_service.py $WORKER2_HOST:$RAG_PIPELINE_DIR/
    
    # å•Ÿå‹•æœå‹™ï¼ˆåœ¨èƒŒæ™¯é‹è¡Œï¼‰
    ssh $WORKER2_HOST "cd $RAG_PIPELINE_DIR && source rag_env.sh && nohup python3 start_rag_service.py > rag_service.log 2>&1 &"
    
    # ç­‰å¾…æœå‹™å•Ÿå‹•
    sleep 10
    
    # æª¢æŸ¥æœå‹™ç‹€æ…‹
    if ssh $WORKER2_HOST "curl -s http://localhost:8002/health" >/dev/null 2>&1; then
        log_success "RAG pipeline æœå‹™å•Ÿå‹•æˆåŠŸ"
        ssh $WORKER2_HOST "curl -s http://localhost:8002/health"
    else
        log_error "RAG pipeline æœå‹™å•Ÿå‹•å¤±æ•—"
        ssh $WORKER2_HOST "tail -20 $RAG_PIPELINE_DIR/rag_service.log"
        exit 1
    fi
}

# é¡¯ç¤ºæœå‹™è³‡è¨Š
show_service_info() {
    log_info "=== RAG Pipeline æœå‹™è³‡è¨Š ==="
    echo "æœå‹™ç«¯é»: http://worker2:8002"
    echo "å¥åº·æª¢æŸ¥: http://worker2:8002/health"
    echo "API æ–‡æª”: http://worker2:8002/docs"
    echo ""
    echo "K8s æœå‹™é€£ç·š:"
    echo "- LLM æœå‹™: http://192.168.32.38:30800"
    echo "- TTS æœå‹™: http://192.168.32.38:30801"
    echo "- STT æœå‹™: http://192.168.32.38:30802"
    echo ""
    echo "æ—¥èªŒæª”æ¡ˆ: $RAG_PIPELINE_DIR/rag_service.log"
    echo "ç’°å¢ƒè®Šæ•¸: $RAG_PIPELINE_DIR/rag_env.sh"
}

# ä¸»å‡½æ•¸
main() {
    log_info "é–‹å§‹éƒ¨ç½² RAG pipeline åˆ° worker2..."
    
    check_ssh_connection
    check_rag_pipeline_dir
    check_k8s_services
    install_dependencies
    test_k8s_connections
    setup_environment
    test_rag_pipeline
    start_rag_service
    show_service_info
    
    log_success "RAG pipeline éƒ¨ç½²å®Œæˆï¼"
}

# åŸ·è¡Œä¸»å‡½æ•¸
main "$@" 