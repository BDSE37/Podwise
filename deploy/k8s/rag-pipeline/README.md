# Podwise RAG Pipeline K8s é–‹ç™¼æ–‡ä»¶

## ğŸ“ ç›®éŒ„çµæ§‹

```
deploy/k8s/rag-pipeline/
â”œâ”€â”€ README.md                           # æœ¬æ–‡ä»¶
â”œâ”€â”€ DEPLOYMENT_GUIDE.md                 # è©³ç´°éƒ¨ç½²æŒ‡å—
â”œâ”€â”€ quick-deploy.sh                     # å¿«é€Ÿéƒ¨ç½²è…³æœ¬
â”œâ”€â”€ build-and-deploy-k8s.sh             # Docker K8s æ§‹å»ºéƒ¨ç½²è…³æœ¬
â”œâ”€â”€ build-and-deploy-podman.sh          # Podman K8s æ§‹å»ºéƒ¨ç½²è…³æœ¬
â”œâ”€â”€ deploy-rag-on-worker2.sh            # Worker2 éƒ¨ç½²è…³æœ¬
â”œâ”€â”€ deploy-single-node.sh               # å–®ç¯€é»éƒ¨ç½²è…³æœ¬
â”œâ”€â”€ test-rag-connection.sh              # é€£æ¥æ¸¬è©¦è…³æœ¬
â”œâ”€â”€ Dockerfile                          # Docker æ˜ åƒæª”
â”œâ”€â”€ rag-pipeline-deployment.yaml        # K8s éƒ¨ç½²é…ç½®
â”œâ”€â”€ rag-pipeline-pvc.yaml               # æŒä¹…åŒ–å­˜å„²é…ç½®
â”œâ”€â”€ rag-pipeline-single-node.yaml       # å–®ç¯€é»éƒ¨ç½²é…ç½®
â”œâ”€â”€ rag-pipeline-pvc-single.yaml        # å–®ç¯€é» PVC é…ç½®
â””â”€â”€ openai-secrets.yaml                 # OpenAI Secrets é…ç½®
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. ä½¿ç”¨å¿«é€Ÿéƒ¨ç½²è…³æœ¬ (æ¨è–¦)

```bash
# é€²å…¥ç›®éŒ„
cd deploy/k8s/rag-pipeline

# æŸ¥çœ‹å¹«åŠ©
./quick-deploy.sh --help

# K8s éƒ¨ç½² (ä½¿ç”¨ Podmanï¼ŒåŒ…å« OpenAI å‚™æ´)
./quick-deploy.sh -m k8s -b podman -k "your_openai_api_key"

# K8s éƒ¨ç½² (ä½¿ç”¨ Docker)
./quick-deploy.sh -m k8s -b docker -k "your_openai_api_key"

# Worker2 éƒ¨ç½²
./quick-deploy.sh -m worker2 -k "your_openai_api_key"

# åŒæ™‚éƒ¨ç½²åˆ° K8s å’Œ Worker2 (ä½¿ç”¨ Podman)
./quick-deploy.sh -m both -b podman -k "your_openai_api_key" -y
```

### 2. æ‰‹å‹•éƒ¨ç½²

```bash
# è¨­ç½®ç’°å¢ƒè®Šæ•¸
export OPENAI_API_KEY="your_openai_api_key"

# åŸ·è¡Œ K8s éƒ¨ç½²
./build-and-deploy-k8s.sh

# æˆ–åŸ·è¡Œ Worker2 éƒ¨ç½²
./deploy-rag-on-worker2.sh
```

## ğŸ¤– LLM å‚™æ´æ©Ÿåˆ¶

### æ¨¡å‹å„ªå…ˆç´š

1. **Qwen2.5-Taiwan** (ç¬¬ä¸€å„ªå…ˆ)
   - å°ç£å„ªåŒ–ç‰ˆæœ¬
   - é‡å°ç¹é«”ä¸­æ–‡å„ªåŒ–
   - æ¨¡å‹: `weiren119/Qwen2.5-Taiwan-8B-Instruct`

2. **Qwen3:8b** (ç¬¬äºŒå„ªå…ˆ)
   - æ¨™æº– Qwen3 æ¨¡å‹
   - ä¸»è¦å‚™ç”¨æ¨¡å‹
   - æ¨¡å‹: `Qwen/Qwen2.5-8B-Instruct`

3. **OpenAI GPT-3.5** (å‚™æ´)
   - éœ€è¦ OpenAI API Key
   - ç•¶å‰é¢æ¨¡å‹ä¸å¯ç”¨æ™‚å•Ÿç”¨
   - æ¨¡å‹: `gpt-3.5-turbo`

4. **OpenAI GPT-4** (æœ€å¾Œå‚™æ´)
   - æœ€é«˜å“è³ªå‚™æ´
   - æˆæœ¬è¼ƒé«˜
   - æ¨¡å‹: `gpt-4`

### é…ç½® OpenAI å‚™æ´

```bash
# æ–¹æ³• 1: ç’°å¢ƒè®Šæ•¸
export OPENAI_API_KEY="your_openai_api_key"

# æ–¹æ³• 2: K8s Secret
kubectl create secret generic openai-secrets \
    --from-literal=OPENAI_API_KEY="your_openai_api_key" \
    --namespace=podwise
```

## ğŸ“‹ éƒ¨ç½²è…³æœ¬èªªæ˜

### quick-deploy.sh
- **åŠŸèƒ½**: æ•´åˆæ‰€æœ‰éƒ¨ç½²æ–¹å¼çš„å¿«é€Ÿéƒ¨ç½²è…³æœ¬
- **ç‰¹é»**: æ”¯æ´å‘½ä»¤è¡Œåƒæ•¸ã€è‡ªå‹•é©—è­‰ã€è©³ç´°æ—¥èªŒ
- **ç”¨æ³•**: `./quick-deploy.sh -m k8s -k "api_key"`

### build-and-deploy-k8s.sh
- **åŠŸèƒ½**: ä½¿ç”¨ Docker æ§‹å»ºæ˜ åƒä¸¦éƒ¨ç½²åˆ° K8s
- **ç‰¹é»**: è‡ªå‹•æ§‹å»ºã€æ¨é€ã€éƒ¨ç½²ã€é©—è­‰
- **åŒ…å«**: Secrets å‰µå»ºã€å¥åº·æª¢æŸ¥ã€æœå‹™æ¸¬è©¦

### build-and-deploy-podman.sh
- **åŠŸèƒ½**: ä½¿ç”¨ Podman æ§‹å»ºæ˜ åƒä¸¦éƒ¨ç½²åˆ° K8s
- **ç‰¹é»**: è‡ªå‹•æ§‹å»ºã€æ¨é€ã€éƒ¨ç½²ã€é©—è­‰ã€æœ¬åœ°æ¸…ç†
- **åŒ…å«**: Secrets å‰µå»ºã€å¥åº·æª¢æŸ¥ã€æœå‹™æ¸¬è©¦ã€æ˜ åƒæ¸…ç†

### deploy-rag-on-worker2.sh
- **åŠŸèƒ½**: åœ¨ worker2 ç¯€é»ä¸Šéƒ¨ç½² RAG Pipeline
- **ç‰¹é»**: SSH é€£æ¥ã€ä¾è³´å®‰è£ã€æœå‹™æ¸¬è©¦
- **åŒ…å«**: ç’°å¢ƒè¨­ç½®ã€LLM æ¸¬è©¦ã€æœå‹™å•Ÿå‹•

### deploy-single-node.sh
- **åŠŸèƒ½**: å–®ç¯€é»éƒ¨ç½² (é©ç”¨æ–¼é–‹ç™¼ç’°å¢ƒ)
- **ç‰¹é»**: ç°¡åŒ–é…ç½®ã€å¿«é€Ÿéƒ¨ç½²
- **åŒ…å«**: åŸºæœ¬æœå‹™é…ç½®ã€æœ¬åœ°æ¸¬è©¦

## âš™ï¸ é…ç½®æ–‡ä»¶èªªæ˜

### rag-pipeline-deployment.yaml
- **ç”¨é€”**: K8s ä¸»è¦éƒ¨ç½²é…ç½®
- **åŒ…å«**: Pod é…ç½®ã€æœå‹™é…ç½®ã€è³‡æºé™åˆ¶
- **ç‰¹é»**: æ”¯æ´ LLM å‚™æ´ã€å¥åº·æª¢æŸ¥ã€ç¯€é»é¸æ“‡

### rag-pipeline-pvc.yaml
- **ç”¨é€”**: æŒä¹…åŒ–å­˜å„²é…ç½®
- **åŒ…å«**: æ•¸æ“šå­˜å„²ã€æ¨¡å‹å­˜å„²ã€å¿«å–å­˜å„²
- **ç‰¹é»**: å¤šå±¤ç´šå­˜å„²ã€å‚™ä»½æ”¯æ´

### openai-secrets.yaml
- **ç”¨é€”**: OpenAI API Key å®‰å…¨å­˜å„²
- **åŒ…å«**: Secret é…ç½®ã€å‘½åç©ºé–“è¨­ç½®
- **ç‰¹é»**: å®‰å…¨å­˜å„²ã€å¯é¸é…ç½®

## ğŸ”§ æ¸¬è©¦å’Œé©—è­‰

### é€£æ¥æ¸¬è©¦
```bash
# åŸ·è¡Œé€£æ¥æ¸¬è©¦
./test-rag-connection.sh

# æ‰‹å‹•æ¸¬è©¦
curl http://worker2:30806/health
curl http://worker2:30806/api/v1/llm-status
```

### LLM å‚™æ´æ¸¬è©¦
```bash
# é€²å…¥ Pod åŸ·è¡Œæ¸¬è©¦
kubectl exec -it deployment/rag-pipeline-service -n podwise -- python3 -c "
from backend.rag_pipeline.test_llm_fallback import LLMFallbackTest
import asyncio

async def test():
    test_suite = LLMFallbackTest()
    results = test_suite.run_all_tests()
    print(f'æ¸¬è©¦çµæœ: {results[\"summary\"]}')

asyncio.run(test())
"
```

## ğŸ“Š ç›£æ§å’Œæ—¥èªŒ

### æŸ¥çœ‹æœå‹™ç‹€æ…‹
```bash
# Pod ç‹€æ…‹
kubectl get pods -n podwise -l app=rag-pipeline-service

# æœå‹™ç‹€æ…‹
kubectl get svc -n podwise -l app=rag-pipeline-service

# æ—¥èªŒæŸ¥çœ‹
kubectl logs -f deployment/rag-pipeline-service -n podwise
```

### å¥åº·æª¢æŸ¥
```bash
# è‡ªå‹•å¥åº·æª¢æŸ¥
kubectl get pods -n podwise -l app=rag-pipeline-service

# æ‰‹å‹•å¥åº·æª¢æŸ¥
curl http://worker2:30806/health
```

## ğŸ”„ ç¶­è­·æ“ä½œ

### æ›´æ–°éƒ¨ç½²
```bash
# æ›´æ–°æ˜ åƒ
kubectl set image deployment/rag-pipeline-service rag-pipeline-service=192.168.32.38:5000/podwise-rag-pipeline:latest -n podwise

# é‡å•Ÿéƒ¨ç½²
kubectl rollout restart deployment/rag-pipeline-service -n podwise
```

### æ“´å±•æœå‹™
```bash
# æ“´å±•å‰¯æœ¬æ•¸
kubectl scale deployment/rag-pipeline-service --replicas=3 -n podwise
```

### æ•…éšœæ’é™¤
```bash
# æŸ¥çœ‹ Pod äº‹ä»¶
kubectl describe pod <pod-name> -n podwise

# æŸ¥çœ‹è©³ç´°æ—¥èªŒ
kubectl logs <pod-name> -n podwise --previous

# é€²å…¥ Pod é™¤éŒ¯
kubectl exec -it <pod-name> -n podwise -- bash
```

## ğŸ¯ æˆåŠŸæŒ‡æ¨™

éƒ¨ç½²æˆåŠŸå¾Œæ‡‰è©²çœ‹åˆ°ï¼š

- âœ… Pod ç‹€æ…‹ç‚º `Running`
- âœ… å¥åº·æª¢æŸ¥ç«¯é»å›æ‡‰æ­£å¸¸
- âœ… API æŸ¥è©¢ç«¯é»æ­£å¸¸å·¥ä½œ
- âœ… LLM å‚™æ´æ©Ÿåˆ¶æ­£å¸¸é‹ä½œ
- âœ… å°ç£æ¨¡å‹ç‚ºç¬¬ä¸€å„ªå…ˆ
- âœ… OpenAI å‚™æ´é…ç½®æ­£ç¢º (å¦‚æœè¨­ç½®)
- âœ… podri-chat èƒ½æˆåŠŸç™¼é€æŸ¥è©¢åˆ° RAG Pipeline

## ğŸ“š ç›¸é—œæ–‡æª”

- [è©³ç´°éƒ¨ç½²æŒ‡å—](DEPLOYMENT_GUIDE.md) - å®Œæ•´çš„éƒ¨ç½²èªªæ˜
- [Podman éƒ¨ç½²æŒ‡å—](PODMAN_DEPLOYMENT.md) - Podman å°ˆç”¨éƒ¨ç½²èªªæ˜
- [CrewAI + LangChain æ•´åˆèªªæ˜](../../../backend/rag_pipeline/README_CrewAI_LangChain_LLM.md) - æ¶æ§‹èªªæ˜
- [LLM å‚™æ´æ¸¬è©¦](../../../backend/rag_pipeline/test_llm_fallback.py) - æ¸¬è©¦è…³æœ¬

## ğŸ¤ è²¢ç»

å¦‚éœ€ä¿®æ”¹æˆ–æ“´å±•éƒ¨ç½²é…ç½®ï¼Œè«‹ï¼š

1. æ›´æ–°å°æ‡‰çš„é…ç½®æ–‡ä»¶
2. ä¿®æ”¹ç›¸é—œçš„éƒ¨ç½²è…³æœ¬
3. æ›´æ–°æ–‡æª”èªªæ˜
4. æ¸¬è©¦éƒ¨ç½²æµç¨‹
5. æäº¤ Pull Request

## ğŸ“ æ”¯æ´

å¦‚é‡åˆ°å•é¡Œï¼Œè«‹ï¼š

1. æŸ¥çœ‹ [æ•…éšœæ’é™¤æŒ‡å—](DEPLOYMENT_GUIDE.md#æ•…éšœæ’é™¤)
2. æª¢æŸ¥æ—¥èªŒæª”æ¡ˆ
3. åŸ·è¡Œæ¸¬è©¦è…³æœ¬
4. è¯ç¹«é–‹ç™¼åœ˜éšŠ 